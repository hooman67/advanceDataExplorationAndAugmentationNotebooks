{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#imports \n",
    "import skimage\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage import img_as_ubyte\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#get file names\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "#calculate mode\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#you must include the / at the end\n",
    "\n",
    "'''\n",
    "imgBoundariesPath = '/home/hooman/dataPreparation/hsTestSet/imgBoundaries/'\n",
    "labelBoundariesPath = '/home/hooman/dataPreparation/hsTestSet/labelBoundaries/'\n",
    "gtMaskPath = '/home/hooman/dataPreparation/hsTestSet/bucketRectangleMasks/'\n",
    "\n",
    "imagesPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/hydraulics/images_fromJira/'\n",
    "labelsPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/hydraulics/labels_fromJira/'\n",
    "'''\n",
    "\n",
    "imagesPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may26-2019/images/'\n",
    "labelsPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may26-2019/labels/'\n",
    "\n",
    "#resultsLoc = \"/home/hooman/resultsFromExistingNetwork/mahdisNetworkResult/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct Color maps from document\n",
    "\n",
    "###**** FOR THE LABELS YOU MUST CONVERT: \n",
    "#imgLabel = imread(croppedLabelsPath + fileName)\n",
    "#imgLabelRev = cv2.cvtColor(imgLabel, cv2.COLOR_RGB2BGR)\n",
    "###***********************\n",
    "\n",
    "\"\"\" \n",
    "*** Dust and Shadow can be outside or inside. They are trying to convert all shadows and dusts to inside only\n",
    "    but this has not been done in my dataset yet.\n",
    "    \n",
    "*** Inap is anything inside the bucket that is inappropriate for FM and for WM.\n",
    "\n",
    "*** Rock == Boulders\n",
    "*** FineInside == Good For Fragmentation\n",
    "    \n",
    "* Hydralics have no cable and no sheave (the pully puling the cables up).\n",
    "* Bucyris has two cables and two sheaves. \n",
    "* B&H has a single cable and a single sheaves\n",
    "\n",
    "\n",
    "\n",
    "rockInside  = (0, 0, 255, 100)     #blue     \"rock_inside\"      = \"0000FF\"\n",
    "fineInside  = (0, 255, 0, 100)     #green    \"fine_inside\"      = \"00FF00\"\n",
    "emptyInside = (255, 255, 0, 100)   #yellow   \"empty\"            = \"FFFF00\"\n",
    "wmInside    = (255, 100, 100, 100) #L-Pink   \"wm_landmarks\"     = \"FF6464\"\n",
    "inapInside  = (150, 100, 50,100)   #L-Brown  \"inapp_For_FM\"     = \"966432\"\n",
    "\n",
    "\n",
    "teeth       = (255,   0, 255, 100) #pink     \"teeth\"            = \"FF00FF\"\n",
    "case        = (255, 0, 0, 100)     #red      \"case\"             = \"FF0000\"\n",
    "truck       = (255, 255, 200, 100) #cream    \"truck\"            = \"FFFFC8\"\n",
    "sheave      = (255, 128, 0, 100)   #Orage    \"Sheave\"           = \"FF8000\"\n",
    "cable       = (0 , 0, 0, 100)      #black    \"Cable\"            = \"000000\"\n",
    "\n",
    "rockOutside = (128, 0, 255, 100)   #purple    \"rock_outside\"    = \"8000FF\"\n",
    "fineOutside = (0, 255, 255, 100)   #cyan      \"fine_outside\"     = \"00FFFF\"\n",
    "\n",
    "void        = (180, 50, 50, 100)   #Brown    \"void anything not in this labels\"  = \"B43232\"\n",
    "shadow      = (120, 120, 120, 100) #gray     \"shadow inside or outside\"          = \"787878\"\n",
    "dust        = (80, 80, 80, 100)    #D-Gray   \"dust inside or outside\"            = \"505050\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "'''\n",
    "#for Backhoe\n",
    "emptyInside = (255, 255, 0)   #yellow   \"empty\"            = \"FFFF00\"\n",
    "case        = (255, 0, 0)     #red      \"case\"             = \"FF0000\"\n",
    "teeth       = (255,   0, 255) #pink     \"teeth\"            = \"FF00FF\"\n",
    "bucketOutside = (0, 80, 50)\n",
    "\n",
    "\n",
    "cable       = (0 , 0, 0)      #black    \"Cable\"            = \"000000\"\n",
    "shadow      = (150, 150, 150) #gray     \"shadow inside or outside\"          = \"787878\"\n",
    "backGround = (0, 255, 255)   #cyan      \"fine_outside\"     = \"00FFFF\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rockInside  = (0, 0, 255)     #blue     \"rock_inside\"      = \"0000FF\"\n",
    "fineInside  = (0, 255, 0)     #green    \"fine_inside\"      = \"00FF00\"\n",
    "fmInapp = (128, 0, 255)   #purple    \"rock_outside\"    = \"8000FF\"\n",
    "\n",
    "wmInapp = (150, 100,50)\n",
    "wm = (255,100,100)\n",
    "\n",
    "\n",
    "wmInside    = (255, 100, 100) #L-Pink   \"wm_landmarks\"     = \"FF6464\"\n",
    "inapInside  = (150, 100, 50)   #L-Brown  \"inapp_For_FM\"     = \"966432\"\n",
    "\n",
    "sheave      = (255, 128, 0)   #Orage    \"Sheave\"           = \"FF8000\"\n",
    "truck       = (255, 255, 200) #cream    \"truck\"            = \"FFFFC8\"\n",
    "\n",
    "dust = (80,80,80)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#To use the labels below with original labels (not the ones you have saved) use:\n",
    "#imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "# to use these values with labels saved with opencv you must convert to BGR\n",
    "#imgLabelRev = cv2.cvtColor(imgLabel, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "########################\n",
    "# I used this labeles for the manually relabeled ones (by Farhad and Max)\n",
    "# for next retrain round: 150, 100,  50 for fmInapp instead of 128, 0, 255\n",
    "# There is inapp in this color too .128,   0, 255\n",
    "\n",
    "rockInside  = (0, 0, 255)     #blue     \"rock_inside\"      = \"0000FF\"\n",
    "fineInside  = (0, 255, 0)     #green    \"fine_inside\"      = \"00FF00\"\n",
    "emptyInside = (255, 255, 0)   #yellow   \"empty\"            = \"FFFF00\"\n",
    "wmInside    = (255, 100, 100) #L-Pink   \"wm_landmarks\"     = \"FF6464\"\n",
    "inapInside  = (150, 100,  50)   #L-Brown  \"inapp_For_FM\"     = \"966432\"\n",
    "\n",
    "\n",
    "teeth       = (255,   0, 255) #pink     \"teeth\"            = \"FF00FF\"\n",
    "case        = (255, 0, 0)     #red      \"case\"             = \"FF0000\"\n",
    "truck       = (255, 255, 200) #cream    \"truck\"            = \"FFFFC8\"\n",
    "sheave      = (255, 128, 0)   #Orage    \"Sheave\"           = \"FF8000\"\n",
    "cable       = (0 , 0, 0)      #black    \"Cable\"            = \"000000\"\n",
    "\n",
    "rockOutside = (128, 0, 255)   #purple    \"rock_outside\"    = \"8000FF\"\n",
    "fineOutside = (0, 255, 255)   #cyan      \"fine_outside\"     = \"00FFFF\"\n",
    "\n",
    "void        = (180, 50, 50)   #Brown    \"void anything not in this labels\"  = \"B43232\"\n",
    "shadow      = (120, 120, 120) #gray     \"shadow inside or outside\"          = \"787878\"\n",
    "dust        = (80, 80, 80)    #D-Gray   \"dust inside or outside\"            = \"505050\"\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################################################################################################\n",
    "#######################################  FMDL 3.1 STUFF  #########################################################\n",
    "##################################################################################################################\n",
    "\n",
    "# (FOR HYDRAULICS) Use this for images fromJira (the one below for manually relabeled) (V3 training)\n",
    "#After the conversion of .pdn (s) to .png\n",
    "# This pixel values work for the ones from JIRA (not the ones farhad relabeled) which are in:\n",
    "#imagesPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/images/'\n",
    "#labelsPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/labels/'\n",
    "'''\n",
    "rockInside  = (100, 0, 0)     #blue     \"rock_inside\"                      = \"640000\"\n",
    "fineInside  = (100, 0, 50)     #green    \"fine_inside\"                     = \"640032\"\n",
    "emptyInside = (0, 100, 100)   #yellow   \"empty\"                            = \"FFFF00\"\n",
    "wmInside    = (39, 39, 100) #L-Pink   \"wm_landmarks\"                       = \"272764\"\n",
    "\n",
    "wmInapp = (20, 39, 59)                              #                      = \"14273b\"\n",
    "\n",
    "inapInside  = (47, 47, 47)   #L-Brown  \"inapp_For_FM\"                      = \"2f2f2f\"\n",
    "\n",
    "fineInside2 = (0, 100, 0)   # for some images the green is this\n",
    "\n",
    "\n",
    "teeth       = (100,   0, 100) #pink     \"teeth\"                             = \"640064\"\n",
    "case        = (255, 0, 0)     #red      \"case\"                              = \"FF0000\"\n",
    "truck       = (255, 255, 200) #cream    \"truck\"                             = \"FFFFC8\"\n",
    "sheave      = (255, 128, 0)   #Orage    \"Sheave\"                            = \"FF8000\"\n",
    "cable       = (0 , 0, 0)      #black    \"Cable\"                             = \"000000\"\n",
    "\n",
    "rockOutside = (128, 0, 255)   #purple    \"rock_outside\"                     = \"8000FF\"\n",
    "fineOutside = (0, 255, 255)   #cyan      \"fine_outside\"                     = \"00FFFF\"\n",
    "\n",
    "void        = (180, 50, 50)   #Brown    \"void anything not in this labels\"  = \"B43232\"\n",
    "shadow      = (120, 120, 120) #gray     \"shadow inside or outside\"          = \"787878\"\n",
    "dust        = (80, 80, 80)    #D-Gray   \"dust inside or outside\"            = \"505050\"\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "########################\n",
    "# (FOR HYDRAULICS) I used this labeles for the manually relabeled ones (by Farhad and Max) V3 training)\n",
    "# for next retrain round: 150, 100,  50 for fmInapp instead of 128, 0, 255\n",
    "# There is inapp in this color too .128,   0, 255\n",
    "\n",
    "rockInside  = (0, 0, 255)     #blue     \"rock_inside\"      = \"0000FF\"\n",
    "fineInside  = (0, 255, 0)     #green    \"fine_inside\"      = \"00FF00\"\n",
    "emptyInside = (255, 255, 0)   #yellow   \"empty\"            = \"FFFF00\"\n",
    "wmInside    = (255, 100, 100) #L-Pink   \"wm_landmarks\"     = \"FF6464\"\n",
    "inapInside  = (150, 100,  50)   #L-Brown  \"inapp_For_FM\"     = \"966432\"\n",
    "\n",
    "\n",
    "teeth       = (255,   0, 255) #pink     \"teeth\"            = \"FF00FF\"\n",
    "case        = (255, 0, 0)     #red      \"case\"             = \"FF0000\"\n",
    "truck       = (255, 255, 200) #cream    \"truck\"            = \"FFFFC8\"\n",
    "sheave      = (255, 128, 0)   #Orage    \"Sheave\"           = \"FF8000\"\n",
    "cable       = (0 , 0, 0)      #black    \"Cable\"            = \"000000\"\n",
    "\n",
    "rockOutside = (128, 0, 255)   #purple    \"rock_outside\"    = \"8000FF\"\n",
    "fineOutside = (0, 255, 255)   #cyan      \"fine_outside\"     = \"00FFFF\"\n",
    "\n",
    "void        = (180, 50, 50)   #Brown    \"void anything not in this labels\"  = \"B43232\"\n",
    "shadow      = (120, 120, 120) #gray     \"shadow inside or outside\"          = \"787878\"\n",
    "dust        = (80, 80, 80)    #D-Gray   \"dust inside or outside\"            = \"505050\"\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "# (FOR CABLE)\n",
    "truck       = (255, 255, 200) #cream    \"truck\"            = \"FFFFC8\"\n",
    "case        = (255, 0, 0)     #red      \"case\"             = \"FF0000\"\n",
    "cable       = (0 , 0, 0)      #black    \"Cable\"            = \"000000\"\n",
    "\n",
    "sheave      = (255, 128, 0)   #Orage    \"Sheave\"           = \"FF8000\"\n",
    "teeth       = (255,   0, 255) #pink     \"teeth\"            = \"FF00FF\"\n",
    "fmInapp     = (128, 0, 255)   #purple   \"fine_inside\"      = \"8000FF\"\n",
    "fineInside  = (0, 255, 0)   #green   \"fine_inside\"      = \"00FF00\"\n",
    "emptyInside = (255, 255, 0)   #yellow   \"empty\"            = \"FFFF00\"\n",
    "wmInside    = (255, 100, 100) #L-Pink   \"wm_landmarks\"     = \"FF6464\"\n",
    "dust        = (80, 80, 80, 100)    #D-Gray   \"dust inside or outside\"            = \"505050\"\n",
    "rockInside  = (0, 0, 255, 100)     #blue     \"rock_inside\"      = \"0000FF\"\n",
    "wmInapp  = (150, 100, 50,100)   #L-Brown  \"inapp_For_WM\"     = \"966432\"\n",
    "shadow      = (120, 120, 120) #gray     \"shadow inside or outside\"          = \"787878\"\n",
    "background = (0, 255, 255)   #cyan      \"fine_outside\"     = \"00FFFF\"\n",
    "\n",
    "void        = (180, 50, 50)   #Brown    \"void anything not in this labels\"  = \"B43232\"\n",
    "'''\n",
    "\n",
    "\n",
    "# (FOR Backhoe)\n",
    "emptyInside = (255, 255, 0)   #yellow   \"empty\"            = \"FFFF00\"\n",
    "case        = (255, 0, 0)     #red      \"case\"             = \"FF0000\"\n",
    "teeth       = (255,   0, 255) #pink     \"teeth\"            = \"FF00FF\"\n",
    "bucketOutside = (0, 80, 50)     # = \"005032\"\n",
    "\n",
    "cable       = (0 , 0, 0)      #black    \"Cable\"            = \"000000\"\n",
    "shadow      = (120, 120, 120) #gray     \"shadow inside or outside\"          = \"787878\"\n",
    "backGround = (0, 255, 255)   #cyan      \"fine_outside\"     = \"00FFFF\"\n",
    "\n",
    "rockInside  = (0, 0, 255)     #blue     \"rock_inside\"      = \"0000FF\"\n",
    "fineInside  = (0, 255, 0)     #green    \"fine_inside\"      = \"00FF00\"\n",
    "fmInapp = (128, 0, 255)   #purple    \"rock_outside\"    = \"8000FF\"\n",
    "\n",
    "wmInapp = (150, 100,50)\n",
    "wm = (255,100,100)\n",
    "\n",
    "wmInside    = (255, 100, 100) #L-Pink   \"wm_landmarks\"     = \"FF6464\"\n",
    "inapInside  = (150, 100, 50)   #L-Brown  \"inapp_For_FM\"     = \"966432\"\n",
    "\n",
    "sheave      = (255, 128, 0)   #Orage    \"Sheave\"           = \"FF8000\"\n",
    "truck       = (255, 255, 200) #cream    \"truck\"            = \"FFFFC8\"\n",
    "\n",
    "dust = (80,80,80)\n",
    "'''\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font color='blue'/> Data Exploration Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Images: Copying, Moving, Deleting from different directoreis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# deleting files that are not in one dir from another\n",
    "fileToKeepDict = {}\n",
    "\n",
    "for fileName in os.listdir('/home/hooman/Downloads/MOTIONMETRICS (2)/FM/preds/'):\n",
    "    fileToKeepDict[fileName[:-3]+'gmp'] = 1\n",
    "\n",
    "\n",
    "    \n",
    "for fileName in os.listdir('/home/hooman/Downloads/MOTIONMETRICS (2)/FM/1947EFC0-16D8-1588-A042-3534DFB3FA0F/'):\n",
    "    if fileName not in fileToKeepDict:\n",
    "        print(fileName)\n",
    "        os.remove('/home/hooman/Downloads/MOTIONMETRICS (2)/FM/1947EFC0-16D8-1588-A042-3534DFB3FA0F/' + fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# deleting images that cannot be opened (usaully after augmentation)\n",
    "dirToDeleteFrom = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/randomCroppedImages/'\n",
    "\n",
    "for fileName in os.listdir(dirToDeleteFrom):\n",
    "    try:\n",
    "        img = imread(dirToDeleteFrom + fileName)\n",
    "    except:\n",
    "        os.remove(dirToDeleteFrom + fileName)\n",
    "        os.remove('/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/randomCroppedMasks/' + fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# copying files from one dir to another\n",
    "\n",
    "import shutil\n",
    "\n",
    "for imgId in os.listdir('/home/hooman/WM_PROJECT/dataPreparation/hsTrainingData/optical/hydraulics/jiraIssues_BOTH-teethAndWm_OpticalHydraulic/image_brokenDownByShovelType/Chador/imagesWithBadLabels'):\n",
    "    shutil.copy('/home/hooman/WM_PROJECT/dataPreparation/hsTrainingData/optical/hydraulics/jiraIssues_BOTH-teethAndWm_OpticalHydraulic/images_all/' + imgId, '/home/hooman/WM_PROJECT/dataPreparation/hsTrainingData/optical/hydraulics/jiraIssues_BOTH-teethAndWm_OpticalHydraulic/testSet_notIncludedIntrainingSets_imagesWithBadLabels_fromBrokenDownByImageType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Exclusing testSet images from trainingSet for BucketTracking\n",
    "# copying files from one dir to another\n",
    "\n",
    "dirWithListOfimages = \"/media/hooman/hsSsdPartUbuntu/FM_PROJECT/FMDL_3.1/cable/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_cable__try1/goodMatInsides_forBBLabelingOfYolo/\"\n",
    "\n",
    "dir2RemoveFrom = \"/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/cable/fmdl-cable-trainingData/images/\"\n",
    "\n",
    "\n",
    "import shutil\n",
    "\n",
    "movedLabels = []\n",
    "\n",
    "for imgId in os.listdir(dirWithListOfimages):\n",
    "    \n",
    "    movedLabels.append(imgId)\n",
    "\n",
    "    imgName = imgId.replace('.jpg', '.xml')\n",
    "    \n",
    "    \n",
    "    if os.path.isfile(dir2RemoveFrom + imgId):\n",
    "    #if os.path.isfile(dir2RemoveFrom + imgName):\n",
    "    \n",
    "        #shutil.move(dir2RemoveFrom + imgName, '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/cable/validationsSet_hsPicked_labels')\n",
    "        \n",
    "        shutil.copy(dir2RemoveFrom + imgId, '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/FMDL_3.1/cable/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_cable__try1/temp')\n",
    "    \n",
    "        #os.remove(dir2RemoveFrom + imgId)\n",
    "        #os.remove(dir2RemoveFrom + imgName)\n",
    "        print(dir2RemoveFrom + imgName)\n",
    "        \n",
    "    \n",
    "print(\"\")\n",
    "print(\"Moved labels and deleted images for  \" + str(len(movedLabels))  + \"  examples\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Images: resizing, converting formats and channels, correcting ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Resize and downsample all images to (128, 160, 3)\n",
    "resizedImagesPath = '/home/hooman/dataPreparation/hsTestSet/images0PaddedForUNet/'\n",
    "\n",
    "for fileName in os.listdir(imagesPath):\n",
    "\n",
    "    img = imread(imagesPath + fileName) \n",
    "    \n",
    "    imgResized = cv2.resize(img, (640, 480)) \n",
    "\n",
    "    # you can downsample with numpy too. I use opencv to be consistant.    imgDs = img[::4, ::4, :]\n",
    "    imgDs = cv2.resize(imgResized, (0,0), fx=0.25, fy=0.25) \n",
    "\n",
    "    imgPadded = cv2.copyMakeBorder(imgDs,4,4,0,0,cv2.BORDER_CONSTANT,value=(0,0,0))\n",
    "    \n",
    "    cv2.imwrite(resizedImagesPath + fileName, imgPadded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# converting single channel images to 3 channels\n",
    "for imId in os.listdir('/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/cable/temp/'):\n",
    "\n",
    "    img = imread('/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/cable/temp/'+ imId)\n",
    "    if len(img.shape) < 3:\n",
    "        img3Chan = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "        cv2.imwrite('/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/cable/hsTestSetOfHardImages/' + imId, img3Chan)\n",
    "        \n",
    "    else:\n",
    "        print(img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Converting jpg image to png, and removing the jpegs\n",
    "img_dest_dir = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/allImages/'\n",
    "\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "imageFileNameDic = {}\n",
    "\n",
    "for file in os.listdir(img_dest_dir):\n",
    "    fileName = file.replace(\".jpg\", \"\")\n",
    "    #fileName = file.replace(\".png\", \"\")\n",
    "    if fileName in imageFileNameDic:\n",
    "        imageFileNameDic[fileName] += 1\n",
    "    else:\n",
    "        imageFileNameDic[fileName] = 0\n",
    "\n",
    "        \n",
    "        \n",
    "for name in imageFileNameDic.keys():\n",
    "    print(name)\n",
    "    im = Image.open(img_dest_dir + '/' + name + '.jpg')\n",
    "    im.save(img_dest_dir + '/' + name + '.png')\n",
    "    os.remove(img_dest_dir + '/' + name + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# converting single channel images to 3 channels\n",
    "for imId in os.listdir('/media/hooman/New Volume/FM_PROJECT_STORAGE/QC-Tests/backhoe/Telfer_EX010_2/Frame/'):\n",
    "\n",
    "    img = imread('/media/hooman/New Volume/FM_PROJECT_STORAGE/QC-Tests/backhoe/Telfer_EX010_2/Frame/'+ imId)\n",
    "    img3Chan = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    cv2.imwrite('/media/hooman/New Volume/FM_PROJECT_STORAGE/QC-Tests/backhoe/Telfer_EX010_2/3chan/' + imId, img3Chan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# compressing png images with jpeg\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "saveDir = '/home/hooman/FM_PROJECT/dataPreparation/fmdlTestData-optical-hydraulic/compressedJpeg80/'\n",
    "\n",
    "for imId in os.listdir('/home/hooman/FM_PROJECT/dataPreparation/fmdlTestData-optical-hydraulic/Frame/'):\n",
    "    img = Image.open('/home/hooman/FM_PROJECT/dataPreparation/fmdlTestData-optical-hydraulic/Frame/'+ imId)\n",
    "    \n",
    "    fileName = imId.replace(\".png\", \"\")\n",
    "    \n",
    "    img.save(saveDir + '/' + fileName + '.jpg', quality=80,optimize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Correcting image Ids by content matching singleImage\n",
    "#HSNOTE: this does not work with abs error must be squared.\n",
    "\n",
    "pathToCorrectNames = '/home/hooman/dataPreparation/testingMahdisNetworkOnMyLatestTestSetForComparison/input-orig/'\n",
    "pathToWrongNames   = '/home/hooman/dataPreparation/testingMahdisNetworkOnMyLatestTestSetForComparison/outputOfSaveH5/'\n",
    "pathToWrongPreds = '/home/hooman/dataPreparation/testingMahdisNetworkOnMyLatestTestSetForComparison/ouputOfNetworkJustOutput/'\n",
    "\n",
    "\n",
    "for srcId in os.listdir(pathToWrongNames):\n",
    "\n",
    "    minScore = 100000000\n",
    "    minId = ''\n",
    "    \n",
    "    for targId in os.listdir(pathToCorrectNames):\n",
    "        srcIm = imread(pathToWrongNames + srcId)\n",
    "\n",
    "        temp= imread(pathToCorrectNames + targId)\n",
    "        targIm = cv2.resize(temp, (srcIm.shape[1], srcIm.shape[0])) \n",
    "\n",
    "        dif = np.square((srcIm - targIm))\n",
    "        score = np.sum(dif)\n",
    "\n",
    "        if score < minScore:\n",
    "            minScore = score\n",
    "            minId = targId\n",
    "            \n",
    "\n",
    "    print(\"src: \" + srcId + \"  matched with: \" + minId)\n",
    "    os.rename(pathToWrongNames + srcId, pathToWrongNames + minId)\n",
    "    os.rename(pathToWrongPreds + srcId, pathToWrongPreds + minId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Correcting image Ids by content matching allChannels\n",
    "\n",
    "\n",
    "pathToCorrectNames = '/home/hooman/dataPreparation/testingMahdisNetworkOnMyLatestTestSetForComparison/input-orig/'\n",
    "pathToWrongNames   = '/home/hooman/dataPreparation/testingMahdisNetworkOnMyLatestTestSetForComparison/outputOfSaveH5/'\n",
    "\n",
    "pathToCorrectNamesIn = '/home/hooman/dataPreparation/testingMahdisNetworkOnMyLatestTestSetForComparison/ouputOfNetworkAllChannels/' \n",
    "\n",
    "namesDic = {}\n",
    "for srcId in os.listdir(pathToWrongNames):\n",
    "\n",
    "    minScore = 100000000\n",
    "    minId = ''\n",
    "    \n",
    "    for targId in os.listdir(pathToCorrectNames):\n",
    "        srcIm = imread(pathToWrongNames + srcId)\n",
    "\n",
    "        temp= imread(pathToCorrectNames + targId)\n",
    "        targIm = cv2.resize(temp, (srcIm.shape[1], srcIm.shape[0])) \n",
    "\n",
    "        dif = np.square((srcIm - targIm))\n",
    "        score = np.sum(dif)\n",
    "\n",
    "        if score < minScore:\n",
    "            minScore = score\n",
    "            minId = targId\n",
    "            \n",
    "    print(srcId + \"___\" + minId)\n",
    "    namesDic[srcId] = minId\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import glob\n",
    "\n",
    "for srcId in namesDic.keys():\n",
    "\n",
    "    #print(\"src: \" + srcId + \"  matched with: \" + minId)\n",
    "    \n",
    "    nameAr = srcId.split('_')\n",
    "    nameAr = nameAr[0:2]\n",
    "\n",
    "    shortName = \"\"\n",
    "    for i in range(len(nameAr)):\n",
    "        shortName = shortName + nameAr[i] + '_'\n",
    "\n",
    "    chanFiles = glob.glob1(pathToCorrectNamesIn, shortName + '*')\n",
    "    \n",
    "    for fil in chanFiles:\n",
    "        chan = fil.split('_')[2]\n",
    "        #print(chan)\n",
    "        \n",
    "        if chan[0:2] == \"ch\":\n",
    "            newname = chan + \"_\" + namesDic[srcId]\n",
    "            print(\"renamed CH: \" + fil + \" to: \" + newname + \"\\n\")\n",
    "            os.rename(pathToCorrectNamesIn + fil, pathToCorrectNamesIn + newname)\n",
    "        else:\n",
    "            newname = namesDic[srcId]\n",
    "            print(\"renamed: \" + fil + \" to: \" + newname + \"\\n\")\n",
    "            os.rename(pathToCorrectNamesIn + fil, pathToCorrectNamesIn + namesDic[srcId])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Images: Displaying side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Showing Images side-by-side\n",
    "\n",
    "\n",
    "#predsDir1 = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/try0-AnuarConfigs/image_hard_pickedByHs_predicted_Anuars_model/'\n",
    "\n",
    "predsDir1 = '/media/hooman/New Volume/FM_PROJECT_STORAGE/QC-Tests/backhoe/Telfer-May10th-byHs/preds_currentUNet/'\n",
    "\n",
    "\n",
    "predsDir2 = '/media/hooman/New Volume/FM_PROJECT_STORAGE/QC-Tests/backhoe/Telfer-May10th-byHs/pres_unet2/'\n",
    "\n",
    "dirToSaveResults = '/media/hooman/New Volume/FM_PROJECT_STORAGE/QC-Tests/backhoe/Telfer-May10th-byHs/combined_unets1and2/'\n",
    "\n",
    "for imgId in os.listdir(predsDir1):    \n",
    "    pred1 = imread(predsDir1 + imgId)\n",
    "    pred2 = imread(predsDir2 + imgId)\n",
    "\n",
    "    try:\n",
    "        \n",
    "        \n",
    "        combImg = np.zeros((pred1.shape[0],1400, 3), np.uint8)\n",
    "\n",
    "        combImg[:, 0:pred1.shape[1], :] = pred1\n",
    "        combImg[:, 700:pred2.shape[1]+700, :] = pred2\n",
    "        \n",
    "        '''\n",
    "        combImg = np.zeros((pred1.shape[0],1400), np.uint8)\n",
    "\n",
    "        combImg[:, 0:pred1.shape[1]] = pred1\n",
    "        combImg[:, 700:pred2.shape[1]+700] = pred2\n",
    "        '''\n",
    "\n",
    "            \n",
    "            \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(combImg,'currentUNET',(30,70), font, 2,(255,255,255), 2, 0)\n",
    "        cv2.putText(combImg,'UNET2',(730,70), font, 2,(255,255,255), 2, 0)\n",
    "       \n",
    "\n",
    "        #plt.imshow(combImg)\n",
    "        #plt.show()\n",
    "        #break\n",
    "\n",
    "        cv2.imwrite(dirToSaveResults + imgId, combImg)\n",
    "    except:\n",
    "        print(imgId)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Showing Images side-by-side for 1280*1280 image sizes \n",
    "\n",
    "\n",
    "#predsDir1 = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/try0-AnuarConfigs/image_hard_pickedByHs_predicted_Anuars_model/'\n",
    "\n",
    "predsDir1 = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/try5-NewTrainingProcedure--higherBatchSize/preds_onBackgroundImages/'\n",
    "\n",
    "\n",
    "predsDir2 = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/try11_sameAs5_afterDataCorrections/preds_onBackground/'\n",
    "\n",
    "dirToSaveResults = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/try11_sameAs5_afterDataCorrections/combined_try5Vs11_backgroundImages/'\n",
    "\n",
    "for imgId in os.listdir(predsDir1):\n",
    "    #hsPred = imread(hsPredsDir + imgId)\n",
    "    #temp = imread(vesPredsDir + imgId)\n",
    "    #vesPred = img3Chan = cv2.cvtColor(temp, cv2.COLOR_GRAY2BGR) \n",
    "    \n",
    "    pred1 = imread(predsDir1 + imgId)\n",
    "    pred2 = imread(predsDir2 + imgId)\n",
    "\n",
    "    combImg = np.zeros((pred1.shape[0],2560, 3), np.uint8)\n",
    "\n",
    "    combImg[:, 0:pred1.shape[1], :] = pred1\n",
    "    combImg[:, 1280:pred2.shape[1]+1280, :] = pred2\n",
    "    \n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(combImg,'try5',(30,70), font, 2,(255,255,255), 2, 0)\n",
    "    cv2.putText(combImg,'try11',(730,70), font, 2,(255,255,255), 2, 0)\n",
    "    \n",
    "    #plt.imshow(combImg)\n",
    "    #plt.show()\n",
    "    #break\n",
    "    \n",
    "    cv2.imwrite(dirToSaveResults + imgId, combImg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Putting the optical flow and U-Net outputs sidebyside.  \n",
    "\n",
    "#FMDL_2018.04.30_11.38.09.png\n",
    "\n",
    "temp = imread('/home/hooman/dataPreparation/fmdlTestData-optical-hydraulic/Frame/' + 'FMDL_2018.04.30_11.38.09.png')\n",
    "\n",
    "frame = cv2.cvtColor(temp, cv2.COLOR_GRAY2BGR) \n",
    "\n",
    "plt.imshow(frame)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "of = imread('/home/hooman/dataPreparation/fmdlTestData-optical-hydraulic/OpticalFlowMagnitude/' + 'FMDL_2018.04.30_11.38.09.png')\n",
    "\n",
    "plt.imshow(of)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "no = imread('/home/hooman/dataPreparation/fmdlTestData-optical-hydraulic/NetOut/' + 'FMDL_2018.04.30_11.38.09.png')\n",
    "\n",
    "plt.imshow(no)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "temp2 = imread('/home/hooman/dataPreparation/fmdlTestData-optical-hydraulic/VES_finalOutput/fragmentation_results/all/' + 'FMDL_2018.04.30_11.38.09.png')\n",
    "\n",
    "fo = cv2.cvtColor(temp2, cv2.COLOR_GRAY2BGR) \n",
    "\n",
    "plt.imshow(fo)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(np.amax(of))\n",
    "\n",
    "\n",
    "combImg = np.zeros((frame.shape[0],2800, 3), np.uint8)\n",
    "\n",
    "combImg[:, 0:frame.shape[1], :] = frame\n",
    "combImg[:, 700:frame.shape[1]+700, :] = cv2.resize(cv2.cvtColor(of, cv2.COLOR_GRAY2BGR), (frame.shape[1], frame.shape[0])) \n",
    "combImg[:, 1400:frame.shape[1]+1400, :] = cv2.resize(cv2.cvtColor(no, cv2.COLOR_GRAY2BGR), (frame.shape[1], frame.shape[0])) \n",
    "combImg[:, 2100:fo.shape[1]+2100, :] = fo\n",
    "\n",
    "\n",
    "plt.imshow(combImg)\n",
    "plt.show()\n",
    "cv2.imwrite('/home/hooman/' + 'combined_FMDL_2018.04.30_11.38.09.png', combImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Converting legecy fm/wm and fontend stuff to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# converting .GMP to .FMDL\n",
    "import os\n",
    "import glob\n",
    "import base64\n",
    "\n",
    "\n",
    "parentInputPath = \"/media/hooman/New Volume/FM_PROJECT_STORAGE/QC-Tests/backhoe/Telfer-May10th-byHs/MOTIONMETRICS/FM/62A358A0-720F-1A2F-875E-0B03B1CF22B7/\"\n",
    "\n",
    "outputPath = \"/media/hooman/New Volume/FM_PROJECT_STORAGE/QC-Tests/backhoe/Telfer-May10th-byHs/frames/\"\n",
    "\n",
    "#for dires in os.listdir(parentInputPath):\n",
    " #   inputPath = parentInputPath + '/' + dires + '/'\n",
    "    \n",
    "    #files = glob.glob(inputPath+'*.gmp')\n",
    "\n",
    "for filename in os.listdir(parentInputPath):\n",
    "\n",
    "    print(filename)\n",
    "\n",
    "    f = open(parentInputPath + filename,'r')\n",
    "\n",
    "    text = f.read()\n",
    "\n",
    "    outFileName = text[text.find(\"filename\")+11:text.find(\"data\") -3]\n",
    "    print(outFileName)\n",
    "\n",
    "    if (text.find(\"FMDL\") > 0) & (text.find(\"FMDL\") < text.find(\"data\")):\n",
    "\n",
    "        img_txt = text[text.find(\"data\")+7:-4];\n",
    "        print(img_txt)\n",
    "\n",
    "        with open(outputPath+outFileName,\"wb\") as ff:\n",
    "\n",
    "            ff.write(base64.b64decode(img_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# YAML to WMDL\n",
    "\n",
    "import glob\n",
    "from base64 import decodestring\n",
    "import base64\n",
    "\n",
    "\n",
    "import zlib\n",
    "import yaml\n",
    "filename = \"C:/Software/Dev/DLWM-20171026-105/resources/CNRL/SH1006/DLWM_reference.yaml\"\n",
    "with open(filename, 'r') as stream:\n",
    "    yamlfile = yaml.load(stream)\n",
    "    \n",
    "stream = open(filename, 'r')\n",
    "\n",
    "import cv2\n",
    "fs_read = cv2.FileStorage(\"D:/temp/test.yml\", cv2.FILE_STORAGE_READ)\n",
    "import yaml\n",
    "filename = \"D:/temp/test.yml\"\n",
    "with open(filename, 'r') as stream:\n",
    "    yamlfile = yaml.load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#WMDL to YAML\n",
    "import glob\n",
    "from base64 import decodestring\n",
    "import base64\n",
    "\n",
    "inputPath = \"C:/Software/Dev/DLWM-20180201/resources/Test/SH7106/CV/input/\"\n",
    "outputPath = \"C:/Software/Dev/DLWM-20180201/resources/Test/SH7106/CV/yaml/\"\n",
    "files = glob.glob(inputPath+'*.wmdl')\n",
    "import zlib  \n",
    "import os\n",
    "for filename in files:\n",
    "    wmdl = open(filename,'rb').read()\n",
    "    wmyaml = zlib.decompress(wmdl)\n",
    "    with open(outputPath+os.path.basename(filename)[:-5]+\".yaml\",\"wb\") as f:\n",
    "        f.write(wmyaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#WMDL GMP            \n",
    "import glob\n",
    "from base64 import decodestring\n",
    "import base64\n",
    "\n",
    "inputPath = \"N:/randd/temp/WMDL_Logs/WMDL_CVE_S20/\"\n",
    "outputPath = \"C:/Software/Dev/DLWM-20180201/resources/CV/SH20/input_2/\"\n",
    "files = glob.glob(inputPath+'*.gmp')\n",
    "for filename in files:\n",
    "    f = open(filename,'r')\n",
    "    text = f.read()\n",
    "    print(text[text.find(\"filename\")+11:text.find(\"data\")])\n",
    "    if (text.find(\"WMDL\") > 0) & (text.find(\"WMDL\") < text.find(\"data\")):\n",
    "        img_txt = text[text.find(\"data\")+7:-4];\n",
    "        with open(outputPath+text[text.find(\"filename\")+11:text.find(\".wmdl\")+5],\"wb\") as f:\n",
    "            f.write(base64.b64decode(img_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# MTDL GMP\n",
    "import glob\n",
    "import base64\n",
    "\n",
    "inputPath = \"N:/temp/MTDL-Sishen/PH03_4100/\"\n",
    "outputPath = \"N:/randd/MachineLearning/Temp/Sishen/PH03_4100/\"\n",
    "files = glob.glob(inputPath+'*.gmp')\n",
    "for filename in files:\n",
    "    f = open(filename,'r')\n",
    "    text = f.read()\n",
    "    if (text.find(\"MTDL-LEGACY\") > 0) & (text.find(\"MTDL-LEGACY\") < text.find(\"data\")):\n",
    "        img_txt = text[text.find(\"data\")+7:-4];\n",
    "        with open(outputPath+text[text.find(\"filename\")+13:text.find(\".jpg\")+4],\"wb\") as f:\n",
    "            f.write(base64.b64decode(img_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# hs Saving Frames from YAML\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "import yaml\n",
    "from PIL import Image as PilImage\n",
    "\n",
    "path2Yamls = '/media/hooman/New Volume/FM_PROJECT_STORAGE/QC-Tests/backhoe/FMDL_Telfer/FMDL_Telfer_7Hour30Min_Threshold0.4/yaml/'\n",
    "path2SaveFrames = '/media/hooman/New Volume/FM_PROJECT_STORAGE/QC-Tests/backhoe/FMDL_Telfer/FMDL_Telfer_7Hour30Min_Threshold0.4/frames/'\n",
    "\n",
    "\n",
    "for yaml_file_name in os.listdir(path2Yamls):\n",
    "    print(yaml_file_name + '\\n')\n",
    "    \n",
    "    # Read YAML file\n",
    "    with open(path2Yamls + yaml_file_name, 'r') as stream:\n",
    "        data_loaded = yaml.load(stream)\n",
    "    \n",
    "    #print(data_loaded['Frame'])\n",
    "\n",
    "    img_byteArray =  base64.b64decode(data_loaded['Frame'])\n",
    "    \n",
    "    image = PilImage.open(io.BytesIO(img_byteArray)).convert(\"RGB\")\n",
    "    image.save(path2SaveFrames + yaml_file_name.replace(\".yaml\", \".png\"),\"PNG\")\n",
    "\n",
    "    #plt.imshow(image)\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Cleaning up CSVs with bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# shuffling a csv  (adds an empty line somewhere, and moves the header)\n",
    "\n",
    "csvRows = readCsvRows('/media/hooman/hsSsdPartUbuntu/FM_PROJECT/FMDL_3.1/backhoe/boxDetector_V2_multiclass/try2-withCaseObject-newData/trainingSet.csv')\n",
    "\n",
    "\n",
    "\n",
    "# shuffle the rows\n",
    "from random import shuffle\n",
    "shuffle(csvRows)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#write the shuffled rows to csv\n",
    "csv_file = open('/media/hooman/hsSsdPartUbuntu/FM_PROJECT/FMDL_3.1/backhoe/boxDetector_V2_multiclass/try2-withCaseObject-newData/trainingSet_shuffled.csv', \"w\") \n",
    "\n",
    "\n",
    "# write rows\n",
    "for row in csvRows:\n",
    "    csv_file.write(row + '\\n')\n",
    "\n",
    "csv_file.close()\n",
    "\n",
    "print(\"wrote \" + str(len(csvRows)) + \" rows to csv file\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#read rows from the file you wanna append to\n",
    "existingRowsDic = getCertainClassRowsDictFromCsv('/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try5/trainSet_multiClass_bucket_fineRock_try5_manuallyCleaned.csv', ['matInside'])\n",
    "\n",
    "\n",
    "\n",
    "#read rows from the file you wanna get the new rows from\n",
    "rowsDicToAddFrom = getCertainClassRowsDictFromCsv('/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/unusedCsvFiles/trainSet_multiClass_bucket_fineRockInapp_try3_uncleaned.csv', ['matInside'])\n",
    "\n",
    "\n",
    "\n",
    "#Append the missing rows\n",
    "n = 0\n",
    "rowsDicToAddTo = {}\n",
    "for imId in os.listdir('/home/hooman/dataPreparation/hsTrainingSet/imsToAddMatInsideFor/'):\n",
    "    n += 1\n",
    "    print(imId)\n",
    "    if imId not in existingRowsDic:\n",
    "        if imId in rowsDicToAddFrom:\n",
    "            rowsDicToAddTo[imId] = rowsDicToAddFrom[imId]\n",
    "        else:\n",
    "            print(\"error didn't find:  \" + imId + \"\\n\")\n",
    "    else:\n",
    "        print(\"already there\\n\")\n",
    "\n",
    "print(\"processed \" + str(n) + \" rows\")\n",
    "\n",
    "writeRowDicToCsv(rowsDicToAddTo, '/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try4/trainSet_multiClass_bucket_fineRock_try4_manuallyCleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# delete images from csv\n",
    "imIdsToDelete = os.listdir('/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/cable/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_cable__try1/examplesToRemove/')\n",
    "\n",
    "csvToWorkWith = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/cable/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_cable__try1/firstTry_final.csv'\n",
    "\n",
    "\n",
    "existingRows = readCsvRows(csvToWorkWith)\n",
    "\n",
    "n1 = 0\n",
    "for row in existingRows:\n",
    "    vals = row.split(',')\n",
    "\n",
    "    if vals[0] not in imIdsToDelete:\n",
    "        existingRows.remove(row)\n",
    "        n1 += 1\n",
    "        \n",
    "print(\"in the first run deleted \" + str(n1) +' rows\\n')\n",
    "\n",
    "n2 = 0\n",
    "for row in existingRows:\n",
    "    vals = row.split(',')\n",
    "\n",
    "    if vals[0] not in imIdsToDelete:\n",
    "        existingRows.remove(row)\n",
    "        n2 += 1\n",
    "        \n",
    "print(\"in the second run deleted \" + str(n2) +' rows\\n')\n",
    "print(\"deleted \" + str(n1+n2) + \" rows in total\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# open the file\n",
    "csv_file = open(csvToWorkWith, \"w\") \n",
    "\n",
    "# define column names\n",
    "columnTitles = \"filename,pathname,xmins,xmax,ymins,ymax,class\\n\"\n",
    "csv_file.write(columnTitles)\n",
    "\n",
    "# write rows\n",
    "for r in existingRows:\n",
    "    row = r + '\\n'\n",
    "    csv_file.write(row)\n",
    "\n",
    "csv_file.close()\n",
    "\n",
    "print(\"wrote \" + str(len(existingRows)) + \" rows to csv file\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add no bucket rows to existing csv and shuffle its rows\n",
    "\n",
    "csvRows = readCsvRows('/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try5/trainSet_multiClass_bucket_fineRock_try5_manuallyCleaned.csv')\n",
    "\n",
    "#getRid of the empty row at the end\n",
    "csvRows = csvRows[0:len(csvRows)-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# add the no bucket rows for the images in dir\n",
    "for imId in os.listdir('/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try6/noShovelImagesToAdd/'):\n",
    "    newRow = str(str(imId) + ',' + str(imagesPath) + str(imId) + ',' + '' + ',' + '' + ',' + '' + ',' + '' + ',' + '')\n",
    "    print(newRow)\n",
    "    \n",
    "    csvRows.append(newRow)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# shuffle the rows\n",
    "from random import shuffle\n",
    "shuffle(csvRows)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#write the shuffled rows to csv\n",
    "csv_file = open('/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try5/trainSet_multiClass_bucket_fineRock_try5_manuallyCleaned_new.csv', \"w\") \n",
    "\n",
    "\n",
    "# write rows\n",
    "for row in csvRows:\n",
    "    csv_file.write(row + '\\n')\n",
    "\n",
    "csv_file.close()\n",
    "\n",
    "print(\"wrote \" + str(len(csvRows)) + \" rows to csv file\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# remove matInsideBoundary rows from CSV\n",
    "\n",
    "rowsDic = getCertainClassRowsDictFromCsv('/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/trainSet_bucketAndMatInsideBoundaries_allImages_BucAndPnH_cleaned.csv', ['bucket'])\n",
    "\n",
    "writeRowDicToCsv(rowsDic, '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/trainSet_justBucketBoundaries_allImages_BucAndPnH_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "source": [
    "## Converting existing network CSVs to out csv format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The CSVs produced by the existing networks provide the topLeft cornor's x value, yvalu, a width, and a height. This must be converted to the format used by us which provides top left and bottom right cornors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "existNetRows = readCsvRows(\"/home/hooman/resultsFromExistingNetwork/testSetFregmentationResults/output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "existNetRowsDict = {}\n",
    "for row in existNetRows[0:60]:\n",
    "    vals = row.split(',')\n",
    "    existNetRowsDict[vals[0]] = vals[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gt_rows = readCsvRows(\"/home/hooman/dataPreparation/testSet_noBbxImagesIncluded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#write rows\n",
    "rows = []\n",
    "for row in gt_rows[1:len(gt_rows)-1]:\n",
    "    vals = row.split(',')\n",
    "    fileName = vals[0]\n",
    "    filePath = imagesPath + fileName\n",
    "    print(\"processing file:\\n\", filePath)\n",
    "    \n",
    "    if fileName in existNetRowsDict:\n",
    "        topx, topy, width, height = existNetRowsDict[fileName]\n",
    "\n",
    "        (topx, topy, width, height) = (int(round(float(topx))), int(round(float(topy))), int(round(float(width))), int(round(float(height)))) \n",
    "\n",
    "        xmin = topx\n",
    "        xmax = topx + width\n",
    "        ymin = topy\n",
    "        ymax = topy + height\n",
    "        \n",
    "        row = fileName + \",\" + filePath + \",\" + str(xmin) +\",\"+ str(xmax) + \",\" + str(ymin) + \",\" + str(ymax) + \",\" + \"bucket\" + \"\\n\"\n",
    "        \n",
    "    else:\n",
    "        row = fileName + \",\" + filePath + \",\" + \"\" +\",\"+ \"\" + \",\" + \"\" + \",\" + \"\" + \",\" + \"bucket\" + \"\\n\"\n",
    "        print(\"Found no bucket boundary\\n\")\n",
    "        \n",
    "    rows.append(row)\n",
    "    \n",
    "print(\"processes \"+ str(len(rows)) + \" rows\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "writeRowsToCsv(rows, \"/home/hooman/resultsFromExistingNetwork/testSetFregmentationResults/testSetOutputConverted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Converting .pdn files to .png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#converting .pdn (dot net) to pnd\n",
    "\n",
    "import pypdn\n",
    "\n",
    "pdnsDir = \"/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/pdnLabels/\"\n",
    "finalDir = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/regen/'\n",
    "\n",
    "#fileName = '1_20161115-222501_0001n0_16697.pdn'\n",
    "for fileName in os.listdir(pdnsDir):\n",
    "\n",
    "    #read the layer info\n",
    "    layeredImage = pypdn.read(pdnsDir + fileName)\n",
    "    #print(layeredImage)\n",
    "\n",
    "\n",
    "    #make the background invisible\n",
    "    layer = layeredImage.layers[0]\n",
    "    layer.visible = False\n",
    "\n",
    "\n",
    "    #Combine the layers into a numpy image\n",
    "    flatImage = layeredImage.flatten(asByte=True)\n",
    "\n",
    "    #plt.figure()\n",
    "    #plt.imshow(flatImage)\n",
    "    #plt.show()\n",
    "\n",
    "    newFileName = fileName.replace('.pdn', '.png')\n",
    "    cv2.imwrite(finalDir + newFileName, flatImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## working with h5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#import skimage\n",
    "#from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "#from skimage import img_as_ubyte\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "#from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import h5py\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read an H5 file\n",
    "filename = 'C:\\\\Users\\\\hooman\\\\Desktop\\\\WM2.0Project\\\\oldOutputOfH5maker\\\\60x150_Synt_False_Norm_True_Enhance_False_HistEqu_False_HistNorm_False\\\\Test.h5'\n",
    "file = h5py.File(filename, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Reading and desplaying one image\n",
    "imgnb = 30\n",
    "\n",
    "for imgnb in range(23584):\n",
    "    image10 = list(file['data'][imgnb])\n",
    "    height10 = list(file['height'][imgnb])\n",
    "    label10 = list(file['label'][imgnb])\n",
    "    mask10 = list(file['mask'][imgnb])\n",
    "\n",
    "    img = cv2.cvtColor(image10[0], cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    print(len(img))\n",
    "    print(len(img[0]))\n",
    "\n",
    "    print(height10)\n",
    "    print(label10)\n",
    "    print(mask10)\n",
    "\n",
    "\n",
    "    cv2.circle(img,(30, int((1-height10[0])*150)), 2, (0,255,0), -1)\n",
    "    cv2.circle(img,(30, int((1-height10[1])*150)), 2, (0,0,255), -1)\n",
    "    cv2.circle(img,(30, int((1-height10[2])*150)), 2, (255,0,0), -1)\n",
    "    cv2.circle(img,(30, int((1-height10[3])*150)), 2, (255,255,0), -1)\n",
    "\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save an array of images into an h5 file\n",
    "outputH5Path = \"N:\\\\randd\\\\MachineLearning\\\\Projects\\\\ShovelMetrics\\\\Optical\\\\Dataset\\\\BucketPattern\\\\nLS_163_Backhoe\\\\WM_FM_TM_EMDUBUO_CACA\\\\h5\\\\Telfer_test_h5\\\\h5\\\\TestB.h5\"\n",
    "with h5py.File(outputH5Path, \"w\") as outputFile:\n",
    "    images = outputFile.create_dataset('data', (108,1,222,254), dtype='f')    \n",
    "    outputFile.flush()\n",
    "    \n",
    "    i = 0\n",
    "    for fImg in imgPyAr:\n",
    "        images[i, :, :, :]  = np.expand_dims(fImg[:,:, 0], axis=0)\n",
    "        \n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Writing just 100 of images to h5 file\n",
    "\n",
    "inputFile = h5py.File('C:\\\\Users\\\\hooman\\\\Desktop\\\\WM2.0Project\\\\h5MakerOutput_10-0\\\\60x150_Synt_False_Norm_True_Enhance_False_HistEqu_False_HistNorm_False\\\\Test.h5', 'r')\n",
    "\n",
    "with h5py.File('C:\\\\Users\\\\hooman\\\\Desktop\\\\WM2.0Project\\\\oldOutputOfH5maker\\\\reduced.h5', \"w\") as outputFile:\n",
    "    images = outputFile.create_dataset('data', (804828,1,150,60), dtype='f')\n",
    "    heights = outputFile.create_dataset('height', (804828,4), dtype='f')\n",
    "    labels = outputFile.create_dataset('label', (804828,4), dtype='f')\n",
    "    masks = outputFile.create_dataset('mask', (804828,4), dtype='f')\n",
    "    \n",
    "    outputFile.flush()\n",
    "    \n",
    "    i = 0\n",
    "    for imgnb in range(0,10000,50):\n",
    "        images[i]  = inputFile['data'][imgnb]\n",
    "        heights[i] = inputFile['height'][imgnb]\n",
    "        labels[i]  = inputFile['label'][imgnb]\n",
    "        masks[i]   = inputFile['mask'][imgnb]\n",
    "        \n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font color='red'>To combine multiple files into one use external links. h5 has the functionality that you can make external links to multiple files (no matter whre they are) inside one file. Your progrtams can then use that one file as if it has the entire data in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Legacy U-Net padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Identify top left and bottom right corners of an image with black margin\n",
    "\n",
    "\n",
    "for i in range(222) :\n",
    "    for j in range(254):\n",
    "        flag = False\n",
    "        if not img[i,j,:].all() == 0:\n",
    "            print(i)\n",
    "            print(j)\n",
    "            flag = True\n",
    "            break\n",
    "    if flag:\n",
    "        break\n",
    "        \n",
    "print(\"\\n\\n\\n\")        \n",
    "for i in reversed(range(222)) :\n",
    "    for j in reversed(range(254)):\n",
    "        flag = False\n",
    "        if not img[i,j,:].all() == 0:\n",
    "            print(i)\n",
    "            print(j)\n",
    "            flag = True\n",
    "            break\n",
    "    if flag:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# resize and pad a directory of images for unet\n",
    "\n",
    "input_dir = \"N:\\\\randd\\\\MachineLearning\\\\Projects\\\\ShovelMetrics\\\\Optical\\\\Dataset\\\\BucketPattern\\\\nLS_163_Backhoe\\\\WM_FM_TM_EMDUBUO_CACA\\\\h5\\\\Telfer_test_h5\\\\image\\\\\"\n",
    "imgPyAr = []\n",
    "\n",
    "for img_name in os.listdir(input_dir):\n",
    "    img = cv2.imread(input_dir + img_name)\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "\n",
    "    orig_h, orig_w, _ = img.shape\n",
    "    print('orig_h: ' + str(orig_h) + '\\norig_w: ' + str(orig_w))\n",
    "\n",
    "\n",
    "\n",
    "    resized_img = cv2.resize(img,(orig_w/4, orig_h/4))\n",
    "    #plt.imshow(resized_img)\n",
    "    #plt.show()\n",
    "\n",
    "    resized_h, resized_w, _ = resized_img.shape\n",
    "    print('resized_h: ' + str(resized_h) + '\\nresized_w: ' + str(resized_w))\n",
    "\n",
    "\n",
    "    final_h = 222\n",
    "    final_w = 254\n",
    "    margin_r = 49\n",
    "    margin_b = 57\n",
    "    final_img = np.zeros((final_h, final_w, 3),dtype = np.float32)\n",
    "    print(final_img.shape)\n",
    "    margin_l = final_w - margin_r - resized_w\n",
    "    margin_t = final_h - margin_b - resized_h\n",
    "    print('margin_l: ' + str(margin_l) + '\\nmargin_t: ' + str(margin_t))\n",
    "\n",
    "\n",
    "    final_img[margin_t:(final_h - margin_b), margin_l:(final_w - margin_r), :] = resized_img[:, :, :]/float(255)\n",
    "\n",
    "    #plt.imshow(final_img)\n",
    "    #plt.show()\n",
    "    imgPyAr.append(final_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Image Augmentation using imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get and resize train images and masks (same as in unet notebook except just one image)\n",
    "TRAIN_PATH = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameNetworkAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/finalTrainingSet_images_fullSize/'\n",
    "\n",
    "MASK_PATH  = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameNetworkAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/finalTrainingSet_masks_fullSize/'\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "train_ids = os.listdir(TRAIN_PATH)\n",
    "train_ids = train_ids[4:6]\n",
    "\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "\n",
    "for n, fileName in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    img = imread(TRAIN_PATH + fileName)[:,:,:IMG_CHANNELS]\n",
    "    \n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    \n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    \n",
    "    mask_ = imread(MASK_PATH + fileName )\n",
    "\n",
    "    #expand dim just converts the (h,w,) image to (h,w,1) look at above for experimentation with np.expand_dim\n",
    "    mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                  preserve_range=True), axis=-1)\n",
    "\n",
    "    #hs this in effect adds all the masks together into one mask of the same size.Since masks are bindary.\n",
    "    mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check if the data we just loaded looks all right\n",
    "ix = 0\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Generatign FM-FrameSelection Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Generatign FM-FrameSelection Plots\n",
    "\n",
    "allFramesDir = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/frameSelection/try7_t40b10_0,150,200,125,1,outSideImageObjRemoved/allFrames_1004_ESP_S04_017/'\n",
    "\n",
    "bufferedFramesDir = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/frameSelection/try7_t40b10_0,150,200,125,1,outSideImageObjRemoved/bufferedFrames_1004_ESP_S04_017/'\n",
    "\n",
    "selectedFramesDir = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/frameSelection/try7_t40b10_0,150,200,125,1,outSideImageObjRemoved/selectedFrames_1004_ESP_S04_017/'\n",
    "\n",
    "vidName = '1004_ESP_S04_017_fmSelection.png'\n",
    "\n",
    "savePath = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/frameSelection/try7_t40b10_0,150,200,125,1,outSideImageObjRemoved/'\n",
    "\n",
    "allFrames = []\n",
    "for imName in os.listdir(allFramesDir):\n",
    "    allFrames.append(int(imName.split('_')[-1][:-4]))\n",
    "    \n",
    "allFrames.sort()\n",
    "\n",
    "\n",
    "\n",
    "bufferedFrames = []\n",
    "for imName in os.listdir(bufferedFramesDir):\n",
    "    bufferedFrames.append(int(imName.split('_')[-1][:-4]))\n",
    "    \n",
    "bufferedFrames.sort()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "selectedFrames = []\n",
    "for imName in os.listdir(selectedFramesDir):\n",
    "    selectedFrames.append(int(imName.split('_')[-1][:-4]))\n",
    "    \n",
    "selectedFrames.sort()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30,5))\n",
    "ax = plt.axes()\n",
    "loc = plticker.MultipleLocator(base=1800.0)\n",
    "ax.xaxis.set_major_locator(loc)\n",
    "ax.grid()\n",
    "\n",
    "plt.plot(allFrames, len(allFrames) * [0], label='received')\n",
    "plt.plot(bufferedFrames, len(bufferedFrames) * [0.2], 'bo', label='buffered')\n",
    "plt.plot(selectedFrames, len(selectedFrames) * [0.5], 'go', label='selected')\n",
    "plt.ylabel('buffered=Blue,  Selected=Green')\n",
    "plt.xlabel('frameNumber(1 minute tick)')\n",
    "\n",
    "\n",
    "plt.savefig(savePath + vidName)\n",
    "plt.legend('best')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "\n",
    "hsDic = {'received': len(allFrames), 'buffered':len(bufferedFrames), 'selected':len(selectedFrames)}\n",
    "plt.bar(hsDic.keys(), hsDic.values(), color='g')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# library's example of mask augmentation\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "ia.seed(1)\n",
    "\n",
    "\n",
    "image = X_train[0]\n",
    "segmap = Y_train[0]\n",
    "segmap = ia.SegmentationMapOnImage(segmap, shape=image.shape, nb_classes=1+1)\n",
    "\n",
    "# Define our augmentation pipeline.\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Dropout([0.05, 0.2]),      # drop 5% or 20% of all pixels\n",
    "    iaa.Sharpen((0.0, 1.0)),       # sharpen the image\n",
    "    iaa.Affine(rotate=(-45, 45)),  # rotate by -45 to 45 degrees (affects heatmaps)\n",
    "    iaa.ElasticTransformation(alpha=50, sigma=5)  # apply water effect (affects heatmaps)\n",
    "], random_order=True)\n",
    "\n",
    "# Augment images and heatmaps.\n",
    "images_aug = []\n",
    "segmaps_aug = []\n",
    "for _ in range(5):\n",
    "    seq_det = seq.to_deterministic()\n",
    "    images_aug.append(seq_det.augment_image(image))\n",
    "    segmaps_aug.append(seq_det.augment_segmentation_maps([segmap])[0])\n",
    "\n",
    "# We want to generate an image of original input images and heatmaps before/after augmentation.\n",
    "# It is supposed to have five columns: (1) original image, (2) augmented image,\n",
    "# (3) augmented heatmap on top of augmented image, (4) augmented heatmap on its own in jet\n",
    "# color map, (5) augmented heatmap on its own in intensity colormap,\n",
    "# We now generate the cells of these columns.\n",
    "#\n",
    "# Note that we add a [0] after each heatmap draw command. That's because the heatmaps object\n",
    "# can contain many sub-heatmaps and hence we draw command returns a list of drawn sub-heatmaps.\n",
    "# We only used one sub-heatmap, so our lists always have one entry.\n",
    "cells = []\n",
    "for image_aug, segmap_aug in zip(images_aug, segmaps_aug):\n",
    "    cells.append(image)                                      # column 1\n",
    "    cells.append(segmap.draw_on_image(image))                # column 2\n",
    "    cells.append(image_aug)                                  # column 3\n",
    "    cells.append(segmap_aug.draw_on_image(image_aug))        # column 4\n",
    "    cells.append(segmap_aug.draw(size=image_aug.shape[:2]))  # column 5\n",
    "\n",
    "# Convert cells to grid image and save.\n",
    "grid_image = ia.draw_grid(cells, cols=5)\n",
    "imageio.imwrite(\"/home/hooman/sdc1Storage/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameNetworkAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/example_segmaps.jpg\", grid_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Hs example of mask augmentation\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "ia.seed(1)\n",
    "\n",
    "\n",
    "image = X_train[1]\n",
    "segmap = Y_train[1]\n",
    "segmap = ia.SegmentationMapOnImage(segmap, shape=image.shape, nb_classes=1+1)\n",
    "\n",
    "\n",
    "\n",
    "X_train_final_augmented = []\n",
    "Y_train_final_augmented= []\n",
    "\n",
    "\n",
    "cropAug = iaa.Sequential([\n",
    "    iaa.CropAndPad(\n",
    "    percent=(-0.3, 0.3),\n",
    "    pad_mode=[\"edge\"]),\n",
    "], random_order=False)\n",
    "\n",
    "\n",
    "scaleAug = iaa.Sequential([\n",
    "    iaa.Scale((0.5, 1.0)),\n",
    "], random_order=False)\n",
    "\n",
    "\n",
    "rotateAug = iaa.Sometimes(0.5, iaa.Affine(rotate=(-10, 10)))\n",
    "\n",
    "dropOutAug = iaa.Sometimes(0.5, iaa.Dropout([0.05, 0.1]))\n",
    "\n",
    "pixelValAddAug = iaa.Sometimes(0.5, iaa.Add((-40,40)))\n",
    "\n",
    "sharpenAug = iaa.Sometimes(0.2, iaa.Sharpen(alpha=(0.05, 0.2)))\n",
    "\n",
    "contrastNormAug = iaa.Sometimes(0.2, iaa.ContrastNormalization((0.5, 1.5)))\n",
    "\n",
    "\n",
    "    \n",
    "# X translation\n",
    "augResIm = iaa.Affine(translate_px={\"x\":-5}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"x\":-5}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "augResIm = iaa.Affine(translate_px={\"x\":-10}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"x\":-10}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "   \n",
    "augResIm = iaa.Affine(translate_px={\"x\":-15}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"x\":-15}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "augResIm = iaa.Affine(translate_px={\"x\":5}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"x\":5}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "   \n",
    "    \n",
    "augResIm = iaa.Affine(translate_px={\"x\":10}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"x\":10}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "augResIm = iaa.Affine(translate_px={\"x\":15}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"x\":15}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "\n",
    "# Y translation\n",
    "augResIm = iaa.Affine(translate_px={\"y\":5}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"y\":5}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "augResIm = iaa.Affine(translate_px={\"y\":10}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"y\":10}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "augResIm = iaa.Affine(translate_px={\"y\":15}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"y\":15}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "#horizantal flip\n",
    "augResIm = iaa.Fliplr(1).augment_image(image)\n",
    "augResMask = iaa.Fliplr(1).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "    \n",
    "#Random crop\n",
    "cropAug_det = cropAug.to_deterministic()\n",
    "augResIm = cropAug_det.augment_image(image)\n",
    "augResMask = cropAug_det.augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "\n",
    "#Random rotate or elastically transform\n",
    "rotateAug_det = rotateAug.to_deterministic()\n",
    "augResIm = rotateAug_det.augment_image(image)\n",
    "augResMask = rotateAug_det.augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "#drop some pixels at random 50% of the time\n",
    "dropOutAug_det = dropOutAug.to_deterministic()\n",
    "augResIm = dropOutAug_det.augment_image(image)\n",
    "augResMask = dropOutAug_det.augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "# add rand nb between -40,40 to some pixels 50% of the time \n",
    "pixelValAddAug_det = pixelValAddAug.to_deterministic()\n",
    "augResIm = pixelValAddAug_det.augment_image(image)\n",
    "augResMask = pixelValAddAug_det.augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "#sharpen images 20% of the time\n",
    "sharpenAug_det = sharpenAug.to_deterministic()\n",
    "augResIm = sharpenAug_det.augment_image(image)\n",
    "augResMask = sharpenAug_det.augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "#contrastNorm images 20% of the time\n",
    "contrastNormAug_det = contrastNormAug.to_deterministic()\n",
    "augResIm = contrastNormAug_det.augment_image(image)\n",
    "augResMask = contrastNormAug_det.augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "cells = []\n",
    "for image_aug, segmap_aug in zip(X_train_final_augmented, segmaps_aug):\n",
    "    imshow(image_aug)\n",
    "    plt.show()\n",
    "    imshow(np.squeeze(segmap_aug))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# hs list of all augmentations I've looked at\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Dropout([0.0, 0.2]),\n",
    "    iaa.Add((-40,40)),\n",
    "    iaa.AddElementwise((-10, 10)),\n",
    "    iaa.AdditiveGaussianNoise(scale=0.1*255),\n",
    "    iaa.GaussianBlur(sigma=1.0),\n",
    "    iaa.Sharpen(alpha=0.2),\n",
    "    iaa.ElasticTransformation(alpha=50, sigma=5),\n",
    "    iaa.Scale((0.5, 1.0)),\n",
    "    iaa.CropAndPad(\n",
    "    percent=(-0.3, 0.3),\n",
    "    pad_mode=[\"constant\"],\n",
    "    pad_cval=(0, 128)),\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.ContrastNormalization((0.5, 1.5)),\n",
    "    iaa.Affine(rotate=(-10, 10)),  # rotate by -10 to 10 degrees (affects heatmaps)\n",
    "    iaa.Affine(translate_px={\"x\":-5}),\n",
    "    iaa.Affine(translate_px={\"x\":-10}),\n",
    "    iaa.Affine(translate_px={\"x\":-15}),\n",
    "    iaa.Affine(translate_px={\"x\":5}),\n",
    "    iaa.Affine(translate_px={\"x\":10}),\n",
    "    iaa.Affine(translate_px={\"x\":15}),\n",
    "    iaa.Affine(translate_px={\"y\":5}),\n",
    "    iaa.Affine(translate_px={\"y\":10}),\n",
    "    iaa.Affine(translate_px={\"y\":15}),\n",
    "], random_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Adding external links to concatenate files\n",
    "\n",
    "import h5py\n",
    "\n",
    "outFile =  h5py.File('C:\\\\Users\\\\hooman\\\\Desktop\\\\WM2.0Project\\\\oldOutputOfH5maker\\\\combinedTrainingSetJustLinks.h5', \"a\")\n",
    "\n",
    "\n",
    "outFile['data'] = h5py.ExternalLink(\"C:\\\\Users\\\\hooman\\\\Desktop\\\\WM2.0Project\\\\h5MakerOutput_10-0\\\\60x150_Synt_False_Norm_True_Enhance_False_HistEqu_False_HistNorm_False\\\\Train.h5\", \"/data\")\n",
    "outFile['height'] = h5py.ExternalLink(\"C:\\\\Users\\\\hooman\\\\Desktop\\\\WM2.0Project\\\\h5MakerOutput_10-0\\\\60x150_Synt_False_Norm_True_Enhance_False_HistEqu_False_HistNorm_False\\\\Train.h5\", \"/height\")\n",
    "outFile['label'] = h5py.ExternalLink(\"C:\\\\Users\\\\hooman\\\\Desktop\\\\WM2.0Project\\\\h5MakerOutput_10-0\\\\60x150_Synt_False_Norm_True_Enhance_False_HistEqu_False_HistNorm_False\\\\Train.h5\", \"/label\")\n",
    "outFile['mask'] = h5py.ExternalLink(\"C:\\\\Users\\\\hooman\\\\Desktop\\\\WM2.0Project\\\\h5MakerOutput_10-0\\\\60x150_Synt_False_Norm_True_Enhance_False_HistEqu_False_HistNorm_False\\\\Train.h5\", \"/mask\")\n",
    "\n",
    "\n",
    "\n",
    "outFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font color='blue'/> FMDL Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Method Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sortLabelsDic(labelsDic, imgLabel, img=[]):\n",
    "\n",
    " #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "            \n",
    "    '''\n",
    "    if len(img) >0 :\n",
    "        print(sortedLabelColsDic)\n",
    "        print(\"\\n\")\n",
    "        print(sortedLabelRowsDic)\n",
    "        print(\"\\n\")\n",
    "    ''' \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ############## Bucket Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    \n",
    "    lowColValsTeeth = []\n",
    "    highColValsTeeth = []\n",
    "    for itemKey in sortedLabelColsDic.keys():\n",
    "        if itemKey == 'teethCols':\n",
    "            labV = sortedLabelColsDic[itemKey]\n",
    "            for v in labV:\n",
    "                lowColValsTeeth.append(v[0])\n",
    "                highColValsTeeth.append(v[len(v)-1])\n",
    "        \n",
    "        labV = sortedLabelColsDic[itemKey]\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    \n",
    "    lowRowValsTeeth = []\n",
    "    highRowValsTeeth = []\n",
    "    for itemKey in sortedLabelRowsDic.keys():\n",
    "        if itemKey == 'teethRows':\n",
    "            labV = sortedLabelRowsDic[itemKey]\n",
    "            for v in labV:\n",
    "                lowRowValsTeeth.append(v[0])\n",
    "                highRowValsTeeth.append(v[len(v)-1])\n",
    "\n",
    "        labV = sortedLabelRowsDic[itemKey]\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "\n",
    "    \n",
    "\n",
    "    #get the bucket boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    yminsTeeth = np.sort(np.array(lowRowValsTeeth))\n",
    "    ymaxsTeeth = np.sort(np.array(highRowValsTeeth))\n",
    "    \n",
    "    '''\n",
    "    print('lowColValsTeeth:')\n",
    "    print(lowColValsTeeth)\n",
    "    print('highColValsTeeth:')\n",
    "    print(highColValsTeeth)\n",
    "    \n",
    "    print('imageShape')\n",
    "    print(imgLabel.shape)\n",
    "    '''\n",
    "    \n",
    "    return xmins, xmaxs, ymins, ymaxs, yminsTeeth, ymaxsTeeth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getBucketBoundariesTooth2ToothV2(imgLabel, img=[]):\n",
    "\n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        \n",
    "                \n",
    "        '''\n",
    "        \n",
    "        #for Cable\n",
    "        'sheave'     :np.where(np.all(imgLabel == sheave, axis=-1)),\n",
    "        'teeth'     :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'fmInapp'     :np.where(np.all(imgLabel == fmInapp, axis=-1)),\n",
    "        'fineInside'     :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'emptyInside'     :np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'     :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'dust'     :np.where(np.all(imgLabel == dust, axis=-1)),\n",
    "        'rockInside'     :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'wmInapp'     :np.where(np.all(imgLabel == wmInapp, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1))\n",
    "        '''\n",
    "        \n",
    "        #for Hydraulics\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        'wmInapp':np.where(np.all(imgLabel == wmInapp, axis=-1)),\n",
    "        'fineInside2' : np.where(np.all(imgLabel == fineInside2, axis=-1))\n",
    "    }\n",
    "    \n",
    "    if len(img) >0 :\n",
    "        plt.imshow(imgLabel)\n",
    "        plt.show()\n",
    "        print(labelsDic)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "    xmins, xmaxs, ymins, ymaxs, yminsTeeth, ymaxsTeeth = sortLabelsDic(labelsDic, imgLabel, img)\n",
    "    \n",
    "          \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0:\n",
    "          \n",
    "        if len(yminsTeeth) > 0 and len(ymaxsTeeth) > 0 and (ymaxsTeeth[len(ymaxsTeeth)-1] - yminsTeeth[0]) > (0.5 * imgLabel.shape[1]):\n",
    "            boundariesDict['bucketInit'] = [xmins[0], xmaxs[len(xmaxs)-1], yminsTeeth[0], ymaxsTeeth[len(ymaxsTeeth)-1]]\n",
    "        \n",
    "        else:\n",
    "            boundariesDict['bucketInit'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1]]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    if 'bucketInit' in boundariesDict:\n",
    "        #(xmin, xmax, ymin, ymax) = boundariesDict['bucketInit']\n",
    "        #cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(255,0,0),3)\n",
    "        \n",
    "        bucketInitHeight = boundariesDict['bucketInit'][1] - boundariesDict['bucketInit'][0]\n",
    "        quart = int(boundariesDict['bucketInit'][0] + bucketInitHeight * 0.4)\n",
    "        \n",
    "        labelsDic2 = {\n",
    "            'fineInside_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == fineInside, axis=-1)),\n",
    "            'fineInside2_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == fineInside2, axis=-1)),\n",
    "            'inapInside_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == inapInside, axis=-1)),\n",
    "            'emptyInside_q':np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == emptyInside, axis=-1)),\n",
    "            'wmInside_q'   :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == wmInside, axis=-1)),\n",
    "            'teeth_q'      :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == teeth, axis=-1)),\n",
    "            'shadow_q'     :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == shadow, axis=-1)),\n",
    "            'wmInapp_q':np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == wmInapp, axis=-1)),\n",
    "            \n",
    "            'rockInside_q' : np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == rockInside, axis=-1)),\n",
    "            #'dust_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == dust, axis=-1)),\n",
    "            #'case_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == case, axis=-1)),\n",
    "        }\n",
    "        \n",
    "        \n",
    "        \n",
    "        xmins2, xmaxs2, ymins2, ymaxs2, yminsTeeth2, ymaxsTeeth2 = sortLabelsDic(labelsDic2, imgLabel, img)\n",
    "        \n",
    "        if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins2) > 0 and len(ymaxs2) > 0:\n",
    "\n",
    "            if len(yminsTeeth2) > 0 and len(ymaxsTeeth2) > 0 and (ymaxsTeeth2[len(ymaxsTeeth2)-1] - yminsTeeth2[0]) > (0.5 * imgLabel.shape[1]):\n",
    "                boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], yminsTeeth2[0], ymaxsTeeth2[len(ymaxsTeeth2)-1]]\n",
    "\n",
    "            else:\n",
    "                boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins2[0], ymaxs2[len(ymaxs2)-1]]\n",
    "        \n",
    "                \n",
    "\n",
    "        ##############################################\n",
    "        ######### Draw Boundaries if Verbose #########\n",
    "        ##############################################\n",
    "        if len(img) > 0:\n",
    "            print(boundariesDict)\n",
    "\n",
    "\n",
    "            #draw bucket boundaries\n",
    "            if 'bucket' in boundariesDict:\n",
    "                (xmin, xmax, ymin, ymax) = boundariesDict['bucket']\n",
    "                cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,255,255),3)\n",
    "\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getMatInsideBoundaries(imgLabel, img=[]):\n",
    "    '''\n",
    "    HS: \n",
    "    ---This method returs a list of boundaries: 1 matInside boundary (if present), which is combination of fineInside, rockInside and inappropritate.\n",
    "    '''\n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        #For Cable  FMDL3.1\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'fmInapp' :np.where(np.all(imgLabel == fmInapp, axis=-1)),\n",
    "\n",
    "        'dust' :np.where(np.all(imgLabel == dust, axis=-1)),\n",
    "        '''\n",
    "        \n",
    "        #For Hydraulics  FMDL3.1\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        \n",
    "        #with the new labels this is the new fmAppropriate mat\n",
    "        'fineInside2' :np.where(np.all(imgLabel == fineInside2, axis=-1))\n",
    "\n",
    "       \n",
    "    }\n",
    "    \n",
    "    if len(img) >0 :\n",
    "        plt.imshow(imgLabel)\n",
    "        plt.show()\n",
    "        print(labelsDic)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "    if len(img) >0 :\n",
    "        print(sortedLabelColsDic)\n",
    "        print(\"\\n\")\n",
    "        print(sortedLabelRowsDic)\n",
    "        print(\"\\n\")\n",
    "         \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ############## matInside Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    for labV in sortedLabelColsDic.values():\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    for labV in sortedLabelRowsDic.values():\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0 : \n",
    "        boundariesDict['matInside'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1]]\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "                \n",
    "\n",
    "    ##############################################\n",
    "    ######### Draw Boundaries if Verbose #########\n",
    "    ##############################################\n",
    "    if len(img) > 0:\n",
    "        print(boundariesDict)\n",
    "        \n",
    "        \n",
    "        #draw boundaries\n",
    "        if 'matInside' in boundariesDict:\n",
    "            (xmin, xmax, ymin, ymax) = boundariesDict['matInside']\n",
    "            cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,0,255),3)\n",
    "        \n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getBucketBoundariesTooth2Tooth(imgLabel, img=[]):\n",
    "\n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        'wmInapp':np.where(np.all(imgLabel == wmInapp, axis=-1)),\n",
    "        'fineInside2' : np.where(np.all(imgLabel == fineInside2, axis=-1)),\n",
    "        \n",
    "        #for Bucyrus\n",
    "        #'sheave'     :np.where(np.all(imgLabel == sheave, axis=-1)),\n",
    "        #'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "    }\n",
    "    \n",
    "    if len(img) >0 :\n",
    "        plt.imshow(imgLabel)\n",
    "        plt.show()\n",
    "        print(labelsDic)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "    if len(img) >0 :\n",
    "        print(sortedLabelColsDic)\n",
    "        print(\"\\n\")\n",
    "        print(sortedLabelRowsDic)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ############## Bucket Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    \n",
    "    lowColValsTeeth = []\n",
    "    highColValsTeeth = []\n",
    "    for itemKey in sortedLabelColsDic.keys():\n",
    "        if itemKey == 'teethCols':\n",
    "            labV = sortedLabelColsDic[itemKey]\n",
    "            for v in labV:\n",
    "                lowColValsTeeth.append(v[0])\n",
    "                highColValsTeeth.append(v[len(v)-1])\n",
    "        \n",
    "        labV = sortedLabelColsDic[itemKey]\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    \n",
    "    lowRowValsTeeth = []\n",
    "    highRowValsTeeth = []\n",
    "    for itemKey in sortedLabelRowsDic.keys():\n",
    "        if itemKey == 'teethRows':\n",
    "            labV = sortedLabelRowsDic[itemKey]\n",
    "            for v in labV:\n",
    "                lowRowValsTeeth.append(v[0])\n",
    "                highRowValsTeeth.append(v[len(v)-1])\n",
    "\n",
    "        labV = sortedLabelRowsDic[itemKey]\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "\n",
    "    \n",
    "\n",
    "    #get the bucket boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    yminsTeeth = np.sort(np.array(lowRowValsTeeth))\n",
    "    ymaxsTeeth = np.sort(np.array(highRowValsTeeth))\n",
    "    \n",
    "    print('lowColValsTeeth:')\n",
    "    print(lowColValsTeeth)\n",
    "    print('highColValsTeeth:')\n",
    "    print(highColValsTeeth)\n",
    "    \n",
    "    print('imageShape')\n",
    "    print(imgLabel.shape)\n",
    "    \n",
    "          \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0:\n",
    "          \n",
    "        if len(yminsTeeth) > 0 and len(ymaxsTeeth) > 0 and (ymaxsTeeth[len(ymaxsTeeth)-1] - yminsTeeth[0]) > (0.5 * imgLabel.shape[1]):\n",
    "            boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], yminsTeeth[0], ymaxsTeeth[len(ymaxsTeeth)-1]]\n",
    "        \n",
    "        else:\n",
    "            boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1]]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "                \n",
    "\n",
    "    ##############################################\n",
    "    ######### Draw Boundaries if Verbose #########\n",
    "    ##############################################\n",
    "    if len(img) > 0:\n",
    "        print(boundariesDict)\n",
    "        \n",
    "        \n",
    "        #draw bucket boundaries\n",
    "        if 'bucket' in boundariesDict:\n",
    "            (xmin, xmax, ymin, ymax) = boundariesDict['bucket']\n",
    "            cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,0,255),3)\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getBucketBoundaries(imgLabel, img=[]):\n",
    "\n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        \n",
    "        #for Bucyrus\n",
    "        #'sheave'     :np.where(np.all(imgLabel == sheave, axis=-1)),\n",
    "        #'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "    }\n",
    "    \n",
    "    if len(img) >0 :\n",
    "        plt.imshow(imgLabel)\n",
    "        plt.show()\n",
    "        print(labelsDic)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "    if len(img) >0 :\n",
    "        print(sortedLabelColsDic)\n",
    "        print(\"\\n\")\n",
    "        print(sortedLabelRowsDic)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ############## Bucket Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    for labV in sortedLabelColsDic.values():\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    for labV in sortedLabelRowsDic.values():\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "\n",
    "    \n",
    "\n",
    "    #get the bucket boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0 : \n",
    "        boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1]]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "                \n",
    "\n",
    "    ##############################################\n",
    "    ######### Draw Boundaries if Verbose #########\n",
    "    ##############################################\n",
    "    if len(img) > 0:\n",
    "        print(boundariesDict)\n",
    "        \n",
    "        \n",
    "        #draw bucket boundaries\n",
    "        (xmin, xmax, ymin, ymax) = boundariesDict['bucket']\n",
    "        cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,0,255),3)\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getAllBoundaries(imgLabel, img=[]):\n",
    "    '''\n",
    "    HS: \n",
    "    ---This method returs a list of boundaries: 1 bucket boundary, 1 fineInside boundary (if present) and several     rockInside boundaries (if present). \n",
    "    '''\n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        \n",
    "        #for Bucyrus\n",
    "        #'sheave'     :np.where(np.all(imgLabel == sheave, axis=-1)),\n",
    "        #'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "    }\n",
    "    \n",
    "    if len(img) >0 :\n",
    "        plt.imshow(imgLabel)\n",
    "        plt.show()\n",
    "        print(labelsDic)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "    if len(img) >0 :\n",
    "        print(sortedLabelColsDic)\n",
    "        print(\"\\n\")\n",
    "        print(sortedLabelRowsDic)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    ##############################################\n",
    "    ############# FineInside Boundary ############\n",
    "    ##############################################'\n",
    "    if 'fineInsideCols' in sortedLabelColsDic and 'fineInsideRows' in sortedLabelRowsDic:\n",
    "        boundariesDict['fineInside'] = [\n",
    "            int(sortedLabelColsDic[\"fineInsideCols\"][0][0]),\n",
    "            int(sortedLabelColsDic[\"fineInsideCols\"][0][len(sortedLabelRowsDic[\"fineInsideRows\"][0])-1]),\n",
    "            int(sortedLabelRowsDic[\"fineInsideRows\"][0][0]),\n",
    "            int(sortedLabelRowsDic[\"fineInsideRows\"][0][len(sortedLabelColsDic[\"fineInsideCols\"][0])-1]),\n",
    "        ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ############# teeth Boundary ############\n",
    "    ##############################################\n",
    "    if 'teethCols' in sortedLabelColsDic and 'teethRows' in sortedLabelRowsDic:\n",
    "        boundariesDict['teeth'] = [\n",
    "            int(sortedLabelColsDic[\"teethCols\"][0][0]),\n",
    "            int(sortedLabelColsDic[\"teethCols\"][0][len(sortedLabelRowsDic[\"teethRows\"][0])-1]),\n",
    "            int(sortedLabelRowsDic[\"teethRows\"][0][0]),\n",
    "            int(sortedLabelRowsDic[\"teethRows\"][0][len(sortedLabelColsDic[\"teethCols\"][0])-1]),\n",
    "        ]   \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ############## Bucket Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    for labV in sortedLabelColsDic.values():\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    for labV in sortedLabelRowsDic.values():\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "\n",
    "    \n",
    "\n",
    "    #get the bucket boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0 : \n",
    "        boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1]]\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    ##############################################\n",
    "    ############# RockInside Boundary ############\n",
    "    ##############################################\n",
    "    if 'rockInsideCols' in sortedLabelColsDic and 'rockInsideRows' in sortedLabelRowsDic:\n",
    "        # Getting the rock maks used to find rock boundaries        \n",
    "        rockMask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "        rockMask[labelsDic['rockInside']] = 1\n",
    "\n",
    "        # This converts any np.array to opencv image.\n",
    "        cv_rockMask = img_as_ubyte(rockMask)\n",
    "\n",
    "        contours, _ = cv2.findContours(cv_rockMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Getting bounding boxes from contours\n",
    "        rockBoundaries = []\n",
    "        for cnt in contours:\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            (xmin, xmax, ymin, ymax) = (y, (y+h), x, (x+w))\n",
    "\n",
    "            # only consider large boundaries.\n",
    "            if h>3 and w >3:\n",
    "                rockBoundaries.append([xmin, xmax, ymin, ymax])\n",
    "\n",
    "        boundariesDict['rockInside'] = rockBoundaries\n",
    "\n",
    "\n",
    "    \n",
    "                \n",
    "\n",
    "    ##############################################\n",
    "    ######### Draw Boundaries if Verbose #########\n",
    "    ##############################################\n",
    "    if len(img) > 0:\n",
    "        print(boundariesDict)\n",
    "        \n",
    "        \n",
    "        #draw bucket boundaries\n",
    "        (xmin, xmax, ymin, ymax) = boundariesDict['bucket']\n",
    "        cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,0,255),3)\n",
    "        \n",
    "        \n",
    "        #draw rockInside boundaries\n",
    "        for rockBb in boundariesDict['rockInside']:\n",
    "            cv2.rectangle(img,(rockBb[2], rockBb[0]),(rockBb[3], rockBb[1]),(255,0,0),3)\n",
    "\n",
    "        \n",
    "        #draw fineInside boundaries\n",
    "        (xmin, xmax, ymin, ymax) = boundariesDict['fineInside']\n",
    "        cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,255,0),3)\n",
    "        \n",
    "        \n",
    "        #draw teeth boundaries\n",
    "        (xmin, xmax, ymin, ymax) = boundariesDict['teeth']\n",
    "        cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(255,255,0),3)\n",
    "        \n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def writeRowsToCsv(rows, csvFullPath):\n",
    "    # open the file\n",
    "    csv_file = open(csvFullPath, \"w\") \n",
    "    \n",
    "    # define column names\n",
    "    columnTitles = \"filename,pathname,xmins,xmax,ymins,ymax,class\\n\"\n",
    "    csv_file.write(columnTitles)\n",
    "\n",
    "    # write rows\n",
    "    for row in rows:\n",
    "        csv_file.write(row)\n",
    "\n",
    "    csv_file.close()\n",
    "    \n",
    "    print(\"wrote \" + str(len(rows)) + \" rows to csv file\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def writeRowDicToCsv(rowsDic, csvFullPath):\n",
    "    # open the file\n",
    "    #use w for mode to override existing\n",
    "    csv_file = open(csvFullPath, \"a\") \n",
    "    \n",
    "    # define column names\n",
    "    columnTitles = \"filename,pathname,xmins,xmax,ymins,ymax,class\\n\"\n",
    "    csv_file.write(columnTitles)\n",
    "\n",
    "    # write rows\n",
    "    for imId in rowsDic:\n",
    "        if imId != 'fileName':\n",
    "            row = rowsDic[imId] + '\\n'\n",
    "            csv_file.write(row)\n",
    "\n",
    "    csv_file.close()\n",
    "    \n",
    "    print(\"wrote \" + str(len(rowsDic)) + \" rows to csv file\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def readCsvRows(fullCsvPath):\n",
    "    # open the file\n",
    "    csv_file = open(fullCsvPath, \"r\") \n",
    "    data = csv_file.read()\n",
    "    csv_file.close()\n",
    "    \n",
    "    rows = data.split('\\n')\n",
    "    \n",
    "    print(\"read \" + str(len(rows)) + \" rows\")\n",
    "    \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getRowsDictFromCsv(fullCsvPath):\n",
    "    csv_file = open(fullCsvPath, \"r\") \n",
    "    data = csv_file.read()\n",
    "    csv_file.close()\n",
    "\n",
    "    rows = data.split('\\n')\n",
    "\n",
    "    rowsDict = {}\n",
    "\n",
    "    for row in rows[1 : len(rows)-1]:\n",
    "        vals = row.split(',')\n",
    "\n",
    "        if vals[0] not in rowsDict:\n",
    "            rowsDict[vals[0]] = []\n",
    "\n",
    "        rowsDict[vals[0]].append(vals[2:7])\n",
    "        \n",
    "    print(\"read \" + str(len(rowsDict)) + \" examples\")\n",
    "    return rowsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getRowsDictFromCsvSaveJustBucketBoundingBox(fullCsvPath):\n",
    "    csv_file = open(fullCsvPath, \"r\") \n",
    "    data = csv_file.read()\n",
    "    csv_file.close()\n",
    "\n",
    "    rows = data.split('\\n')\n",
    "\n",
    "    rowsDict = {}\n",
    "\n",
    "    for row in rows[1 : len(rows)-1]:\n",
    "        vals = row.split(',')\n",
    "\n",
    "        if vals[-1] == 'bucket':\n",
    "            rowsDict[vals[0]] = vals[2:7]\n",
    "        \n",
    "    print(\"read \" + str(len(rowsDict)) + \" examples\")\n",
    "    return rowsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getCertainClassRowsDictFromCsv(fullCsvPath, classesToLookFor):\n",
    "    csv_file = open(fullCsvPath, \"r\") \n",
    "    data = csv_file.read()\n",
    "    csv_file.close()\n",
    "\n",
    "    rows = data.split('\\n')\n",
    "\n",
    "    rowsDict = {}\n",
    "\n",
    "    for row in rows[1 : len(rows)-1]:\n",
    "        vals = row.split(',')\n",
    "        \n",
    "        if vals[6] in classesToLookFor:\n",
    "\n",
    "            if vals[0] not in rowsDict:\n",
    "                rowsDict[vals[0]] = row\n",
    "            else:\n",
    "                print(\"error. duplicateRow. This shouldn't happen\")\n",
    "        \n",
    "    print(\"read \" + str(len(rowsDict)) + \" examples\")\n",
    "    return rowsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def visualizeRowDict(rowDict, writeToDisk=False, outputDirPath=\"\", saveLabelToo=False):\n",
    "    for imgId in rowsDict:\n",
    "\n",
    "        img = imread(imagesPath + imgId)\n",
    "        if saveLabelToo==True:\n",
    "            label = imread(labelsPath + imgId)\n",
    "\n",
    "        for box in rowsDict[imgId]:\n",
    "            \n",
    "            if(box[0] != \"\"):\n",
    "\n",
    "                if box[4] == 'bucket':\n",
    "                    (xmin, xmax, ymin, ymax) = box[0:4]\n",
    "                    int(round(float(xmin)))\n",
    "                    cv2.rectangle(img,(int(round(float(xmin))), int(round(float(ymin)))),(int(round(float(xmax))), int(round(float(ymax)))),(0,0,255),3)\n",
    "                    \n",
    "                    \n",
    "                if box[4] == 'matInside':\n",
    "                    (xmin, xmax, ymin, ymax) = box[0:4]\n",
    "                    cv2.rectangle(img,(int(round(float(xmin))), int(round(float(ymin)))),(int(round(float(xmax))), int(round(float(ymax)))),(0,255,0),3)\n",
    "\n",
    "\n",
    "                if box[4] == 'fineInside':\n",
    "                    (xmin, xmax, ymin, ymax) = box[0:4]\n",
    "                    cv2.rectangle(img,(int(round(float(xmin))), int(round(float(ymin)))),(int(round(float(xmax))), int(round(float(ymax)))),(0,255,0),3)\n",
    "\n",
    "\n",
    "                if box[4] == 'rockInside':\n",
    "                    (xmin, xmax, ymin, ymax) = box[0:4]\n",
    "                    cv2.rectangle(img,(int(round(float(xmin))), int(round(float(ymin)))),(int(round(float(xmax))), int(round(float(ymax)))),(255,0,0),3)\n",
    "\n",
    "\n",
    "        if writeToDisk==True and outputDirPath != \"\":\n",
    "            cv2.imwrite(outputDirPath + imgId, img)\n",
    "            \n",
    "            if saveLabelToo==True:\n",
    "                cv2.imwrite(outputDirPath + \"_label_\" + imgId, label)\n",
    "        else:\n",
    "            print(imgId)\n",
    "            if saveLabelToo==True:\n",
    "                plt.imshow(label)\n",
    "                plt.show()\n",
    "\n",
    "            plt.imshow(img)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def visualizeRow(row):\n",
    "    vals = row.split(',')\n",
    "    \n",
    "    img = imread(imagesPath + vals[0])\n",
    "    label = imread(labelsPath + vals[0])\n",
    "    \n",
    "    xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "    if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "        (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "        \n",
    "        \n",
    "        if vals[6] == 'matInside':\n",
    "            cv2.rectangle(img,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(0,255,0),3)\n",
    "            cv2.rectangle(label,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(0,255,0),3)\n",
    "            \n",
    "        if vals[6] == 'matInside':\n",
    "            cv2.rectangle(img,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(0,0,255),3)\n",
    "            cv2.rectangle(label,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(0,0,255),3)\n",
    "            \n",
    "        else:\n",
    "            #read in notebook\n",
    "            cv2.rectangle(img,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(255,0,0),3)\n",
    "            cv2.rectangle(label,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(255,0,0),3)\n",
    "            \n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(label)\n",
    "    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def writeRowToDisk(row, writeLabelsToo=False):\n",
    "    vals = row.split(',')\n",
    "    \n",
    "    img = imread(imagesPath + vals[0])\n",
    "    \n",
    "    xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "    cv2.rectangle(img,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(255,0,0),3)\n",
    "    \n",
    "    cv2.imwrite(imgBoundariesPath + vals[0], img)\n",
    "    \n",
    "    if writeLabelsToo:\n",
    "        label = imread(labelsPath + vals[0])\n",
    "        cv2.rectangle(label,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(255,0,0),3)\n",
    "        cv2.imwrite(labelBoundariesPath + vals[0], label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def visualizeImg(imgId):\n",
    "    img = imread(imagesPath + imgId)\n",
    "    label = imread(labelsPath + imgId)\n",
    "    \n",
    "    foundBucketBoundary, xmin, xmax, ymin, ymax = getBucketBoundaries(label)\n",
    "    \n",
    "    if(foundBucketBoundary):\n",
    "        cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(255,0,0),3)\n",
    "        cv2.rectangle(label,(ymin, xmin),(ymax, xmax),(255,0,0),3)\n",
    "\n",
    "        plt.imshow(img)\n",
    "        plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(label)\n",
    "        plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(\"could not find bucket boundary\\n\")\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(label)\n",
    "        plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getBbxMask(row, writeToDisk=False, mask_direct_path=None, verbose=False):\n",
    "    vals = row.split(',')\n",
    "    \n",
    "    img = imread(imagesPath + vals[0])\n",
    "    mask = np.zeros((img.shape[0], img.shape[1]), bool)\n",
    "    \n",
    "    xmin, xmax, ymin, ymax = vals[2:6]\n",
    "    if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "        (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "        mask[ymin:ymax, xmin:xmax] = 1\n",
    "    \n",
    "    if writeToDisk == True and mask_direct_path != None:\n",
    "        mask.dtype='uint8'\n",
    "        cv2.imwrite(mask_direct_path + vals[0], mask)\n",
    "        \n",
    "    if verbose:\n",
    "        if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "            cv2.rectangle(img,(xmin, ymin),(xmax, ymax),(255,0,0),3)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def calcPerformance(pred_rows, gt_rows, predictedBbMasks_path, gtBbMaks_path, verbose=False, predictedRowDict=None):\n",
    "    total_tn = 0\n",
    "    total_tp = 0\n",
    "    total_fn = 0\n",
    "    total_fp = 0\n",
    "    \n",
    "    rowCount = 0\n",
    "\n",
    "    if predictedRowDict == None:\n",
    "        print(\"using pred_rows\")\n",
    "        for pred_row, gt_row in zip(pred_rows, gt_rows):\n",
    "            pred_vals = pred_row.split(',')\n",
    "            gt_vals = gt_row.split(',')\n",
    "\n",
    "            if gt_vals[0] == pred_vals[0]:\n",
    "                pred_mask = imread(predictedBbMasks_path + pred_vals[0])\n",
    "                gt_mask = imread(gtBbMaks_path + gt_vals[0])\n",
    "\n",
    "                pos_preds = np.where(pred_mask == 1)\n",
    "                neg_preds = np.where(pred_mask == 0)\n",
    "\n",
    "                pos_overlap = pred_mask * gt_mask\n",
    "                neg_overlap = np.logical_not(pred_mask) * np.logical_not(gt_mask)\n",
    "\n",
    "                tp = np.count_nonzero(pos_overlap)\n",
    "                tn = np.count_nonzero(neg_overlap)\n",
    "                fp = len(pos_preds[0]) - tp\n",
    "                fn = len(neg_preds[0]) - tn\n",
    "\n",
    "                total_fp += fp\n",
    "                total_fn += fn\n",
    "                total_tp += tp\n",
    "                total_tn += tn\n",
    "                \n",
    "                rowCount += 1\n",
    "\n",
    "            else:\n",
    "                print(\"ERROR image id's don't match between gt csv file and predictions csv file\")\n",
    "\n",
    "    else:\n",
    "        print(\"using predictedRowDict\")\n",
    "        for gt_row in gt_rows:\n",
    "            gt_vals = gt_row.split(',')\n",
    "\n",
    "            if gt_vals[0] in predictedRowDict:\n",
    "                pred_vals = predictedRowDict[gt_vals[0]]\n",
    "                pred_mask = imread(predictedBbMasks_path + gt_vals[0])\n",
    "                gt_mask = imread(gtBbMaks_path + gt_vals[0])\n",
    "\n",
    "                pos_preds = np.where(pred_mask == 1)\n",
    "                neg_preds = np.where(pred_mask == 0)\n",
    "\n",
    "                pos_overlap = pred_mask * gt_mask\n",
    "                neg_overlap = np.logical_not(pred_mask) * np.logical_not(gt_mask)\n",
    "\n",
    "                tp = np.count_nonzero(pos_overlap)\n",
    "                tn = np.count_nonzero(neg_overlap)\n",
    "                fp = len(pos_preds[0]) - tp\n",
    "                fn = len(neg_preds[0]) - tn\n",
    "\n",
    "                total_fp += fp\n",
    "                total_fn += fn\n",
    "                total_tp += tp\n",
    "                total_tn += tn\n",
    "                \n",
    "                rowCount += 1\n",
    "                \n",
    "        \n",
    "    print(\"Processed \" + str(rowCount) + \" rows:\" )\n",
    "                \n",
    "\n",
    "                \n",
    "    if verbose:\n",
    "        plt.imshow(pred_mask)\n",
    "        plt.title(\"pred\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(gt_mask)\n",
    "        plt.title(\"gt\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(pos_overlap)\n",
    "        plt.title(\"pos_overlap\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(neg_overlap)\n",
    "        plt.title(\"neg_overlap\")\n",
    "        plt.show()\n",
    "\n",
    "        print(\"tp: \" + str(tp) + \" ,    fp: \" + str(fp) + \" ,    tn: \" + str(tn) + \" ,    fn: \" + str(fn) + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    sensitivity = float(total_tp) / (total_tp + total_fn)\n",
    "    specificity = float(total_tn) / (total_tn + total_fp)\n",
    "    precision = float(total_tp) / (total_tp + total_fp)\n",
    "    f_score = 2 * precision * sensitivity / (precision + sensitivity)\n",
    "\n",
    "    print(\"-Sensitivity: \" + str(sensitivity) +\n",
    "          \" ,    -Specificity: \" + str(specificity) +\n",
    "          \" ,    -Precision: \" + str(precision) +\n",
    "          \" ,    -F_score: \" + str(f_score)\n",
    "         )\n",
    "    \n",
    "    return sensitivity, specificity, precision, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def calcPerformance_insideBucket_multiClass(unet_pathToSavedResults, unet_pathTo1ChanLabels, verbose = False):\n",
    "\n",
    "    total_tn = 0\n",
    "    total_tp = 0\n",
    "    total_fn = 0\n",
    "    total_fp = 0\n",
    "\n",
    "    rowCount = 0\n",
    "\n",
    "\n",
    "    for imgId in os.listdir(unet_pathTo1ChanLabels):\n",
    "\n",
    "        label = imread(unet_pathTo1ChanLabels + imgId)\n",
    "        pred = imread(unet_pathToSavedResults + imgId)\n",
    "\n",
    "        labelMask = np.zeros((label.shape[0], label.shape[1]), bool)\n",
    "        predMask = np.zeros((pred.shape[0], pred.shape[1]), bool)\n",
    "\n",
    "\n",
    "\n",
    "        labelPixels = np.where(label == 2)\n",
    "        predPixels = np.where(pred == 2)\n",
    "\n",
    "        labelMask[labelPixels] = 1\n",
    "        predMask[predPixels] = 1\n",
    "\n",
    "\n",
    "\n",
    "        pos_preds = np.where(predMask == 1)\n",
    "        neg_preds = np.where(predMask == 0)\n",
    "\n",
    "        pos_overlap = predMask * labelMask\n",
    "        neg_overlap = np.logical_not(predMask) * np.logical_not(labelMask)\n",
    "\n",
    "\n",
    "        if verbose==True:\n",
    "            imshow(label)\n",
    "            plt.title('label')\n",
    "            plt.show()\n",
    "\n",
    "            imshow(labelMask)\n",
    "            plt.title('labelMask')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            imshow(pred)\n",
    "            plt.title('pred')\n",
    "            plt.show()\n",
    "\n",
    "            imshow(predMask)\n",
    "            plt.title('pred')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        tp = np.count_nonzero(pos_overlap)\n",
    "        tn = np.count_nonzero(neg_overlap)\n",
    "        fp = len(pos_preds[0]) - tp\n",
    "        fn = len(neg_preds[0]) - tn\n",
    "\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "        total_tp += tp\n",
    "        total_tn += tn\n",
    "\n",
    "        rowCount += 1\n",
    "\n",
    "\n",
    "\n",
    "    sensitivity = float(total_tp) / (total_tp + total_fn)\n",
    "    specificity = float(total_tn) / (total_tn + total_fp)\n",
    "    precision = float(total_tp) / (total_tp + total_fp)\n",
    "    f_score = 2 * precision * sensitivity / (precision + sensitivity)\n",
    "\n",
    "    print(\"-Sensitivity: \" + str(sensitivity) +\n",
    "          \" ,    -Specificity: \" + str(specificity) +\n",
    "          \" ,    -Precision: \" + str(precision) +\n",
    "          \" ,    -F_score: \" + str(f_score)\n",
    "         )\n",
    "\n",
    "\n",
    "    return sensitivity, specificity, precision, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cropImgFromRow(row, showResult = True , saveResult=False, cropImgPath = \"\", cropLabelPath = \"\"):\n",
    "    vals = row.split(',')\n",
    "\n",
    "    img = imread(imagesPath + vals[0])\n",
    "    label = imread(labelsPath + vals[0])\n",
    "\n",
    "    xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "    if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "        (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "\n",
    "        img = img[ymin:ymax, xmin:xmax,]\n",
    "        label = label[ymin:ymax, xmin:xmax]\n",
    "        \n",
    "        \n",
    "        \n",
    "    if saveResult==True:\n",
    "        cv2.imwrite(cropImgPath + vals[0], img)\n",
    "        cv2.imwrite(cropLabelPath + vals[0], label)\n",
    "\n",
    "        \n",
    "    if showResult==True:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(label)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cropImgFromRowV2(vals, imgName, margin, showResult = True , saveResult=False, cropImgPath = \"\", cropLabelPath = \"\"):\n",
    "\n",
    "    bestVal = vals[0]\n",
    "    for val in vals:\n",
    "        if val[4] == 'matInside':\n",
    "            bestVal = val\n",
    "    \n",
    "    img = imread(imagesPath + imgName)\n",
    "    label = imread(labelsPath + imgName)\n",
    "\n",
    "    xmin, xmax, ymin, ymax = bestVal[0:4]\n",
    "\n",
    "    if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "        (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "\n",
    "        \n",
    "        \n",
    "        if (ymin-margin) > 0:\n",
    "            yminAdj = (ymin-margin)\n",
    "        else:\n",
    "            yminAdj = ymin\n",
    "\n",
    "\n",
    "        if (xmin-margin) > 0:\n",
    "            xminAdj = (xmin-margin)\n",
    "        else:\n",
    "            xminAdj = xmin\n",
    "\n",
    "\n",
    "\n",
    "        if (ymax + margin) < img.shape[0]:\n",
    "            ymaxAdj = (ymax + margin)\n",
    "        else:\n",
    "            ymaxAdj = ymax\n",
    "\n",
    "\n",
    "\n",
    "        if (xmax + margin) < img.shape[1]:\n",
    "            xmaxAdj = (xmax + margin)\n",
    "        else:\n",
    "            xmaxAdj = xmax\n",
    "\n",
    "\n",
    "        img = img[yminAdj:ymaxAdj, xminAdj:xmaxAdj,]\n",
    "        label = label[yminAdj:ymaxAdj, xminAdj:xmaxAdj]\n",
    "\n",
    "        \n",
    "\n",
    "    if saveResult==True:\n",
    "        cv2.imwrite(cropImgPath + imgName, img)\n",
    "        cv2.imwrite(cropLabelPath + imgName, label)\n",
    "\n",
    "\n",
    "    if showResult==True:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(label)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def randomCropImgFromRow(row, showResult = True , saveResult=False, cropImgPath = \"\", cropLabelPath = \"\", offsetsToApply = []):\n",
    "    vals = row.split(',')\n",
    "\n",
    "    img = imread(imagesPath + vals[0])\n",
    "    label = imread(labelsPath + vals[0])\n",
    "\n",
    "    xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "    if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "        (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "\n",
    "        imgWidth = img.shape[1]\n",
    "        imgHeight = img.shape[0]\n",
    "        \n",
    "        if showResult==True:\n",
    "            plt.imshow(img)\n",
    "            plt.title('imgOrig')\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            \n",
    "        imgAct = img[ymin:ymax, xmin:xmax,]\n",
    "        labelAct = label[ymin:ymax, xmin:xmax]\n",
    "\n",
    "        if saveResult==True:\n",
    "            cv2.imwrite(cropImgPath + vals[0].replace('.png', '_RCAct.png'), imgAct)\n",
    "            cv2.imwrite(cropLabelPath + vals[0].replace('.png', '_RCAct.png'), labelAct)\n",
    "\n",
    "        if showResult==True:\n",
    "            plt.imshow(imgAct)\n",
    "            plt.title('imgAct')\n",
    "            plt.show()\n",
    "            \n",
    "\n",
    "            \n",
    "        for offset in offsetsToApply:\n",
    "            \n",
    "            img1 =     img[ymin + offset:ymax + offset, xmin:xmax]\n",
    "            label1 = label[ymin + offset:ymax + offset, xmin:xmax]\n",
    "            \n",
    "            if saveResult==True:\n",
    "                cv2.imwrite(cropImgPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_1.png', img1)\n",
    "                cv2.imwrite(cropLabelPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_1.png', label1)\n",
    "            \n",
    "            if showResult==True:\n",
    "                plt.imshow(img1)\n",
    "                plt.title('img1')\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            img2 =     img[ymin:ymax, xmin + offset:xmax + offset]\n",
    "            label2 = label[ymin:ymax, xmin + offset:xmax + offset]\n",
    "\n",
    "            if saveResult==True:\n",
    "                cv2.imwrite(cropImgPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_2.png', img2)\n",
    "                cv2.imwrite(cropLabelPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_2.png', label2)\n",
    "            \n",
    "            if showResult==True:\n",
    "                plt.imshow(img2)\n",
    "                plt.title('img2')\n",
    "                plt.show()\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "            if (ymin - offset) >= 0:\n",
    "                img3 =     img[ymin - offset:ymax - offset, xmin:xmax]\n",
    "                label3 = label[ymin - offset:ymax - offset, xmin:xmax]\n",
    "\n",
    "                if saveResult==True:\n",
    "                    cv2.imwrite(cropImgPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_3.png', img3)\n",
    "                    cv2.imwrite(cropLabelPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_3.png', label3)\n",
    "\n",
    "                if showResult==True:\n",
    "                    plt.imshow(img3)\n",
    "                    plt.title('img3')\n",
    "                    plt.show()\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "            if (xmin - offset) >= 0:\n",
    "                img4 =     img[ymin:ymax, xmin - offset:xmax - offset]\n",
    "                label4 = label[ymin:ymax, xmin - offset:xmax - offset]\n",
    "\n",
    "                if saveResult==True:\n",
    "                    cv2.imwrite(cropImgPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_4.png', img4)\n",
    "                    cv2.imwrite(cropLabelPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_4.png', label4)\n",
    "\n",
    "                if showResult==True:\n",
    "                    plt.imshow(img4)\n",
    "                    plt.title('img4')\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## SSD Data Generation: Cable and Hydraulics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### FMDL 3.1 Automated data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def seperateTrainingImages_hydraulics(\n",
    "    imgLabel, \n",
    "    img,\n",
    "    imgName,\n",
    "    dir2PutRejectedImages='/home/hooman/Desktop/deleteThis/negExamples/',\n",
    "    dir2PutAcceptedImages='/home/hooman/Desktop/deleteThis/goodExamples/',\n",
    "    dir2PutBadMatInsideImages='/home/hooman/Desktop/deleteThis/badExamples/',\n",
    "    verbose=True\n",
    "    ):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    rockInside  = (100, 0, 0)     #blue     \"rock_inside\"                      = \"640000\"\n",
    "    fineInside  = (100, 0, 50)     #green    \"fine_inside\"                     = \"640032\"\n",
    "    emptyInside = (0, 100, 100)   #yellow   \"empty\"                            = \"FFFF00\"\n",
    "    wmInside    = (39, 39, 100) #L-Pink   \"wm_landmarks\"                       = \"272764\"\n",
    "\n",
    "    fineInside2 = (20, 39, 59)                              #                      = \"14273b\"\n",
    "\n",
    "    inapInside  = (47, 47, 47)   #L-Brown  \"inapp_For_FM\"                      = \"2f2f2f\"\n",
    "\n",
    "    wmInapp = (0, 100, 0)   # for some images the green is this\n",
    "\n",
    "\n",
    "    teeth       = (100,   0, 100) #pink     \"teeth\"                             = \"640064\"\n",
    "    case        = (255, 0, 0)     #red      \"case\"                              = \"FF0000\"\n",
    "    truck       = (255, 255, 200) #cream    \"truck\"                             = \"FFFFC8\"\n",
    "    sheave      = (255, 128, 0)   #Orage    \"Sheave\"                            = \"FF8000\"\n",
    "    cable       = (0 , 0, 0)      #black    \"Cable\"                             = \"000000\"\n",
    "\n",
    "    rockOutside = (128, 0, 255)   #purple    \"rock_outside\"                     = \"8000FF\"\n",
    "    fineOutside = (0, 255, 255)   #cyan      \"fine_outside\"                     = \"00FFFF\"\n",
    "\n",
    "    void        = (180, 50, 50)   #Brown    \"void anything not in this labels\"  = \"B43232\"\n",
    "    shadow      = (120, 120, 120) #gray     \"shadow inside or outside\"          = \"787878\"\n",
    "    dust        = (80, 80, 80)    #D-Gray   \"dust inside or outside\"            = \"505050\"\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    minAcceptableBucketArea = 10000\n",
    "    minAcceptableBucketHeight = 100\n",
    "    minMatInsideArea2BucketAreaRatio = 0.65\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    boundariesDict = {}\n",
    "    status = 'undefined'\n",
    "    \n",
    "\n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {        \n",
    "        #for Hydraulics only\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        'wmInapp':np.where(np.all(imgLabel == wmInapp, axis=-1)),\n",
    "        'fineInside2' : np.where(np.all(imgLabel == fineInside2, axis=-1))\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    if verbose:\n",
    "        plt.imshow(imgLabel)\n",
    "        plt.title('imgLabel')\n",
    "        plt.show()\n",
    "        plt.imshow(img)\n",
    "        plt.title('img')\n",
    "        plt.show()\n",
    "\n",
    "        print('\\nlabelsDic:')\n",
    "        print(labelsDic)\n",
    "     \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    #######################################################\n",
    "    ########## Finding initial bucket boundary ############\n",
    "    #######################################################\n",
    "    xmins, xmaxs, ymins, ymaxs, yminsTeeth, ymaxsTeeth = sortLabelsDic(labelsDic, imgLabel, img)\n",
    "    \n",
    "          \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0:\n",
    "          \n",
    "        if len(yminsTeeth) > 0 and len(ymaxsTeeth) > 0 and (ymaxsTeeth[len(ymaxsTeeth)-1] - yminsTeeth[0]) > (0.5 * imgLabel.shape[1]):\n",
    "            boundariesDict['bucketInit'] = [xmins[0], xmaxs[len(xmaxs)-1], yminsTeeth[0], ymaxsTeeth[len(ymaxsTeeth)-1]]\n",
    "        \n",
    "        else:\n",
    "            boundariesDict['bucketInit'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1]]\n",
    "\n",
    "\n",
    "            \n",
    "                 \n",
    "    if 'bucketInit' in boundariesDict:\n",
    "        \n",
    "        (xminInit, xmaxInit, yminInit, ymaxInit) = boundariesDict['bucketInit']\n",
    "       \n",
    "        foundBucketArea = (ymaxInit - yminInit)*(xmaxInit - xminInit)\n",
    "        foundBucketHeight = xmaxInit - xminInit\n",
    "        \n",
    "        if verbose:            \n",
    "            cv2.rectangle(img,(yminInit, xminInit),(ymaxInit, xmaxInit),(255,0,0),3)\n",
    "            plt.imshow(img)\n",
    "            plt.title('initialBucket')\n",
    "            plt.show()\n",
    "            print('foundBucketArea:')\n",
    "            print(foundBucketArea)          \n",
    "            print('foundBucketHeight')\n",
    "            print(foundBucketHeight)\n",
    "  \n",
    "        \n",
    "        \n",
    "        #######################################################\n",
    "        ##########******Reject1 Bucket sizes*****#########\n",
    "        #If initial bucket we found is too small, reject this image\n",
    "        #######################################################\n",
    "        if foundBucketArea < minAcceptableBucketArea:    \n",
    "            cv2.rectangle(img,(yminInit, xminInit),(ymaxInit, xmaxInit),(255,0,0),3)\n",
    "            status = 'rejected-bucketArea2small'\n",
    "            \n",
    "            cv2.imwrite(dir2PutRejectedImages + imgName, img)\n",
    "            \n",
    "            boundariesDict['finalStatus'] = status\n",
    "            return boundariesDict\n",
    "        \n",
    "        if foundBucketHeight < minAcceptableBucketHeight:\n",
    "            cv2.rectangle(img,(yminInit, xminInit),(ymaxInit, xmaxInit),(255,0,0),3)\n",
    "            status = 'rejected-bucketHeight2small'\n",
    "            \n",
    "            cv2.imwrite(dir2PutRejectedImages + imgName, img)\n",
    "            \n",
    "            boundariesDict['finalStatus'] = status\n",
    "            return boundariesDict\n",
    "        #######################################################\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "        #######################################################\n",
    "        ########## Finding final bucket boundary ##############\n",
    "        #######################################################    \n",
    "        bucketInitHeight = boundariesDict['bucketInit'][1] - boundariesDict['bucketInit'][0]\n",
    "        quart = int(boundariesDict['bucketInit'][0] + bucketInitHeight * 0.4)\n",
    "        \n",
    "        labelsDic2 = {\n",
    "            'fineInside_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == fineInside, axis=-1)),\n",
    "            'fineInside2_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == fineInside2, axis=-1)),\n",
    "            'inapInside_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == inapInside, axis=-1)),\n",
    "            'emptyInside_q':np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == emptyInside, axis=-1)),\n",
    "            'wmInside_q'   :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == wmInside, axis=-1)),\n",
    "            'teeth_q'      :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == teeth, axis=-1)),\n",
    "            'shadow_q'     :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == shadow, axis=-1)),\n",
    "            'wmInapp_q':np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == wmInapp, axis=-1)),\n",
    "            \n",
    "            'rockInside_q' : np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == rockInside, axis=-1)),\n",
    "            #'dust_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == dust, axis=-1)),\n",
    "            #'case_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == case, axis=-1)),\n",
    "        }\n",
    "        \n",
    "        \n",
    "        xmins2, xmaxs2, ymins2, ymaxs2, yminsTeeth2, ymaxsTeeth2 = sortLabelsDic(labelsDic2, imgLabel, img)\n",
    "        \n",
    "        if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins2) > 0 and len(ymaxs2) > 0:\n",
    "\n",
    "            if len(yminsTeeth2) > 0 and len(ymaxsTeeth2) > 0 and (ymaxsTeeth2[len(ymaxsTeeth2)-1] - yminsTeeth2[0]) > (0.5 * imgLabel.shape[1]):\n",
    "                boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], yminsTeeth2[0], ymaxsTeeth2[len(ymaxsTeeth2)-1]]\n",
    "\n",
    "            else:\n",
    "                boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins2[0], ymaxs2[len(ymaxs2)-1]]\n",
    "        \n",
    "                \n",
    "\n",
    "\n",
    "        if 'bucket' in boundariesDict:\n",
    "            (xmin, xmax, ymin, ymax) = boundariesDict['bucket']\n",
    "            cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,255,255),3)\n",
    "\n",
    "            if verbose:\n",
    "                plt.imshow(img)\n",
    "                plt.title('finalBucket')\n",
    "                plt.show()\n",
    "\n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "##################################################################################################################\n",
    "            \n",
    "            ##############################################\n",
    "            ######### Processing MatInside ###############\n",
    "            ##############################################\n",
    "            labelsDicMatInside = {\n",
    "                #For Hydraulics  FMDL3.1\n",
    "                'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "                'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "                'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "\n",
    "                #with the new labels this is the new fmAppropriate mat\n",
    "                'fineInside2' :np.where(np.all(imgLabel == fineInside2, axis=-1)),\n",
    "            }\n",
    "            \n",
    "        \n",
    "            if verbose:\n",
    "                print('\\n\\n\\nlabelsDicMatInside:')\n",
    "                print(labelsDicMatInside)\n",
    "\n",
    "                \n",
    "\n",
    "            #get the boundary for each label\n",
    "            sortedLabelColsDicMatInside = {}\n",
    "            sortedLabelRowsDicMatInside = {}\n",
    "            for k in labelsDicMatInside.keys():\n",
    "                if len(labelsDicMatInside[k][0]) > 0:\n",
    "                    sortedLabelColsDicMatInside[k+'Cols'] = np.sort(labelsDicMatInside[k][0]),\n",
    "                    sortedLabelRowsDicMatInside[k+'Rows'] = np.sort(labelsDicMatInside[k][1]),\n",
    "\n",
    "\n",
    "\n",
    "            #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "            lowColValsMatInside = []\n",
    "            highColValsMatInside = []\n",
    "            for labV in sortedLabelColsDicMatInside.values():\n",
    "                for v in labV:\n",
    "                    lowColValsMatInside.append(v[0])\n",
    "                    highColValsMatInside.append(v[len(v)-1])\n",
    "\n",
    "            lowRowValsMatInside = []\n",
    "            highRowValsMatInside = []\n",
    "            for labV in sortedLabelRowsDicMatInside.values():\n",
    "                for v in labV:\n",
    "                    lowRowValsMatInside.append(v[0])\n",
    "                    highRowValsMatInside.append(v[len(v)-1])\n",
    "\n",
    "\n",
    "\n",
    "            #get the boundary\n",
    "            xminsMatInside = np.sort(np.array(lowColValsMatInside))\n",
    "            xmaxsMatInside = np.sort(np.array(highColValsMatInside))\n",
    "            yminsMatInside = np.sort(np.array(lowRowValsMatInside))\n",
    "            ymaxsMatInside = np.sort(np.array(highRowValsMatInside))\n",
    "            \n",
    "            \n",
    "            \n",
    "                    \n",
    "            ##########################################################################\n",
    "            ############## decide to keep or reject matInside Boundary ###############\n",
    "            ##########################################################################\n",
    "\n",
    "            if len(xminsMatInside) > 0 and len(xmaxsMatInside) > 0 and len(yminsMatInside) > 0 and len(ymaxsMatInside) > 0 : \n",
    "            \n",
    "                boundariesDict['matInside'] = [xminsMatInside[0], xmaxsMatInside[len(xmaxsMatInside)-1], yminsMatInside[0], ymaxsMatInside[len(ymaxsMatInside)-1]]\n",
    "\n",
    "\n",
    "                (xminFinalMatInside, xmaxFinalMatInside, yminFinalMatInside, ymaxFinalMatInside) = boundariesDict['matInside']\n",
    "\n",
    "                cv2.rectangle(img,(yminFinalMatInside, xminFinalMatInside),(ymaxFinalMatInside, xmaxFinalMatInside),(255,255, 0),3)\n",
    "\n",
    "                foundFinalMatInsideArea = (ymaxFinalMatInside - yminFinalMatInside)*(xmaxFinalMatInside - xminFinalMatInside)\n",
    "                \n",
    "                matInside2BucketAreaRatio = foundFinalMatInsideArea / foundBucketArea\n",
    "\n",
    "\n",
    "                if verbose:\n",
    "                    print('\\nmatInside2BucketAreaRatio:')\n",
    "                    print(matInside2BucketAreaRatio)\n",
    "                    \n",
    "                    plt.imshow(img)\n",
    "                    plt.title('finalMatInside')\n",
    "                    plt.show()\n",
    "\n",
    "                    \n",
    "                                        \n",
    "                    \n",
    "                #################################################################\n",
    "                ##########******Reject2 not enough good material*****############\n",
    "                #If no fine, or rock material that are good in the bucket, reject\n",
    "                #################################################################\n",
    "                if len(labelsDicMatInside['rockInside'][0]) == 0 and len(labelsDicMatInside['fineInside'][0]) == 0 and len(labelsDicMatInside['fineInside2'][0]) == 0:\n",
    "\n",
    "                    status = 'rejected-SomeButNotEnoughAppropriateMaterial'\n",
    "\n",
    "                    cv2.imwrite(dir2PutBadMatInsideImages + imgName, img)\n",
    "\n",
    "                    boundariesDict['finalStatus'] = status\n",
    "\n",
    "                    return boundariesDict\n",
    "                #################################################################                    \n",
    "                    \n",
    "                    \n",
    "                ###############################################################################\n",
    "                ##########******Reject3 not enough good material*****##########################\n",
    "                #If area of matInside is much less than bucket area (mostly empty bucket), reject\n",
    "                ###############################################################################                \n",
    "                if matInside2BucketAreaRatio < minMatInsideArea2BucketAreaRatio:    \n",
    "                    status = 'rejected-matInsideArea2small'\n",
    "\n",
    "                    cv2.imwrite(dir2PutBadMatInsideImages + imgName, img)\n",
    "\n",
    "                    boundariesDict['finalStatus'] = status\n",
    "                    return boundariesDict\n",
    "                #################################################################\n",
    "                \n",
    "                \n",
    "                status = 'accepted-BothBucketAndMatInside'\n",
    "            else:\n",
    "                #Found bucket but no MatInside    \n",
    "                status = 'accepted-onlyBucketNoMatInsideContent'\n",
    "                \n",
    "                \n",
    "            cv2.imwrite(dir2PutAcceptedImages + imgName, img)    \n",
    "            boundariesDict['finalStatus'] = status\n",
    "            \n",
    "            return boundariesDict\n",
    "                \n",
    "        else:\n",
    "            # Found no bucket\n",
    "            boundariesDict['finalStatus'] = 'rejected_foundNoBucket'\n",
    "            cv2.imwrite(dir2PutRejectedImages + imgName, img)\n",
    "            return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Automatically generating training data from directory of images\n",
    "imagesPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/hydraulics/images_fromJira/'\n",
    "labelsPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/hydraulics/labels_fromJira/'\n",
    "\n",
    "dir2PutRejectedImages='/home/hooman/Desktop/deleteThis/negExamples/'\n",
    "dir2PutAcceptedImages='/home/hooman/Desktop/deleteThis/goodExamples/'\n",
    "dir2PutBadMatInsideImages='/home/hooman/Desktop/deleteThis/badExamples/'\n",
    "verbose=False\n",
    "\n",
    "\n",
    "rows = []\n",
    "for fileName in os.listdir(imagesPath):\n",
    "    \n",
    "    filePath = labelsPath + fileName\n",
    "    \n",
    "    imgLabel = imread(filePath)\n",
    "    \n",
    "    #I added this for try3  ssd-multiclass-tries 1 and 2 didnt have this.\n",
    "    imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "    img = imread(imagesPath + fileName)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"processing file:\\n\" + filePath + '\\n')\n",
    "    \n",
    "    boundariesDict = seperateTrainingImages_hydraulics(imgLabel, img, fileName, dir2PutRejectedImages, dir2PutAcceptedImages, dir2PutBadMatInsideImages, verbose)\n",
    "\n",
    "    print('\\nboundariesDict:')\n",
    "    print(boundariesDict)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if boundariesDict and ('bucket' in boundariesDict):\n",
    "        # write up the rows\n",
    "        (xmin, xmax, ymin, ymax) = boundariesDict['bucket']\n",
    "        row = fileName + \",\" + filePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"bucket\" + \"\\n\"\n",
    "    \n",
    "        rows.append(row)\n",
    "\n",
    "        \n",
    "        if('matInside' in boundariesDict):\n",
    "            if len(boundariesDict['matInside']) == 4:\n",
    "                (xmin, xmax, ymin, ymax) = boundariesDict['matInside']\n",
    "                row = fileName + \",\" + filePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"matInside\" + \"\\n\"\n",
    "            else:\n",
    "                print(\"ERROR: Found more than one matInside Boundaries. This should NOT happen\\n\")\n",
    "\n",
    "            rows.append(row)  \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "print(\"processed \"+ str(len(rows)) + \" rows\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#(single image of above for tests) (do not delete)\n",
    "rows = []\n",
    "\n",
    "\n",
    "#fileName = 'KAJF0576_20110311071930_avi_15591.png'\n",
    "#fileName = '1004_ESP_S05_001_35973.png'\n",
    "#fileName = '1_20161115-222501_0001n0_3297.png'\n",
    "#fileName = '1_20170118-023300_0001n0_9611.png'\n",
    "#fileName = '1_20161117-022000_0001n0_12000.png' \n",
    "#fileName = '1_20171114-111400_0001n0_18741.png'\n",
    "#fileName = '1_20180122-051000_0001n0_29579.png'\n",
    "#fileName = '1_20161116-025500_0001n0_13817.png'\n",
    "#fileName = '1_20170118-111000_0001n0_17029.png'\n",
    "\n",
    "#fileName = '1004_ESP_S04_009_69091.png'\n",
    "#fileName = '1004_ESP_S04_009_67813.png'\n",
    "\n",
    "fileName = '1004_ESP_S04_009_66324.png'\n",
    "\n",
    "    \n",
    "    \n",
    "filePath = labelsPath + fileName\n",
    "\n",
    "imgLabel = imread(filePath)\n",
    "img = imread(imagesPath + fileName)\n",
    "\n",
    "#I added this for try3  ssd-multiclass-tries 1 and 2 didnt have this.\n",
    "imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "\n",
    "print(\"processing file:\\n\" + filePath + '\\n\\n\\n')\n",
    "\n",
    "\n",
    "boundariesDict = seperateTrainingImages_hydraulics(imgLabel, img, fileName)\n",
    "\n",
    "\n",
    "print('\\n\\n\\nboundariesDict:')\n",
    "print(boundariesDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "writeRowsToCsv(rows, \"/home/hooman/Desktop/deleteThis/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for row in rows[0:38]:\n",
    "    visualizeRow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Finding boundaries and writing them to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Finding matInside and bucket boundaries. For ssdMulti-try3\n",
    "rows = []\n",
    "for fileName in os.listdir(imagesPath):\n",
    "    \n",
    "    filePath = labelsPath + fileName\n",
    "    \n",
    "    imgLabel = imread(filePath)\n",
    "    \n",
    "    #I added this for try3  ssd-multiclass-tries 1 and 2 didnt have this.\n",
    "    imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "    \n",
    "    print(\"processing file: \" + filePath)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #bucketBoundariesDict = getBucketBoundaries(imgLabel)\n",
    "    bucketBoundariesDict = getBucketBoundariesTooth2ToothV2(imgLabel)\n",
    "    matInsideBoundariesDict = getMatInsideBoundaries(imgLabel)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if bucketBoundariesDict and ('bucket' in bucketBoundariesDict):\n",
    "        # write up the rows\n",
    "        (xmin, xmax, ymin, ymax) = bucketBoundariesDict['bucket']\n",
    "        row = fileName + \",\" + filePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"bucket\" + \"\\n\"\n",
    "    \n",
    "        rows.append(row)\n",
    "    \n",
    "    else:\n",
    "        print(\"ERROR: Found no bucket boundary.\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    if('matInside' in matInsideBoundariesDict):\n",
    "        if len(matInsideBoundariesDict['matInside']) == 4:\n",
    "            (xmin, xmax, ymin, ymax) = matInsideBoundariesDict['matInside']\n",
    "            row = fileName + \",\" + filePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"matInside\" + \"\\n\"\n",
    "        else:\n",
    "            print(\"ERROR: Found more than one matInside Boundaries. This should NOT happen\\n\")\n",
    "        \n",
    "        rows.append(row)        \n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "print(\"processes \"+ str(len(rows)) + \" rows\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "writeRowsToCsv(rows, \"/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/cable/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_cable__try1/validationSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for row in rows[200:300]:\n",
    "    visualizeRow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#(single image of above for tests) Debugging boundaris for boxDetector 2nd round (do not delete)\n",
    "rows = []\n",
    "\n",
    "#fileName = '1_20180703-100000_1001n0_23970.png'\n",
    "fileName = '1003_PTF_S14_A_001_2187.png'\n",
    "   \n",
    "    \n",
    "    \n",
    "filePath = labelsPath + fileName\n",
    "\n",
    "imgLabel = imread(filePath)\n",
    "img = imread(imagesPath + fileName)\n",
    "\n",
    "#I added this for try3  ssd-multiclass-tries 1 and 2 didnt have this.\n",
    "imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "print(\"processing file: \" + filePath)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bucketBoundariesDict = getBucketBoundariesTooth2ToothV2(imgLabel, img)\n",
    "#matInsideBoundariesDict = getMatInsideBoundaries(imgLabel, img)\n",
    "\n",
    "\n",
    "\n",
    "if('bucket' in bucketBoundariesDict):\n",
    "    # write up the rows\n",
    "    (xmin, xmax, ymin, ymax) = bucketBoundariesDict['bucket']\n",
    "    row = fileName + \",\" + filePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"bucket\" + \"\\n\"\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Found no bucket boundary.\\n\")\n",
    "\n",
    "\n",
    "\n",
    "if('matInside' in matInsideBoundariesDict):\n",
    "    if len(matInsideBoundariesDict['matInside']) == 4:\n",
    "        (xmin, xmax, ymin, ymax) = matInsideBoundariesDict['matInside']\n",
    "        row = fileName + \",\" + filePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"matInside\" + \"\\n\"\n",
    "    else:\n",
    "        print(\"ERROR: Found more than one matInside Boundaries. This should NOT happen\\n\")\n",
    "\n",
    "    rows.append(row)        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Visualizing existing csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 4514 examples\n"
     ]
    }
   ],
   "source": [
    "rowsDict = getRowsDictFromCsv(\"/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may10-2019/trainingSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "visualizeRowDict(rowsDict, True, '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may10-2019/boundariesVisualized/', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## U-Net Data Generation: Cable and Hydraulics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Cropping images to contain only ROI (V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rowDict = getRowsDictFromCsv('/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameNetworkAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/unetBoxes_finalTrainingSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for imgName in os.listdir(imagesPath):\n",
    "    cropImgFromRowV2(rowDict[imgName],imgName, 100, False , True,'/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameNetworkAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/finalTrainingSet_images_croped/','/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameNetworkAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/finalTrainingSet_masks_croped/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Random Cropping images for U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gt_rows = readCsvRows('/home/hooman/backhoeOpticalScene/roiDelineators/try1-csvFrom-ssdTry2/fromSSdTry2_fineAndRockAndInapInMatInside_backhoe_shuffled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# random crop images and masks\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "offsetsToApply = [50,75, 100, 125, 150, 175]\n",
    "dirToSaveImages = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/randomCroppedImages/'\n",
    "dirToSaveMasks = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/randomCroppedMasks/'\n",
    "\n",
    "\n",
    "dirToReadImages = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/allImages/'\n",
    "dirToReadMasks = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/fullMaks/'\n",
    "\n",
    "\n",
    "for row in gt_rows[1:len(gt_rows)-1]:\n",
    "    \n",
    "    vals = row.split(',')\n",
    "\n",
    "    if os.path.exists(dirToReadImages + vals[0]) and os.path.exists(dirToReadMasks + vals[0]):\n",
    "        \n",
    "        #This causes a \"Too many open files error\"\n",
    "        #img = imread(dirToReadImages + vals[0])\n",
    "        #label = imread(dirToReadMasks + vals[0])\n",
    "        \n",
    "        imgPil = Image.open(dirToReadImages + vals[0])\n",
    "        img = np.array(imgPil) \n",
    "        imgPil.close()\n",
    "\n",
    "        labelPil = Image.open(dirToReadMasks + vals[0])\n",
    "        label = np.array(labelPil)\n",
    "        labelPil.close()\n",
    "        \n",
    "        \n",
    "\n",
    "        xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "        if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "            (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "\n",
    "            imgWidth = img.shape[1]\n",
    "            imgHeight = img.shape[0]\n",
    "\n",
    "\n",
    "            imgAct = img[ymin:ymax, xmin:xmax,]\n",
    "            labelAct = label[ymin:ymax, xmin:xmax]\n",
    "\n",
    "            if imgAct.shape[0] > 0 and imgAct.shape[1] > 0 and labelAct.shape[0] > 0 and labelAct.shape[1] > 0: \n",
    "                cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '_RCAct.png'), imgAct)\n",
    "                cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '_RCAct.png'), labelAct)\n",
    "\n",
    "\n",
    "\n",
    "            for offset in offsetsToApply:\n",
    "\n",
    "                img1 =     img[ymin + offset:ymax + offset, xmin:xmax]\n",
    "                label1 = label[ymin + offset:ymax + offset, xmin:xmax]\n",
    "                \n",
    "                if img1.shape[0] > 0 and img1.shape[1] > 0 and label1.shape[0] > 0 and label1.shape[1] > 0: \n",
    "                    cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_1.png', img1)\n",
    "                    cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_1.png', label1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                img2 =     img[ymin:ymax, xmin + offset:xmax + offset]\n",
    "                label2 = label[ymin:ymax, xmin + offset:xmax + offset]\n",
    "         \n",
    "                if img2.shape[0] > 0 and img2.shape[1] > 0 and label2.shape[0] > 0 and label2.shape[1] > 0: \n",
    "                    cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_2.png', img2)\n",
    "                    cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_2.png', label2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                if (ymin - offset) > 0:\n",
    "                    img3 =     img[ymin - offset:ymax - offset, xmin:xmax]\n",
    "                    label3 = label[ymin - offset:ymax - offset, xmin:xmax]\n",
    "                    \n",
    "                    if img3.shape[0] > 0 and img3.shape[1] > 0 and label3.shape[0] > 0 and label3.shape[1] > 0: \n",
    "                        cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_3.png', img3)\n",
    "                        cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_3.png', label3)\n",
    "\n",
    "\n",
    "\n",
    "                if (xmin - offset) > 0:\n",
    "                    img4 =     img[ymin:ymax, xmin - offset:xmax - offset]\n",
    "                    label4 = label[ymin:ymax, xmin - offset:xmax - offset]\n",
    "                    \n",
    "                    if img4.shape[0] > 0 and img4.shape[1] > 0 and label4.shape[0] > 0 and label4.shape[1] > 0: \n",
    "\n",
    "                        cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_4.png', img4)\n",
    "                        cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_4.png', label4)\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"one of the provided directories doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#random cropping images and labels\n",
    "\n",
    "offsetsToApply = [50,75, 100, 125, 150, 175]\n",
    "dirToSaveImages = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCroppedImages/'\n",
    "dirToSaveLabels = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCroppedLabels/'\n",
    "\n",
    "for row in gt_rows[1:len(gt_rows)-1]:\n",
    "    randomCropImgFromRow(row, False , True, dirToSaveImages, dirToSaveLabels, offsetsToApply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Creating semantic segmentation Masks for U-Net from Cropped images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# creating masks for u-net CORRECT (using BGR for labels) more efficent to use with augmentations quickly\n",
    "\n",
    "\n",
    "croppedImagesPath = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCropped_images/'\n",
    "croppedLabelsPath = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCropped_labels/'\n",
    "croppedMasksPath  = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCropped_masks/'\n",
    "\n",
    "\n",
    "n = 0\n",
    "for fileName in os.listdir(croppedLabelsPath):\n",
    "    \n",
    "    try:\n",
    "        img = imread(croppedImagesPath + fileName)\n",
    "        imgLabel = imread(croppedLabelsPath + fileName)\n",
    "        #imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGB2BGR)  This is wrong too\n",
    "        imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "\n",
    "        labelsDic = {\n",
    "            'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "            'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "            'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        #    'emptyInside' :np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        }\n",
    "\n",
    "\n",
    "        #print(labelsDic)\n",
    "\n",
    "        mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "        mask[labelsDic['fineInside']] = 1\n",
    "        mask[labelsDic['rockInside']] = 1\n",
    "        mask[labelsDic['inapInside']] = 1\n",
    "        #mask[labelsDic['emptyInside']] = 1\n",
    "\n",
    "\n",
    "        mask.dtype='uint8'\n",
    "        cv2.imwrite(croppedMasksPath + fileName, mask)\n",
    "\n",
    "        n += 1\n",
    "    except:\n",
    "        print(\"couldnt open file: \" + fileName)\n",
    "\n",
    "print(\"created  \" + str(n) + \"  binary masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# creating masks for u-net CORRECT (using BGR for labels) with overlay\n",
    "\n",
    "'''\n",
    "croppedImagesPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/images/'\n",
    "croppedLabelsPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/labels/'\n",
    "croppedMasksPath  = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/masks/'\n",
    "croppedOverlayedPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/overlayed/'\n",
    "'''\n",
    "\n",
    "'''\n",
    "croppedImagesPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/finalTrainingSet_images/'\n",
    "croppedLabelsPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/labels_fromJira/'\n",
    "\n",
    "croppedMasksPath  = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/images_frmJira__fullSizeImages_masks/'\n",
    "croppedOverlayedPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/images_frmJira__fullSizeImages_overlays/'\n",
    "'''\n",
    "\n",
    "croppedImagesPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/images_manuallyLabeled/'\n",
    "\n",
    "croppedLabelsPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/labeles_manuallyLabeled/'\n",
    "\n",
    "croppedMasksPath  = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/manuallyLabeled_masks/'\n",
    "\n",
    "croppedOverlayedPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/manuallyLabeled_overlays/'\n",
    "\n",
    "\n",
    "\n",
    "n = 0\n",
    "for fileName in os.listdir(croppedImagesPath):\n",
    "    img = imread(croppedImagesPath + fileName)\n",
    "    imgLabel = imread(croppedLabelsPath + fileName)\n",
    "    #imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGB2BGR)  This is wrong too\n",
    "    imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "\n",
    "    labelsDic = {\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        \n",
    "        #for V3 with the new labels this is the new fmAppropriate mat\n",
    "        'fineInside2' :np.where(np.all(imgLabel == fineInside2, axis=-1)),\n",
    "        \n",
    "        #V2 for Hydraulics U-Net I had the inapInside labels but not for BucyrucAndPnH  for V3 no inapp.\n",
    "        #'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        \n",
    "    #    'emptyInside' :np.where(np.all(imgLabel == emptyInside, axis=-1)), bad idea\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "    #print(labelsDic)\n",
    "    #print(img.shape)\n",
    "\n",
    "    mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "    mask[labelsDic['fineInside']] = 1\n",
    "    mask[labelsDic['fineInside2']] = 1\n",
    "    mask[labelsDic['rockInside']] = 1\n",
    "    #mask[labelsDic['inapInside']] = 1\n",
    "    #mask[labelsDic['emptyInside']] = 1\n",
    "\n",
    "\n",
    "\n",
    "    mask.dtype='uint8'\n",
    "    maskOverlay = cv2.cvtColor(mask*255, cv2.COLOR_GRAY2BGR)\n",
    "    maskOverlay[:,:,0] = 0\n",
    "    maskOverlay[:,:,2] = 0\n",
    "\n",
    "\n",
    "    opacity = 0.2\n",
    "    cv2.addWeighted(maskOverlay, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "\n",
    "\n",
    "    mask.dtype='uint8'\n",
    "    cv2.imwrite(croppedMasksPath + fileName, mask)\n",
    "    cv2.imwrite(croppedOverlayedPath + fileName, img)\n",
    "\n",
    "    n += 1\n",
    "\n",
    "print(\"created  \" + str(n) + \"  binary masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# debugging UNET data generation\n",
    "\n",
    "# creating masks for u-net CORRECT (using BGR for labels) with overlay\n",
    "\n",
    "'''\n",
    "croppedImagesPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/images/'\n",
    "croppedLabelsPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/labels/'\n",
    "croppedMasksPath  = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/masks/'\n",
    "croppedOverlayedPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/overlayed/'\n",
    "'''\n",
    "\n",
    "croppedImagesPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/images_fromJira/'\n",
    "croppedLabelsPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/labels_fromJira/'\n",
    "\n",
    "croppedMasksPath  = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/images_frmJira__fullSizeImages_masks/'\n",
    "croppedOverlayedPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/images_frmJira__fullSizeImages_overlays/'\n",
    "\n",
    "\n",
    "\n",
    "fileName = '1_20161115-073100_0001n0_11017.png'\n",
    "\n",
    "\n",
    "\n",
    "img = imread(croppedImagesPath + fileName)\n",
    "imgLabel = imread(croppedLabelsPath + fileName)\n",
    "#imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGB2BGR)  This is wrong too\n",
    "imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "\n",
    "labelsDic = {\n",
    "    'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "    'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "\n",
    "    #for V3 with the new labels this is the new fmAppropriate mat\n",
    "    'fineInside2' :np.where(np.all(imgLabel == fineInside2, axis=-1)),\n",
    "\n",
    "    #V2 for Hydraulics U-Net I had the inapInside labels but not for BucyrucAndPnH  for V3 no inapp.\n",
    "    #'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "\n",
    "#    'emptyInside' :np.where(np.all(imgLabel == emptyInside, axis=-1)), bad idea\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "#print(labelsDic)\n",
    "#print(img.shape)\n",
    "\n",
    "mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "mask[labelsDic['fineInside']] = 1\n",
    "mask[labelsDic['fineInside2']] = 1\n",
    "mask[labelsDic['rockInside']] = 1\n",
    "#mask[labelsDic['inapInside']] = 1\n",
    "#mask[labelsDic['emptyInside']] = 1\n",
    "\n",
    "\n",
    "\n",
    "mask.dtype='uint8'\n",
    "maskOverlay = cv2.cvtColor(mask*255, cv2.COLOR_GRAY2BGR)\n",
    "maskOverlay[:,:,0] = 0\n",
    "maskOverlay[:,:,2] = 0\n",
    "\n",
    "\n",
    "opacity = 0.2\n",
    "cv2.addWeighted(maskOverlay, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "\n",
    "\n",
    "mask.dtype='uint8'\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "#cv2.imwrite(croppedMasksPath + fileName, mask)\n",
    "#cv2.imwrite(croppedOverlayedPath + fileName, img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Creating padded images for U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " 1. Some images are (480, 640, 3)   some are (480, 720, 3) so first we resize them all to (480, 640, 3)\n",
    " \n",
    " 2. Now that all images are 40W*480H, we downsample them by 4 to get 160W*120H. \n",
    "\n",
    " 3. Next, the VES U-Net pads these with 0 making them 162W*130H. But doing that in Keras leads to output being 160*128. So I pad the inputs with 0 to be 160W*128H to begin with.\n",
    " \n",
    " 4. The label input has 6 channels (size 128*160) 5 of them are below:\n",
    "\n",
    "    \"value\": [[\"WM_landmarks\"], [\"Fine_Inside\", \"Rock_inside\"], [\"Teeth\"], [\"Empty\", \"Shadow\", \"Dust\"], [\"Case\"]]\n",
    "\n",
    "    The 6th is background, which is everything that is not these. So in the image, the pixels have above labels are 0 and everything else is a 1. \n",
    "    \n",
    "    \n",
    "    ***Dust and shadow are supposed to be just inside, but there are examples of them outside. I am going to deviate from above in that I won't group [\"Empty\", \"Shadow\", \"Dust\"] just [\"Empty\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating the (128, 160, 1) labels \n",
    "generatedMaskPath = '/home/hooman/dataPreparation/hsTestSet/masks0PaddedForUNet/'\n",
    "\n",
    "for fileName in os.listdir(labelsPath):\n",
    "    \n",
    "    label = imread(labelsPath + fileName) \n",
    "    \n",
    "    \n",
    "    \n",
    "    #resize the label map.\n",
    "    imgLabelResized = cv2.resize(label, (640, 480)) \n",
    "\n",
    "    # you can downsample with numpy too. I use opencv to be consistant.    imgDs = img[::4, ::4, :]\n",
    "    imgLabelDs = cv2.resize(imgLabelResized, (0,0), fx=0.25, fy=0.25) \n",
    "\n",
    "    imgLabel = cv2.copyMakeBorder(imgLabelDs,4,4,0,0,cv2.BORDER_CONSTANT,value=(0,0,0,0))\n",
    "    \n",
    "    \n",
    "\n",
    "    mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), int)\n",
    "\n",
    "\n",
    "    labelsDic = {\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'case'       :np.where(np.all(imgLabel == case, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        'dust'       :np.where(np.all(imgLabel == dust, axis=-1)),\n",
    "    }\n",
    "\n",
    "    #channel 1\n",
    "    if 'wmInside' in labelsDic:\n",
    "        mask[labelsDic['wmInside']] = 1\n",
    "\n",
    "\n",
    "    #channel 2\n",
    "    if 'rockInside' in labelsDic:\n",
    "        mask[labelsDic['rockInside']] = 2\n",
    "\n",
    "    if 'fineInside' in labelsDic:\n",
    "        mask[labelsDic['fineInside']] = 2\n",
    "\n",
    "\n",
    "    #channel 3\n",
    "    if 'teeth' in labelsDic:\n",
    "        mask[labelsDic['teeth']] = 3\n",
    "\n",
    "\n",
    "    #channel 4\n",
    "    if 'emptyInside' in labelsDic:\n",
    "        mask[labelsDic['emptyInside']] = 4\n",
    "\n",
    "    if 'shadow' in labelsDic:\n",
    "        mask[labelsDic['shadow']] = 4\n",
    "\n",
    "    if 'dust' in labelsDic:\n",
    "        mask[labelsDic['dust']] = 4\n",
    "\n",
    "\n",
    "    #channel 5\n",
    "    if 'case' in labelsDic:\n",
    "        mask[labelsDic['case']] = 5\n",
    "\n",
    "        \n",
    "    cv2.imwrite(generatedMaskPath + fileName, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Correct Creating the (128, 160, 6) labels \n",
    "generatedMaskPath = '/home/hooman/dataPreparation/hsTrainingSet/masks6Chan/'\n",
    "\n",
    "for fileName in os.listdir(labelsPath):\n",
    "    \n",
    "    label = imread(labelsPath + fileName) \n",
    "    \n",
    "    \n",
    "    \n",
    "    #resize the label map.\n",
    "    imgLabelResized = cv2.resize(label, (640, 480)) \n",
    "\n",
    "    # you can downsample with numpy too. I use opencv to be consistant.    imgDs = img[::4, ::4, :]\n",
    "    imgLabelDs = cv2.resize(imgLabelResized, (0,0), fx=0.25, fy=0.25) \n",
    "\n",
    "    imgLabel = cv2.copyMakeBorder(imgLabelDs,4,4,0,0,cv2.BORDER_CONSTANT,value=(0,0,0,0))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1], 6), bool)\n",
    "\n",
    "    backGroundMask = np.ones((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "\n",
    "    \n",
    "    \n",
    "    labelsDic = {\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'case'       :np.where(np.all(imgLabel == case, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        'dust'       :np.where(np.all(imgLabel == dust, axis=-1)),\n",
    "    }\n",
    "\n",
    "    \n",
    "    \n",
    "    #channel 1\n",
    "    if 'wmInside' in labelsDic:\n",
    "        mask[labelsDic['wmInside'][0], labelsDic['wmInside'][1], 1] = 1\n",
    "        backGroundMask[labelsDic['wmInside']] = 0\n",
    "\n",
    "\n",
    "    #channel 2\n",
    "    if 'rockInside' in labelsDic:\n",
    "        mask[labelsDic['rockInside'][0], labelsDic['rockInside'][1], 2] = 1\n",
    "        backGroundMask[labelsDic['rockInside']] = 0\n",
    "\n",
    "    if 'fineInside' in labelsDic:\n",
    "        mask[labelsDic['fineInside'][0], labelsDic['fineInside'][1], 2] = 1\n",
    "        backGroundMask[labelsDic['fineInside']] = 0\n",
    "\n",
    "\n",
    "    #channel 3\n",
    "    if 'teeth' in labelsDic:\n",
    "        mask[labelsDic['teeth'][0], labelsDic['teeth'][1], 3] = 1\n",
    "        backGroundMask[labelsDic['teeth']] = 0\n",
    "\n",
    "\n",
    "    #channel 4\n",
    "    if 'emptyInside' in labelsDic:\n",
    "        mask[labelsDic['emptyInside'][0], labelsDic['emptyInside'][1], 4] = 1\n",
    "        backGroundMask[labelsDic['emptyInside']] = 0\n",
    "\n",
    "    if 'shadow' in labelsDic:\n",
    "        mask[labelsDic['shadow'][0], labelsDic['shadow'][1], 4] = 1\n",
    "        backGroundMask[labelsDic['shadow']] = 0\n",
    "\n",
    "    if 'dust' in labelsDic:\n",
    "        mask[labelsDic['dust'][0], labelsDic['dust'][1], 4] = 1\n",
    "        backGroundMask[labelsDic['dust']] = 0\n",
    "\n",
    "\n",
    "    #channel 5\n",
    "    if 'case' in labelsDic:\n",
    "        mask[labelsDic['case'][0], labelsDic['case'][1], 5] = 1\n",
    "        backGroundMask[labelsDic['case']] = 0\n",
    "\n",
    "\n",
    "    #channel 0\n",
    "    mask[:,:, 0] = backGroundMask\n",
    "    \n",
    "    \n",
    "    np.save(generatedMaskPath + fileName.replace(\".png\",\"\"), mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Overlaying Segmentation results for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Overlaying predicted segmentation resutls\n",
    "unet_pathToSavedResults = '/home/hooman/UNet/hsUnet_try13/predicted1chanImages/'\n",
    "testImagesPath = '/home/hooman/dataPreparation/hsTestSet/cropped/croppedImages/'\n",
    "\n",
    "# set this to '' to not save results but desplay the images instead\n",
    "pathToSaveOverlayResults = '/home/hooman/UNet/hsUnet_try13/croppedImagesPredictionsOverlayed/'\n",
    "\n",
    "\n",
    "for imgId in os.listdir(testImagesPath):\n",
    "\n",
    "    img = imread(testImagesPath + imgId)\n",
    "\n",
    "    pred = imread(unet_pathToSavedResults + imgId)\n",
    "    predRes = cv2.resize(pred, (img.shape[1], img.shape[0])) \n",
    "\n",
    "    predCol = cv2.cvtColor(predRes*255, cv2.COLOR_GRAY2BGR)\n",
    "    predCol[:,:,0] = 0\n",
    "    predCol[:,:,2] = 0\n",
    "\n",
    "    \n",
    "    opacity = 0.1\n",
    "    overIm = cv2.addWeighted(predCol, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "    \n",
    "    if pathToSaveOverlayResults != '':\n",
    "        cv2.imwrite(pathToSaveOverlayResults + imgId, overIm)\n",
    "    else:\n",
    "        imshow(overIm)\n",
    "        plt.title('overLayedImage')\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    imgRes = cv2.resize(img, (128, 128)) \n",
    "    imshow(img)\n",
    "    plt.title('img')\n",
    "    plt.show()\n",
    "\n",
    "    imshow(imgRes)\n",
    "    plt.title('imgRes')\n",
    "    plt.show()\n",
    "\n",
    "    imshow(pred)\n",
    "    plt.title('pred')\n",
    "    plt.show()\n",
    "\n",
    "    imshow(predRes)\n",
    "    plt.title('predRes')\n",
    "    plt.show()\n",
    "\n",
    "    imshow(predCol)\n",
    "    plt.title('predCol')\n",
    "    plt.show()\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Overlaying Ground Truth Masks multiple images\n",
    "pathToMasks =  '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCropped_masks/'\n",
    "pathToImages = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCropped_images/'\n",
    "pathToSaveOverlayResults = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCropped_overlay/'\n",
    "\n",
    "\n",
    "for imgId in os.listdir(pathToImages):\n",
    "\n",
    "    img = imread(pathToImages + imgId)\n",
    "    mask = imread(pathToMasks + imgId)\n",
    "\n",
    "    mask.dtype='uint8'\n",
    "    maskOverlay = cv2.cvtColor(mask*255, cv2.COLOR_GRAY2BGR)\n",
    "    maskOverlay[:,:,0] = 0\n",
    "    maskOverlay[:,:,2] = 0\n",
    "\n",
    "\n",
    "    opacity = 0.2\n",
    "    cv2.addWeighted(maskOverlay, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "    \n",
    "\n",
    "    mask.dtype='uint8'\n",
    "    \n",
    "    \n",
    "    cv2.imwrite(pathToSaveOverlayResults + imgId, img)\n",
    "    \n",
    "    #imshow(img)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Overlaying Ground Truth Masks single image\n",
    "\n",
    "pathToMasks = '/home/hooman/dataPreparation/hsTrainingSet/cropped/wrong_croppedMasks/'\n",
    "pathToImages = '/home/hooman/dataPreparation/hsTrainingSet/cropped/croppedImages/'\n",
    "\n",
    "imgId = '1_20161116-155500_0001n0_20737.png'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img = imread(pathToImages + imgId)\n",
    "mask = imread(pathToMasks + imgId)\n",
    "\n",
    "mask.dtype='uint8'\n",
    "maskOverlay = cv2.cvtColor(mask*255, cv2.COLOR_GRAY2BGR)\n",
    "maskOverlay[:,:,0] = 0\n",
    "maskOverlay[:,:,2] = 0\n",
    "\n",
    "\n",
    "opacity = 0.2\n",
    "cv2.addWeighted(maskOverlay, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "\n",
    "\n",
    "mask.dtype='uint8'\n",
    "\n",
    "imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Correcting ROI Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#function checking if two lines intersec\n",
    "\n",
    "def pointsCross(A,B,C):\n",
    "    return (C[1]-A[1]) * (B[0]-A[0]) > (B[1]-A[1]) * (C[0]-A[0])\n",
    "\n",
    "# Return true if line segments AB and CD intersect\n",
    "def linesIntersect(line1, line2):\n",
    "    A = np.array(line1[0])\n",
    "    B = np.array(line1[1])\n",
    "\n",
    "    C = np.array(line2[0])\n",
    "    D = np.array(line2[1])\n",
    "    \n",
    "    return pointsCross(A,C,D) != pointsCross(B,C,D) and pointsCross(A,B,C) != pointsCross(A,B,D)\n",
    "\n",
    "def unitTest():\n",
    "    line1 = ( (0, 10), (10,0) )\n",
    "    line2 = ( (15, 12), (10,10) ) \n",
    "    \n",
    "    line3 = ((89, 256), (112, 479))\n",
    "    line4 = ((104, 439), (134, 430))\n",
    "\n",
    "    assert linesIntersect(line1,line2) == False\n",
    "    assert linesIntersect(line3,line4) == True\n",
    "    \n",
    "unitTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Converting ROI points from ratio to abs and drawing them on image\n",
    "\n",
    "im = cv2.imread('/home/hooman/Downloads/RE__Invalid_FM_ROI/download.jpg')\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "jq = [\n",
    "    (0.1390625,0.5333333333333333),\n",
    "    (0.175,0.9979166666666667),\n",
    "    (0.1625,0.9145833333333333),\n",
    "    (0.209375,0.8958333333333334),\n",
    "    (0.1765625,0.825),\n",
    "    (0.26875,0.7854166666666667),\n",
    "    (0.2421875,0.7020833333333333),\n",
    "    (0.33125,0.6833333333333333),\n",
    "    (0.26875,0.71875),\n",
    "    (0.35,0.7375),\n",
    "    (0.4703125,0.6125),\n",
    "    (0.5265625,0.6145833333333334),\n",
    "    (0.5390625,0.7145833333333333),\n",
    "    (0.503125,0.7208333333333333),\n",
    "    (0.690625,0.825),\n",
    "    (0.6453125,0.8916666666666667),\n",
    "    (0.8328125,0.8604166666666667),\n",
    "    (0.809375,0.5541666666666667),\n",
    "    (0.728125,0.5520833333333334),\n",
    "    (0.6953125,0.47291666666666665),\n",
    "    (0.340625,0.38333333333333336)\n",
    "]\n",
    "\n",
    "\n",
    "jqConv = []\n",
    "for el in jq:\n",
    "    jqConv.append( ((int(el[0]*im.shape[1])),int(el[1]*im.shape[0])) )\n",
    "\n",
    "\n",
    "print(im.shape)\n",
    "print(jqConv)\n",
    "\n",
    "'''\n",
    "for i in range(len(jqConv)-1):\n",
    "    cv2.line(im, jqConv[i], jqConv[i+1], (255,0,0),2)\n",
    "    \n",
    "cv2.line(im, jqConv[len(jqConv)-1], jqConv[0], (255,0,0),2)\n",
    "\n",
    "cv2.imwrite('/home/hooman/Downloads/RE__Invalid_FM_ROI/res.png', im)\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def areSelfIntersecting(boundary_points):\n",
    "    \n",
    "    lines = []\n",
    "\n",
    "    for i in range(len(boundary_points)-1):\n",
    "        newLine = (boundary_points[i], boundary_points[i+1])\n",
    "\n",
    "        for oldLine in lines[:-1]:\n",
    "            if linesIntersect(oldLine, newLine):\n",
    "                return True\n",
    "\n",
    "        lines.append( newLine )\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#don't draw the edge that intersects boundary\n",
    "\n",
    "im = cv2.imread('/home/hooman/Downloads/RE__Invalid_FM_ROI/download.jpg')\n",
    "\n",
    "\n",
    "lines = []\n",
    "for i in range(len(jqConv)):\n",
    "    if i < len(jqConv)-1:\n",
    "        newLine = (jqConv[i], jqConv[i+1])\n",
    "    else:\n",
    "        newLine = (jqConv[len(jqConv)-1], jqConv[0])\n",
    "    \n",
    "    isOk = True\n",
    "    for oldLine in lines[:-1]:\n",
    "        if linesIntersect(oldLine, newLine):\n",
    "            print(i)\n",
    "            isOk = False\n",
    "            \n",
    "    if isOk:\n",
    "        cv2.line(im, newLine[0], newLine[1], (255,0,0),2)\n",
    "        lines.append( newLine )\n",
    "\n",
    "\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "areSelfIntersecting(jqConv[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Backhoe Shovels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### FMDL 3.1: SSD Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getAllBoundaries_backhoe(imgLabel, img=[]):\n",
    "    \n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        'emptyInside' :np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'case' :np.where(np.all(imgLabel == case, axis=-1)),\n",
    "        'teeth' :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'bucketOutside':np.where(np.all(imgLabel == bucketOutside, axis=-1)),\n",
    "        'sheave': np.where(np.all(imgLabel == sheave, axis=-1)),\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "  \n",
    "    \n",
    "    ##############################################\n",
    "    ############## Bucket Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    for labV in sortedLabelColsDic.values():\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    for labV in sortedLabelRowsDic.values():\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "\n",
    "    \n",
    "\n",
    "    #get the bucket boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0 : \n",
    "\n",
    "        (bucket_xmin, bucket_xmax, bucket_ymin, bucket_ymax) = (xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1])\n",
    "        \n",
    "        \n",
    "        croppedIm = imgLabel[0:bucket_xmax, bucket_ymin:bucket_ymax]\n",
    "        \n",
    "        #plt.imshow(croppedIm)\n",
    "        #plt.show()\n",
    "        \n",
    "        labelsDic2 = {\n",
    "            'rockInside' :np.where(np.all(croppedIm == rockInside, axis=-1)),\n",
    "            \n",
    "            'fineInside' :np.where(np.all(croppedIm == fineInside, axis=-1)),\n",
    "            \n",
    "            'fmInapp' :np.where(np.all(croppedIm == fmInapp, axis=-1)),\n",
    "            'inapInside' :np.where(np.all(croppedIm == inapInside, axis=-1)),   \n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "        #get the boundary for each label\n",
    "        sortedLabelColsDic = {}\n",
    "        sortedLabelRowsDic = {}\n",
    "        for k in labelsDic2.keys():\n",
    "            if len(labelsDic2[k][0]) > 0:\n",
    "                sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic2[k][0]),\n",
    "                sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic2[k][1]),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ##############################################\n",
    "        ############## matInside Boundary ###############\n",
    "        ##############################################\n",
    "        #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "        lowColVals = []\n",
    "        highColVals = []\n",
    "        for labV in sortedLabelColsDic.values():\n",
    "            for v in labV:\n",
    "                lowColVals.append(v[0])\n",
    "                highColVals.append(v[len(v)-1])\n",
    "\n",
    "        lowRowVals = []\n",
    "        highRowVals = []\n",
    "        for labV in sortedLabelRowsDic.values():\n",
    "            for v in labV:\n",
    "                lowRowVals.append(v[0])\n",
    "                highRowVals.append(v[len(v)-1])\n",
    "\n",
    "\n",
    "\n",
    "        #get the bucket boundary\n",
    "        xmins2 = np.sort(np.array(lowColVals))\n",
    "        xmaxs2 = np.sort(np.array(highColVals))\n",
    "        ymins2 = np.sort(np.array(lowRowVals))\n",
    "        ymaxs2 = np.sort(np.array(highRowVals))\n",
    "\n",
    "        if len(xmins2) > 0 and len(xmaxs2) > 0 and len(ymins2) > 0 and len(ymaxs2) > 0 : \n",
    "            boundariesDict['matInside'] = [xmins2[0], xmaxs2[len(xmaxs2)-1], ymins2[0] + bucket_ymin, ymaxs2[len(ymaxs2)-1] + bucket_ymin]\n",
    "        \n",
    "            #if bucket_xmin > xmins[0]:\n",
    "                #bucket_xmin = xmins[0]\n",
    "        \n",
    "        boundariesDict['bucket'] = [bucket_xmin, bucket_xmax, bucket_ymin, bucket_ymax]\n",
    "        \n",
    "        \n",
    "        if len(img) > 0:\n",
    "            cv2.rectangle(img,(bucket_ymin, bucket_xmin),(bucket_ymax, bucket_xmax),(0,255,255),3)\n",
    "            \n",
    "            if 'matInside' in boundariesDict:\n",
    "                (xmin, xmax, ymin, ymax) = boundariesDict['matInside']\n",
    "                cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,0,255),3)\n",
    "\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "        \n",
    "               \n",
    "\n",
    "\n",
    "\n",
    "        return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getAllBoundaries_backhoe_V2(imgLabel, img=[]):\n",
    "    \n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        'emptyInside' :np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'case' :np.where(np.all(imgLabel == case, axis=-1)),\n",
    "        'teeth' :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'bucketOutside':np.where(np.all(imgLabel == bucketOutside, axis=-1)),\n",
    "        'sheave': np.where(np.all(imgLabel == sheave, axis=-1)),\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "  \n",
    "    \n",
    "    ##############################################\n",
    "    ############## Bucket Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    for labV in sortedLabelColsDic.values():\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    for labV in sortedLabelRowsDic.values():\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "   # print(sortedLabelColsDic)\n",
    "\n",
    "    \n",
    "\n",
    "    #get the bucket boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0 : \n",
    "\n",
    "        (bucket_xmin, bucket_xmax, bucket_ymin, bucket_ymax) = (xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1])\n",
    "        \n",
    "        \n",
    "        if 'bucketOutsideCols' in sortedLabelColsDic:\n",
    "            \n",
    "           # print(sortedLabelColsDic['bucketOutsideCols'][0])\n",
    "            sortedBackOfShovelCols = np.sort(np.array(sortedLabelColsDic['bucketOutsideCols'][0]))\n",
    "            backOfBucketMinX = sortedBackOfShovelCols[0]\n",
    "            backOfBucketMaxX = sortedBackOfShovelCols[len(sortedBackOfShovelCols)-1]\n",
    "            \n",
    "            newMaxX = int( backOfBucketMinX + (backOfBucketMaxX - backOfBucketMinX)/2 )\n",
    "            \n",
    "            croppedIm = imgLabel[0:newMaxX, bucket_ymin:bucket_ymax]\n",
    "            \n",
    "            \n",
    "        if 'teethCols' in sortedLabelColsDic:\n",
    "            \n",
    "           # print(sortedLabelColsDic['bucketOutsideCols'][0])\n",
    "            sortedTeethCols = np.sort(np.array(sortedLabelColsDic['teethCols'][0]))\n",
    "            teethMinX = sortedTeethCols[0]\n",
    "            teethMaxX = sortedTeethCols[len(sortedTeethCols)-1]\n",
    "            \n",
    "            newMaxX = int( teethMinX + (teethMaxX - teethMinX)/2 )\n",
    "            \n",
    "            croppedIm = imgLabel[0:newMaxX, bucket_ymin:bucket_ymax]\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            croppedIm = imgLabel[0:bucket_xmax, bucket_ymin:bucket_ymax]\n",
    "        \n",
    "        #plt.imshow(croppedIm)\n",
    "        #plt.show()\n",
    "        \n",
    "        labelsDic2 = {\n",
    "            'rockInside' :np.where(np.all(croppedIm == rockInside, axis=-1)),\n",
    "            \n",
    "            'fineInside' :np.where(np.all(croppedIm == fineInside, axis=-1)),\n",
    "            \n",
    "            'fmInapp' :np.where(np.all(croppedIm == fmInapp, axis=-1)),\n",
    "            'inapInside' :np.where(np.all(croppedIm == inapInside, axis=-1)), \n",
    "            'shadow' :np.where(np.all(croppedIm == shadow, axis=-1)), \n",
    "            \n",
    "        }\n",
    "        \n",
    "        \n",
    "        #print(labelsDic2)\n",
    "\n",
    "\n",
    "\n",
    "        #get the boundary for each label\n",
    "        sortedLabelColsDic = {}\n",
    "        sortedLabelRowsDic = {}\n",
    "        for k in labelsDic2.keys():\n",
    "            if len(labelsDic2[k][0]) > 0:\n",
    "                sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic2[k][0]),\n",
    "                sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic2[k][1]),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ##############################################\n",
    "        ############## matInside Boundary ###############\n",
    "        ##############################################\n",
    "        #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "        lowColVals = []\n",
    "        highColVals = []\n",
    "        for labV in sortedLabelColsDic.values():\n",
    "            for v in labV:\n",
    "                lowColVals.append(v[0])\n",
    "                highColVals.append(v[len(v)-1])\n",
    "\n",
    "        lowRowVals = []\n",
    "        highRowVals = []\n",
    "        for labV in sortedLabelRowsDic.values():\n",
    "            for v in labV:\n",
    "                lowRowVals.append(v[0])\n",
    "                highRowVals.append(v[len(v)-1])\n",
    "\n",
    "\n",
    "\n",
    "        #get the bucket boundary\n",
    "        xmins2 = np.sort(np.array(lowColVals))\n",
    "        xmaxs2 = np.sort(np.array(highColVals))\n",
    "        ymins2 = np.sort(np.array(lowRowVals))\n",
    "        ymaxs2 = np.sort(np.array(highRowVals))\n",
    "\n",
    "        if len(xmins2) > 0 and len(xmaxs2) > 0 and len(ymins2) > 0 and len(ymaxs2) > 0 : \n",
    "            boundariesDict['matInside'] = [xmins2[0], xmaxs2[len(xmaxs2)-1], ymins2[0] + bucket_ymin, ymaxs2[len(ymaxs2)-1] + bucket_ymin]\n",
    "        \n",
    "            #if bucket_xmin > xmins[0]:\n",
    "                #bucket_xmin = xmins[0]\n",
    "                \n",
    "                \n",
    "            if bucket_xmin > xmins2[0]:\n",
    "                bucket_xmin = xmins2[0]\n",
    "        \n",
    "        boundariesDict['bucket'] = [bucket_xmin, bucket_xmax, bucket_ymin, bucket_ymax]\n",
    "        \n",
    "        \n",
    "        if len(img) > 0:\n",
    "            cv2.rectangle(img,(bucket_ymin, bucket_xmin),(bucket_ymax, bucket_xmax),(0,255,255),3)\n",
    "            \n",
    "            if 'matInside' in boundariesDict:\n",
    "                (xmin, xmax, ymin, ymax) = boundariesDict['matInside']\n",
    "                cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,0,255),3)\n",
    "\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "        \n",
    "               \n",
    "\n",
    "\n",
    "\n",
    "        return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Finding matInside and bucket boundaries. For Backhoe\n",
    "rows = []\n",
    "\n",
    "#for fileName in os.listdir(labelsPath):\n",
    "for fileName in os.listdir('/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/backhoe/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_backhoe__try1/validationSet/'):\n",
    "    \n",
    "    imgFilePath = imagesPath + fileName\n",
    "    \n",
    "    imgLabel = imread(labelsPath + fileName)\n",
    "    \n",
    "    #I added this for try3  ssd-multiclass-tries 1 and 2 didnt have this.\n",
    "    imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "    \n",
    "    print(\"processing file: \" + fileName)\n",
    "    \n",
    "    \n",
    "    #I used this for most images in training FMDL3.1 except the some cases where the inside material is defined by back of bucket. But the V2 should work with everything\n",
    "    allBoundaries = getAllBoundaries_backhoe(imgLabel)\n",
    "    \n",
    "    #Tried this for all reprocesseds.\n",
    "    #allBoundaries = getAllBoundaries_backhoe_V2(imgLabel)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if allBoundaries:\n",
    "        if('bucket' in allBoundaries):\n",
    "            # write up the rows\n",
    "            (xmin, xmax, ymin, ymax) = allBoundaries['bucket']\n",
    "            row = fileName + \",\" + imgFilePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"bucket\" + \"\\n\"\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "        else:\n",
    "            print(\"ERROR: Found no bucket boundary.\\n\")\n",
    "\n",
    "\n",
    "\n",
    "        if('matInside' in allBoundaries):\n",
    "            if len(allBoundaries['matInside']) == 4:\n",
    "                (xmin, xmax, ymin, ymax) = allBoundaries['matInside']\n",
    "                row = fileName + \",\" + imgFilePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"matInside\" + \"\\n\"\n",
    "            else:\n",
    "                print(\"ERROR: Found more than one matInside Boundaries. This should NOT happen\\n\")\n",
    "\n",
    "            rows.append(row)        \n",
    "\n",
    "    \n",
    "        \n",
    "# shuffle the rows\n",
    "#from random import shuffle\n",
    "#shuffle(rows)       \n",
    "        \n",
    "#print(\"processes \"+ str(len(rows)) + \" rows\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "writeRowsToCsv(rows, \"/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/backhoe/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_backhoe__try1/negetiveExamplesForTraining.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# (singleImage for Debug) Finding matInside and bucket boundaries. For Backhoe\n",
    "\n",
    "#fileName = '1_20180703-100000_1001n0_23970.png'\n",
    "#fileName = '1_20180704-200300_1001n0_9159.png'\n",
    "#fileName = '1_20180703-101500_1001n0_2971.png'\n",
    "#fileName = '1_20180703-103000_1001n0_8378.png'\n",
    "#fileName = '1_20180704-084800_1001n0_694.png'\n",
    "fileName = '1_20180703-213900_1001n0_1725.png'\n",
    "    \n",
    "imgFilePath = imagesPath + fileName\n",
    "\n",
    "imgLabel = imread(labelsPath + fileName)\n",
    "img = imread(imagesPath + fileName)\n",
    "\n",
    "#I added this for try3  ssd-multiclass-tries 1 and 2 didnt have this.\n",
    "imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "print(\"processing file: \" + fileName)\n",
    "\n",
    "allBoundaries = getAllBoundaries_backhoe_V2(imgLabel, img)\n",
    "rows = [] \n",
    "\n",
    "if allBoundaries:\n",
    "    if('bucket' in allBoundaries):\n",
    "        # write up the rows\n",
    "        (xmin, xmax, ymin, ymax) = allBoundaries['bucket']\n",
    "        row = fileName + \",\" + imgFilePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"bucket\" + \"\\n\"\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    else:\n",
    "        print(\"ERROR: Found no bucket boundary.\\n\")\n",
    "\n",
    "\n",
    "    if('matInside' in allBoundaries):\n",
    "        if len(allBoundaries['matInside']) == 4:\n",
    "            (xmin, xmax, ymin, ymax) = allBoundaries['matInside']\n",
    "            \n",
    "            row = fileName + \",\" + imgFilePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"matInside\" + \"\\n\"\n",
    "        else:\n",
    "            print(\"ERROR: Found more than one matInside Boundaries. This should NOT happen\\n\")\n",
    "\n",
    "        rows.append(row)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### FMDL 3.1 (bucket width correction): SSD Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getAllBoundaries_backhoe_V3(imgLabel, img=[]):\n",
    "    \n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        'emptyInside' :np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'case' :np.where(np.all(imgLabel == case, axis=-1)),\n",
    "        'teeth' :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'bucketOutside':np.where(np.all(imgLabel == bucketOutside, axis=-1)),\n",
    "        'sheave': np.where(np.all(imgLabel == sheave, axis=-1)),\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "  \n",
    "    \n",
    "    ##############################################\n",
    "    ############## Bucket Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    for labV in sortedLabelColsDic.values():\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    for labV in sortedLabelRowsDic.values():\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "   # print(sortedLabelColsDic)\n",
    "\n",
    "    \n",
    "\n",
    "    #get the bucket boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0 : \n",
    "\n",
    "        (bucket_xmin, bucket_xmax, bucket_ymin, bucket_ymax) = (xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1])\n",
    "        \n",
    "        \n",
    "        if 'bucketOutsideCols' in sortedLabelColsDic:\n",
    "            \n",
    "           # print(sortedLabelColsDic['bucketOutsideCols'][0])\n",
    "            sortedBackOfShovelCols = np.sort(np.array(sortedLabelColsDic['bucketOutsideCols'][0]))\n",
    "            backOfBucketMinX = sortedBackOfShovelCols[0]\n",
    "            backOfBucketMaxX = sortedBackOfShovelCols[len(sortedBackOfShovelCols)-1]\n",
    "            \n",
    "            newMaxX = int( backOfBucketMinX + (backOfBucketMaxX - backOfBucketMinX)/2 )\n",
    "            \n",
    "            croppedIm = imgLabel[0:newMaxX, bucket_ymin:bucket_ymax]\n",
    "            \n",
    "            \n",
    "        if 'teethCols' in sortedLabelColsDic:\n",
    "            \n",
    "           # print(sortedLabelColsDic['bucketOutsideCols'][0])\n",
    "            sortedTeethCols = np.sort(np.array(sortedLabelColsDic['teethCols'][0]))\n",
    "            teethMinX = sortedTeethCols[0]\n",
    "            teethMaxX = sortedTeethCols[len(sortedTeethCols)-1]\n",
    "            \n",
    "            newMaxX = int( teethMinX + (teethMaxX - teethMinX)/2 )\n",
    "            \n",
    "            croppedIm = imgLabel[0:newMaxX, bucket_ymin:bucket_ymax]\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            croppedIm = imgLabel[0:bucket_xmax, bucket_ymin:bucket_ymax]\n",
    "        \n",
    "        #plt.imshow(croppedIm)\n",
    "        #plt.show()\n",
    "        \n",
    "        labelsDic2 = {\n",
    "            'rockInside' :np.where(np.all(croppedIm == rockInside, axis=-1)),\n",
    "            \n",
    "            'fineInside' :np.where(np.all(croppedIm == fineInside, axis=-1)),\n",
    "            \n",
    "            'fmInapp' :np.where(np.all(croppedIm == fmInapp, axis=-1)),\n",
    "            'inapInside' :np.where(np.all(croppedIm == inapInside, axis=-1)), \n",
    "            'shadow' :np.where(np.all(croppedIm == shadow, axis=-1)), \n",
    "            \n",
    "        }\n",
    "        \n",
    "        \n",
    "        #print(labelsDic2)\n",
    "\n",
    "\n",
    "\n",
    "        #get the boundary for each label\n",
    "        sortedLabelColsDic = {}\n",
    "        sortedLabelRowsDic = {}\n",
    "        for k in labelsDic2.keys():\n",
    "            if len(labelsDic2[k][0]) > 0:\n",
    "                sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic2[k][0]),\n",
    "                sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic2[k][1]),\n",
    "\n",
    "\n",
    "\n",
    "        ##############################################\n",
    "        ############## matInside Boundary ###############\n",
    "        ##############################################\n",
    "        #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "        lowColVals = []\n",
    "        highColVals = []\n",
    "        for labV in sortedLabelColsDic.values():\n",
    "            for v in labV:\n",
    "                lowColVals.append(v[0])\n",
    "                highColVals.append(v[len(v)-1])\n",
    "\n",
    "        lowRowVals = []\n",
    "        highRowVals = []\n",
    "        for labV in sortedLabelRowsDic.values():\n",
    "            for v in labV:\n",
    "                lowRowVals.append(v[0])\n",
    "                highRowVals.append(v[len(v)-1])\n",
    "\n",
    "\n",
    "\n",
    "        #get the bucket boundary\n",
    "        xmins2 = np.sort(np.array(lowColVals))\n",
    "        xmaxs2 = np.sort(np.array(highColVals))\n",
    "        ymins2 = np.sort(np.array(lowRowVals))\n",
    "        ymaxs2 = np.sort(np.array(highRowVals))\n",
    "\n",
    "        if len(xmins2) > 0 and len(xmaxs2) > 0 and len(ymins2) > 0 and len(ymaxs2) > 0 : \n",
    "            boundariesDict['matInside'] = [xmins2[0], xmaxs2[len(xmaxs2)-1], ymins2[0] + bucket_ymin, ymaxs2[len(ymaxs2)-1] + bucket_ymin]\n",
    "        \n",
    "            #if bucket_xmin > xmins[0]:\n",
    "                #bucket_xmin = xmins[0]\n",
    "                \n",
    "                \n",
    "            if bucket_xmin > xmins2[0]:\n",
    "                bucket_xmin = xmins2[0]\n",
    "        \n",
    "        boundariesDict['bucket'] = [bucket_xmin, bucket_xmax, bucket_ymin, bucket_ymax]\n",
    "        \n",
    "        \n",
    "        if len(img) > 0:\n",
    "            cv2.rectangle(img,(bucket_ymin, bucket_xmin),(bucket_ymax, bucket_xmax),(0,255,255),3)\n",
    "            \n",
    "            if 'matInside' in boundariesDict:\n",
    "                (xmin, xmax, ymin, ymax) = boundariesDict['matInside']\n",
    "                cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,0,255),3)\n",
    "\n",
    "#            plt.imshow(img)\n",
    "#            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        labelsDic3 = {\n",
    "            'case' :np.where(np.all(croppedIm == case, axis=-1)),\n",
    "            'sheave': np.where(np.all(croppedIm == sheave, axis=-1)),\n",
    "            \n",
    "            'rockInside' :np.where(np.all(croppedIm == rockInside, axis=-1)),\n",
    "            'fineInside' :np.where(np.all(croppedIm == fineInside, axis=-1)),\n",
    "            'fmInapp' :np.where(np.all(croppedIm == fmInapp, axis=-1)),\n",
    "            'inapInside' :np.where(np.all(croppedIm == inapInside, axis=-1)), \n",
    "            'shadow' :np.where(np.all(croppedIm == shadow, axis=-1)), \n",
    "        }\n",
    "    \n",
    "      #  print(\"\\n\\n\")\n",
    "      #  print('labelsDic3')\n",
    "      #  print(labelsDic3)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "        #get the edge closer to cable\n",
    "        offsetToTopOfMatInside = 20\n",
    "        corrected_boundariesDict = {}\n",
    "        sortedLabelColsDic = {}\n",
    "        sortedLabelRowsDic = {}\n",
    "        if 'matInside' in boundariesDict:\n",
    "            (xmin_matInside, xmax_matInside, ymin_matInside, ymax_matInside) = boundariesDict['matInside']\n",
    "      \n",
    "            for k in labelsDic3.keys():\n",
    "                if len(labelsDic3[k][0]) > 0:\n",
    "                    sortedLabelColsDic[k+'Cols'] = []\n",
    "                    sortedLabelRowsDic[k+'Rows'] = []\n",
    "                    for i in range(len(labelsDic3[k][0])):\n",
    "                        \n",
    "                        if labelsDic3[k][0][i] < (xmin_matInside + offsetToTopOfMatInside):\n",
    "                            sortedLabelColsDic[k+'Cols'].append(labelsDic3[k][0][i])\n",
    "                            sortedLabelRowsDic[k+'Rows'].append(labelsDic3[k][1][i])\n",
    "                            \n",
    "                            \n",
    "                    sortedLabelColsDic[k+'Cols'].sort()\n",
    "                    sortedLabelRowsDic[k+'Rows'].sort()\n",
    "                    \n",
    "                    \n",
    "\n",
    "            #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "            lowColVals = []\n",
    "            highColVals = []\n",
    "            for labV in sortedLabelColsDic.values():\n",
    "                if len(labV) > 0:\n",
    "                    lowColVals.append(labV[0])\n",
    "                    highColVals.append(labV[len(labV)-1])\n",
    "\n",
    "            lowRowVals = []\n",
    "            highRowVals = []\n",
    "            for labV in sortedLabelRowsDic.values():\n",
    "                if len(labV) > 0:\n",
    "                    lowRowVals.append(labV[0])\n",
    "                    highRowVals.append(labV[len(labV)-1])\n",
    "\n",
    "\n",
    "        else:\n",
    "            for k in labelsDic3.keys():\n",
    "                if len(labelsDic3[k][0]) > 0:\n",
    "                    sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic3[k][0]),\n",
    "                    sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic3[k][1]),\n",
    "                    \n",
    "\n",
    "            #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "            lowColVals = []\n",
    "            highColVals = []\n",
    "            for labV in sortedLabelColsDic.values():\n",
    "                for v in labV:\n",
    "                    lowColVals.append(v[0])\n",
    "                    highColVals.append(v[len(v)-1])\n",
    "\n",
    "            lowRowVals = []\n",
    "            highRowVals = []\n",
    "            for labV in sortedLabelRowsDic.values():\n",
    "                for v in labV:\n",
    "                    lowRowVals.append(v[0])\n",
    "                    highRowVals.append(v[len(v)-1])\n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "        (xmins2, xmaxs2, ymins2, ymaxs2) = ([],[],[],[])\n",
    "        ymins2 = np.sort(np.array(lowRowVals))\n",
    "        ymaxs2 = np.sort(np.array(highRowVals))\n",
    "        xmins2 = np.sort(np.array(lowColVals))\n",
    "        xmaxs2 = np.sort(np.array(highColVals))\n",
    "            \n",
    "\n",
    "\n",
    "        if len(xmins2) > 0 and len(xmaxs2) > 0 and len(ymins2) > 0 and len(ymaxs2) > 0 : \n",
    "            boundariesDict['case'] = [xmins2[0], xmaxs2[len(xmaxs2)-1] + offsetToTopOfMatInside, ymins2[0] + bucket_ymin, ymaxs2[len(ymaxs2)-1] + bucket_ymin]\n",
    "        \n",
    "\n",
    "        if len(img) > 0:\n",
    "            if 'case' in boundariesDict:\n",
    "                (xmin, xmax, ymin, ymax) = boundariesDict['case']\n",
    "                cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(255,0,255),3)\n",
    "\n",
    "           # plt.imshow(img)\n",
    "           # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "               \n",
    "        print('boundariesDict')\n",
    "        print(boundariesDict)\n",
    "\n",
    "\n",
    "        return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Finding case, matInside and bucket boundaries. For Backhoe V3\n",
    "rows = []\n",
    "\n",
    "for fileName in os.listdir(imagesPath):\n",
    "    \n",
    "    imgFilePath = imagesPath + fileName\n",
    "\n",
    "    imgLabel = imread(labelsPath + fileName)\n",
    "    img = imread(imagesPath + fileName)\n",
    "\n",
    "    #I added this for try3  ssd-multiclass-tries 1 and 2 didnt have this.\n",
    "    imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "    print(\"processing file: \" + fileName)\n",
    "\n",
    "    allBoundaries = getAllBoundaries_backhoe_V3(imgLabel, img)\n",
    " \n",
    "    if allBoundaries:\n",
    "        if('bucket' in allBoundaries):\n",
    "            # write up the rows\n",
    "            (xmin, xmax, ymin, ymax) = allBoundaries['bucket']\n",
    "            row = fileName + \",\" + imgFilePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"bucket\" + \"\\n\"\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "        else:\n",
    "            print(\"ERROR: Found no bucket boundary.\\n\")\n",
    "\n",
    "\n",
    "        if('matInside' in allBoundaries):\n",
    "            if len(allBoundaries['matInside']) == 4:\n",
    "                (xmin, xmax, ymin, ymax) = allBoundaries['matInside']\n",
    "\n",
    "                row = fileName + \",\" + imgFilePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"matInside\" + \"\\n\"\n",
    "            else:\n",
    "                print(\"ERROR: Found more than one matInside Boundaries. This should NOT happen\\n\")\n",
    "\n",
    "            rows.append(row)  \n",
    "\n",
    "\n",
    "        if('case' in allBoundaries):\n",
    "            if len(allBoundaries['case']) == 4:\n",
    "                (xmin, xmax, ymin, ymax) = allBoundaries['case']\n",
    "\n",
    "                row = fileName + \",\" + imgFilePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"case\" + \"\\n\"\n",
    "            else:\n",
    "                print(\"ERROR: Found more than one case Boundaries. This should NOT happen\\n\")\n",
    "\n",
    "            rows.append(row)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 11543 rows to csv file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "writeRowsToCsv(rows, \"/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may10-2019/trainingSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# (singleImage for Debug) Finding matInside and bucket boundaries. For Backhoe\n",
    "\n",
    "fileName = '1_20180703-101500_1001n0_6232.png'\n",
    "#fileName = '1_20180703-101500_1001n0_13151.png'\n",
    "    \n",
    "imgFilePath = imagesPath + fileName\n",
    "\n",
    "imgLabel = imread(labelsPath + fileName)\n",
    "img = imread(imagesPath + fileName)\n",
    "\n",
    "#I added this for try3  ssd-multiclass-tries 1 and 2 didnt have this.\n",
    "imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "print(\"processing file: \" + fileName)\n",
    "\n",
    "allBoundaries = getAllBoundaries_backhoe_V3(imgLabel, img)\n",
    "rows = [] \n",
    "\n",
    "if allBoundaries:\n",
    "    if('bucket' in allBoundaries):\n",
    "        # write up the rows\n",
    "        (xmin, xmax, ymin, ymax) = allBoundaries['bucket']\n",
    "        row = fileName + \",\" + imgFilePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"bucket\" + \"\\n\"\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    else:\n",
    "        print(\"ERROR: Found no bucket boundary.\\n\")\n",
    "\n",
    "\n",
    "    if('matInside' in allBoundaries):\n",
    "        if len(allBoundaries['matInside']) == 4:\n",
    "            (xmin, xmax, ymin, ymax) = allBoundaries['matInside']\n",
    "            \n",
    "            row = fileName + \",\" + imgFilePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"matInside\" + \"\\n\"\n",
    "        else:\n",
    "            print(\"ERROR: Found more than one matInside Boundaries. This should NOT happen\\n\")\n",
    "\n",
    "        rows.append(row)  \n",
    "        \n",
    "        \n",
    "    if('case' in allBoundaries):\n",
    "        if len(allBoundaries['case']) == 4:\n",
    "            (xmin, xmax, ymin, ymax) = allBoundaries['case']\n",
    "            \n",
    "            row = fileName + \",\" + imgFilePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"case\" + \"\\n\"\n",
    "        else:\n",
    "            print(\"ERROR: Found more than one case Boundaries. This should NOT happen\\n\")\n",
    "\n",
    "        rows.append(row)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### FMDL 3.1 (training unet for the 1st time after Telfer bug): UNET Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getFullSize_LabelDic_fromCropped(labelsDicCropped, bucket_xmin, bucket_ymin):\n",
    "    labelsDicFullSize = deepcopy(labelsDicCropped)\n",
    "\n",
    "    for key in labelsDicCropped.keys():\n",
    "        if len(labelsDicCropped[key]) > 1:\n",
    "            if len(labelsDicCropped[key][0]) > 1 and len(labelsDicCropped[key][1]) > 1:\n",
    "                for i in range(len(labelsDicCropped[key][0])):\n",
    "                    labelsDicFullSize[key][0][i] = labelsDicCropped[key][0][i] + bucket_ymin\n",
    "\n",
    "                for i in range(len(labelsDicCropped[key][1])):\n",
    "                    labelsDicFullSize[key][1][i] = labelsDicCropped[key][1][i] + bucket_xmin\n",
    "\n",
    "    return labelsDicFullSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#creating both full size and cropped masks and overlays\n",
    "\n",
    "imagesPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may10-2019/images_fromJira/'\n",
    "\n",
    "labelsPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may10-2019/labels_fromJira/'\n",
    "\n",
    "bucketBoundariesDict = getRowsDictFromCsvSaveJustBucketBoundingBox('/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may10-2019/bucketBoundaries.csv')\n",
    "\n",
    "\n",
    "masksSavePath_fullSize = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may10-2019/masks_full/'\n",
    "\n",
    "masksSavePath_cropped = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may10-2019/masks_cropped/'\n",
    "\n",
    "imagesSavePath_cropped = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may10-2019/images_cropped/'\n",
    "\n",
    "overlaySavePath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may10-2019/overlays_full/'\n",
    "\n",
    "\n",
    "for fileName in os.listdir(imagesPath):\n",
    "\n",
    "    ######################### load bucket boundary ##########################################################\n",
    "    print(\"prcessing imgId: \" + fileName + \"\\n\")\n",
    "    \n",
    "    if fileName in bucketBoundariesDict:\n",
    "        (xmin, xmax, ymin, ymax) = (bucketBoundariesDict[fileName][0:4])\n",
    "        (bucket_xmin, bucket_xmax, bucket_ymin, bucket_ymax) = (int(xmin), int(xmax), int(ymin), int(ymax))\n",
    "    else:\n",
    "        print('Error:skipping image. no bucketBoundingBox for\\n' + fileName)\n",
    "        continue\n",
    "    ########################################################################################################\n",
    "        \n",
    "        \n",
    "    ######################### load and cropp image and label################################################\n",
    "    imgLabel = imread(labelsPath + fileName)\n",
    "    imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "    croppedLabel = imgLabel[bucket_ymin:bucket_ymax, bucket_xmin:bucket_xmax]\n",
    "\n",
    "    img = imread(imagesPath + fileName)\n",
    "    croppedImage = img[bucket_ymin:bucket_ymax, bucket_xmin:bucket_xmax]\n",
    "    cv2.imwrite(imagesSavePath_cropped + fileName, croppedImage)\n",
    "    ########################################################################################################\n",
    "    \n",
    "\n",
    "    \n",
    "    #Create a mas from cropped image\n",
    "    labelsDicCropped = {\n",
    "        'rockInside' : np.where(np.all(croppedLabel == rockInside, axis=-1)),\n",
    "        'fineInside' : np.where(np.all(croppedLabel == fineInside, axis=-1)),\n",
    "        'fmInapp'    : np.where(np.all(croppedLabel == fmInapp, axis=-1)),\n",
    "    }\n",
    "    \n",
    "    labelsDicFullsize = getFullSize_LabelDic_fromCropped(labelsDicCropped, bucket_xmin, bucket_ymin)\n",
    "\n",
    "\n",
    "    \n",
    "    ################################## create full size masks ###############################################\n",
    "    mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "    mask2 = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "    mask.dtype='uint8'\n",
    "    mask2.dtype='uint8'\n",
    "\n",
    "    mask[labelsDicFullsize['fineInside']] = 1\n",
    "    mask[labelsDicFullsize['rockInside']] = 1\n",
    "    mask[labelsDicFullsize['fmInapp']] = 1\n",
    "    \n",
    "    #Remove the points that are not in the largest contour from mask\n",
    "    _,contours,_ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE, offset=(0, 0))\n",
    "\n",
    "    if contours:\n",
    "        max_cnt = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # cv2.drawContours(mask2, max_cnt, -1, 1, cv2.FILLED, 8) thos does NOT fill up the inside of contour\n",
    "        cv2.drawContours(mask2, [max_cnt], -1, 1, cv2.FILLED, 8)\n",
    "\n",
    "\n",
    "    #if no contours found, mask2 will remain as all 0s\n",
    "    cv2.imwrite(masksSavePath_fullSize + fileName, mask2)\n",
    "    #########################################################################################################\n",
    "    \n",
    "    \n",
    "    ###################################### create cropped masks #############################################\n",
    "    mask_cropped = np.zeros((croppedLabel.shape[0], croppedLabel.shape[1]), bool)\n",
    "    mask2_cropped = np.zeros((croppedLabel.shape[0], croppedLabel.shape[1]), bool)\n",
    "    mask_cropped.dtype='uint8'\n",
    "    mask2_cropped.dtype='uint8'\n",
    "\n",
    "    mask_cropped[labelsDicCropped['fineInside']] = 1\n",
    "    mask_cropped[labelsDicCropped['rockInside']] = 1\n",
    "    mask_cropped[labelsDicCropped['fmInapp']] = 1\n",
    "    \n",
    "    #Remove the points that are not in the largest contour from mask\n",
    "    _,contours2,_ = cv2.findContours(mask_cropped, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE, offset=(0, 0))\n",
    "\n",
    "    if contours:\n",
    "        max_cnt2 = max(contours2, key=cv2.contourArea)\n",
    "\n",
    "        # cv2.drawContours(mask2, max_cnt, -1, 1, cv2.FILLED, 8) thos does NOT fill up the inside of contour\n",
    "        cv2.drawContours(mask2_cropped, [max_cnt2], -1, 1, cv2.FILLED, 8)\n",
    "\n",
    "\n",
    "    #if no contours found, mask2 will remain as all 0s\n",
    "    cv2.imwrite(masksSavePath_cropped + fileName, mask2_cropped)\n",
    "    #########################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ###################################### create overlays ##################################################\n",
    "    #get the overlay\n",
    "    maskOverlay = cv2.cvtColor(mask2*255, cv2.COLOR_GRAY2BGR)\n",
    "    maskOverlay[:,:,0] = 0\n",
    "    maskOverlay[:,:,2] = 0\n",
    "\n",
    "    opacity = 0.2\n",
    "    cv2.addWeighted(maskOverlay, opacity, img, 1 - opacity, 0, img)\n",
    "    cv2.imwrite(overlaySavePath + fileName, img)\n",
    "    #########################################################################################################\n",
    "    \n",
    "\n",
    "    \n",
    "    '''        \n",
    "    plt.imshow(mask)\n",
    "    plt.title('mask1')\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(mask2)\n",
    "    plt.title('mask2 final')\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.title('overlayed img')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.imshow(mask2_cropped)\n",
    "    plt.title('mask2_cropped')\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(mask2)\n",
    "    plt.title('mask2 final')\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(croppedImage)\n",
    "    plt.title('croppedImage')\n",
    "    plt.show()\n",
    "    break\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gt_rows = readCsvRows(\"/home/hooman/backhoeOpticalScene/boxDetectors/try3_ssdMultiClass_withInappInMatInside_upsideDownShovelsRemoved/fineAndRockAndInapInMatInside_backhoe_shuffled_UpsideDownShovelsRemoved.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#creating full size masks (used for FMDL 3.0)\n",
    "\n",
    "imagesPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may10-2019/images_fromJira/'\n",
    "labelsPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may10-2019/labels_fromJira/'\n",
    "\n",
    "masksSavePath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may10-2019/full_masks/'\n",
    "\n",
    "overlaySavePath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may10-2019/full_overlays/'\n",
    "\n",
    "\n",
    "for fileName in os.listdir(imagesPath):\n",
    "\n",
    "    print(\"prcessing imgId: \" + fileName + \"\\n\")\n",
    "\n",
    "    #read the image from csv row\n",
    "    img = imread(imagesPath + fileName)\n",
    "    \n",
    "    imgLabel = imread(labelsPath + fileName)\n",
    "    imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "\n",
    "    #Create a mas from cropped image\n",
    "    labelsDic = {\n",
    "        'rockInside' : np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' : np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'fmInapp'    : np.where(np.all(imgLabel == fmInapp, axis=-1)),\n",
    "    }\n",
    "\n",
    "\n",
    "    mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "    mask2 = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "    mask.dtype='uint8'\n",
    "    mask2.dtype='uint8'\n",
    "\n",
    "    mask[labelsDic['fineInside']] = 1\n",
    "    mask[labelsDic['rockInside']] = 1\n",
    "    mask[labelsDic['fmInapp']] = 1\n",
    "\n",
    "\n",
    "\n",
    "    #Remove the points that are not in the largest contour from mask\n",
    "    _,contours,_ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE, offset=(0, 0))\n",
    "\n",
    "    if contours:\n",
    "        max_cnt = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # cv2.drawContours(mask2, max_cnt, -1, 1, cv2.FILLED, 8) thos does NOT fill up the inside of contour\n",
    "        cv2.drawContours(mask2, [max_cnt], -1, 1, cv2.FILLED, 8)\n",
    "\n",
    "\n",
    "    #if no contours found, mask2 will remain as all 0s\n",
    "    cv2.imwrite(masksSavePath + fileName, mask2)\n",
    "\n",
    "\n",
    "    #get the overlay\n",
    "    maskOverlay = cv2.cvtColor(mask2*255, cv2.COLOR_GRAY2BGR)\n",
    "    maskOverlay[:,:,0] = 0\n",
    "    maskOverlay[:,:,2] = 0\n",
    "\n",
    "    opacity = 0.2\n",
    "    cv2.addWeighted(maskOverlay, opacity, img, 1 - opacity, 0, img)\n",
    "    \n",
    "    cv2.imwrite(overlaySavePath + fileName, img)\n",
    "\n",
    "\n",
    "    '''        \n",
    "    plt.imshow(mask)\n",
    "    plt.title('mask1')\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(mask2)\n",
    "    plt.title('mask2 final')\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.title('overlayed img')\n",
    "    plt.show()\n",
    "    break\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# random crop the FULL masks create above. You need FULL images and Masks here not cropped. \n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "offsetsToApply = [50,75, 100, 125, 150, 175]\n",
    "\n",
    "dirToSaveImages = '/home/hooman/backhoeOpticalScene/roiDelineators/try4-csvFrom-ssdTry3-withInapp-reducedNumberOfempyBuckets-BatchSize4/randomCroppedImages/'\n",
    "\n",
    "dirToSaveMasks = '/home/hooman/backhoeOpticalScene/roiDelineators/try4-csvFrom-ssdTry3-withInapp-reducedNumberOfempyBuckets-BatchSize4/randomCroppedMasks/'\n",
    "\n",
    "\n",
    "dirToReadImages = '/home/hooman/backhoeOpticalScene/roiDelineators/try4-csvFrom-ssdTry3-withInapp-reducedNumberOfempyBuckets-BatchSize4/images/'\n",
    "\n",
    "dirToReadMasks = '/home/hooman/backhoeOpticalScene/roiDelineators/try4-csvFrom-ssdTry3-withInapp-reducedNumberOfempyBuckets-BatchSize4/full-masks_withInapp/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for row in gt_rows[1:len(gt_rows)-1]:\n",
    "    \n",
    "    vals = row.split(',')\n",
    "\n",
    "    if os.path.exists(dirToReadImages + vals[0]) and os.path.exists(dirToReadMasks + vals[0]):\n",
    "        \n",
    "        try:\n",
    "            imgPil = Image.open(dirToReadImages + vals[0])\n",
    "            img = np.array(imgPil) \n",
    "            imgPil.close()\n",
    "\n",
    "            labelPil = Image.open(dirToReadMasks + vals[0])\n",
    "            label = np.array(labelPil)\n",
    "            labelPil.close()\n",
    "\n",
    "\n",
    "\n",
    "            xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "            if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "                (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "\n",
    "                imgWidth = img.shape[1]\n",
    "                imgHeight = img.shape[0]\n",
    "\n",
    "\n",
    "                imgAct = img[ymin:ymax, xmin:xmax,]\n",
    "                labelAct = label[ymin:ymax, xmin:xmax]\n",
    "\n",
    "                if imgAct.shape[0] > 0 and imgAct.shape[1] > 0 and labelAct.shape[0] > 0 and labelAct.shape[1] > 0: \n",
    "                    cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '_RCAct.png'), imgAct)\n",
    "                    cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '_RCAct.png'), labelAct)\n",
    "\n",
    "\n",
    "\n",
    "                for offset in offsetsToApply:\n",
    "\n",
    "                    img1 =     img[ymin + offset:ymax + offset, xmin:xmax]\n",
    "                    label1 = label[ymin + offset:ymax + offset, xmin:xmax]\n",
    "\n",
    "                    if img1.shape[0] > 0 and img1.shape[1] > 0 and label1.shape[0] > 0 and label1.shape[1] > 0: \n",
    "                        cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_1.png', img1)\n",
    "                        cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_1.png', label1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    img2 =     img[ymin:ymax, xmin + offset:xmax + offset]\n",
    "                    label2 = label[ymin:ymax, xmin + offset:xmax + offset]\n",
    "\n",
    "                    if img2.shape[0] > 0 and img2.shape[1] > 0 and label2.shape[0] > 0 and label2.shape[1] > 0: \n",
    "                        cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_2.png', img2)\n",
    "                        cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_2.png', label2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    if (ymin - offset) > 0:\n",
    "                        img3 =     img[ymin - offset:ymax - offset, xmin:xmax]\n",
    "                        label3 = label[ymin - offset:ymax - offset, xmin:xmax]\n",
    "\n",
    "                        if img3.shape[0] > 0 and img3.shape[1] > 0 and label3.shape[0] > 0 and label3.shape[1] > 0: \n",
    "                            cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_3.png', img3)\n",
    "                            cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_3.png', label3)\n",
    "\n",
    "\n",
    "\n",
    "                    if (xmin - offset) > 0:\n",
    "                        img4 =     img[ymin:ymax, xmin - offset:xmax - offset]\n",
    "                        label4 = label[ymin:ymax, xmin - offset:xmax - offset]\n",
    "\n",
    "                        if img4.shape[0] > 0 and img4.shape[1] > 0 and label4.shape[0] > 0 and label4.shape[1] > 0: \n",
    "\n",
    "                            cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_4.png', img4)\n",
    "                            cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_4.png', label4)\n",
    "        \n",
    "        except:\n",
    "            print(\"coud not open file: \" + vals[0] + \"\\n\")\n",
    "\n",
    "    else:\n",
    "        print(\"one of the provided directories doesn't exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Calculating Performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Calculating Performance for Bucket Boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Step 1 Create binary masks from predictions:\n",
    "    \n",
    "    # read the prediction results from csv\n",
    "    rows = readCsvRows(\"/home/hooman/dataPreparation/testSet_noBbxImagesIncluded.csv\")\n",
    "    \n",
    "    #produce binary masks\n",
    "    for row in rows[1:]:\n",
    "        getBbxMask(row, True, gtMaskPath)\n",
    "        \n",
    "#### Step 2 Load the predictions csv and the testSet csv using readCsvRows method (according to above)\n",
    "#### Step 3 Call the calcPerformance method providing it with the predicted and gt rows, and the paths to where the binary masks are stored.\n",
    "\n",
    "    Example: \n",
    "    _,_,_,_ = calcPerformance(pred_rows[1:len(pred_rows)-1], gt_rows[1:len(gt_rows)-1], \"/home/hooman/mobileNet_try2/result_defaultParams/predictedBbMasks/\", gtMaskPath)\n",
    "\n",
    " ####  <font color='red'>Note that: </font>  \n",
    "1. There is a slash required at the end of paths. \n",
    "2. When you provide the rows to the calcPerformance function, make sure you index in a way that the first, and last rows in the csv are igoned. This is because when you use the readCsvRows function the first row takes column headers and the last row contains an empty line.\n",
    "\n",
    "3. If your gt and prediction csv's do not match you need to create a dictionary for your predictions and suply that aswell. \n",
    "        existNetRowsDict = {}\n",
    "        for row in pred_rows[1:60]:\n",
    "            vals = row.split(',')\n",
    "            existNetRowsDict[vals[0]] = vals[1:5]\n",
    "            \n",
    "4. The call then becomes:<br>\n",
    "           _,_,_,_ = calcPerformance(pred_rows[1:len(pred_rows)-1], gt_rows[1:len(gt_rows)-1],  \"/home/hooman/resultsFromExistingNetwork/testSetFregmentationResults/predictedBinMasks/\", gtMaskPath, predictedRowDict=existNetRowsDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gt_rows = readCsvRows(\"/home/hooman/dataPreparation/testSet_noBbxImagesIncluded_singleClass_bucketBound_NoTeeth_NoCase.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_rows = readCsvRows(\"/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try1/result_minScore09_ckpt-72237/result_minScore09_ckpt-72237.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_,_,_,_ = calcPerformance(pred_rows[1:len(pred_rows)-1], gt_rows[1:len(gt_rows)-1],  \"/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try1/result_minScore09_ckpt-72237/predictedBbMasks/\", gtMaskPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Generating Binary Bounding Box Masks for performance calcluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "These are needed to quickly calcualte True/False Positives/Negetives using metrix multiplication of masks.\n",
    "You can visualize the generated binary masks using:\n",
    "\n",
    "\n",
    "\n",
    "    for row in rows[1:]:\n",
    "        m = getBbxMask(row, False, \"/home/hooman/mobileNet_try2/result_defaultParams/predictedBbMasks/\", True)\n",
    "        plt.imshow(m)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rows = readCsvRows(\"/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try1/result_defaultParams_ckpt-72237/result_defaultParams_ckpt-72237.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for row in rows[1:len(rows)-1]:\n",
    "    getBbxMask(row, True, \"/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try1/result_defaultParams_ckpt-72237/predictedBbMasks/\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Calculating Performance for inside Bucket Delineations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# loading and displaying saved single channel U-Net resutls\n",
    "unet_pathToSavedResults = '/home/hooman/UNet/vesUnet_try1/predicted6chanImages/'\n",
    "unet_pathTo1ChanLabels = '/home/hooman/dataPreparation/hsTestSet/masks0PaddedForUNet/'\n",
    "unet_pathToTestImages = '/home/hooman/dataPreparation/hsTestSet/images0PaddedForUNet/'\n",
    "\n",
    "for imgId in os.listdir(unet_pathToTestImages):\n",
    "    \n",
    "    img = imread(unet_pathToTestImages + imgId)\n",
    "    label = imread(unet_pathTo1ChanLabels + imgId)\n",
    "    pred = imread(unet_pathToSavedResults + imgId)\n",
    "    \n",
    "    \n",
    "    imshow(img)\n",
    "    plt.title('image')\n",
    "    plt.show()\n",
    "        \n",
    "    imshow(label)\n",
    "    plt.title('label')\n",
    "    plt.show()\n",
    "    \n",
    "    imshow(pred)\n",
    "    plt.title('pred')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_,_,_,_ = calcPerformance_insideBucket_multiClass('/home/hooman/UNet/hsUnet_try2/predicted6chanImages_cropped/', '/home/hooman/dataPreparation/hsTestSet/cropped/croppedMasks_resized128-160/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# calculating performance for hsUNet style singleClass\n",
    "unet_pathToSavedResults = '/home/hooman/UNet/hsUnet_try14/predicted1chanImages/'\n",
    "unet_pathTo1ChanLabelsMasks = '/home/hooman/dataPreparation/hsTestSet/cropped/28by28Masks/croppedMask_withInapp_mistakesRemoved/'\n",
    "verbose = False\n",
    "\n",
    "\n",
    "total_tn = 0\n",
    "total_tp = 0\n",
    "total_fn = 0\n",
    "total_fp = 0\n",
    "\n",
    "rowCount = 0\n",
    "\n",
    "\n",
    "for imgId in os.listdir(unet_pathTo1ChanLabelsMasks):\n",
    "    \n",
    "    label = imread(unet_pathTo1ChanLabelsMasks + imgId)\n",
    "    pred = imread(unet_pathToSavedResults + imgId)\n",
    "\n",
    "    labelMask = label.astype(bool)\n",
    "    predMask = pred.astype(bool)\n",
    "\n",
    "\n",
    "    pos_preds = np.where(predMask == 1)\n",
    "    neg_preds = np.where(predMask == 0)\n",
    "\n",
    "    pos_overlap = predMask * labelMask\n",
    "    neg_overlap = np.logical_not(predMask) * np.logical_not(labelMask)\n",
    "\n",
    "\n",
    "    if verbose==True:\n",
    "        imshow(label)\n",
    "        plt.title('label')\n",
    "        plt.show()\n",
    "\n",
    "        imshow(labelMask)\n",
    "        plt.title('labelMask')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        imshow(pred)\n",
    "        plt.title('pred')\n",
    "        plt.show()\n",
    "\n",
    "        imshow(predMask)\n",
    "        plt.title('pred')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    tp = np.count_nonzero(pos_overlap)\n",
    "    tn = np.count_nonzero(neg_overlap)\n",
    "    fp = len(pos_preds[0]) - tp\n",
    "    fn = len(neg_preds[0]) - tn\n",
    "\n",
    "    total_fp += fp\n",
    "    total_fn += fn\n",
    "    total_tp += tp\n",
    "    total_tn += tn\n",
    "\n",
    "    rowCount += 1\n",
    "\n",
    "\n",
    "\n",
    "sensitivity = float(total_tp) / (total_tp + total_fn)\n",
    "specificity = float(total_tn) / (total_tn + total_fp)\n",
    "precision = float(total_tp) / (total_tp + total_fp)\n",
    "f_score = 2 * precision * sensitivity / (precision + sensitivity)\n",
    "\n",
    "print(\"-Sensitivity: \" + str(sensitivity) +\n",
    "      \" ,    -Specificity: \" + str(specificity) +\n",
    "      \" ,    -Precision: \" + str(precision) +\n",
    "      \" ,    -F_score: \" + str(f_score)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# calculating performance for multi-class predictions using single class labels    \n",
    "unet_pathToSavedResults = '/home/hooman/UNet/vesUnet_try1/predicted6chanImages_cropped/'\n",
    "unet_pathTo1ChanLabels = '/home/hooman/dataPreparation/hsTestSet/cropped/croppedMasks_resized128-160/'\n",
    "verbose = False\n",
    "\n",
    "\n",
    "total_tn = 0\n",
    "total_tp = 0\n",
    "total_fn = 0\n",
    "total_fp = 0\n",
    "\n",
    "rowCount = 0\n",
    "\n",
    "\n",
    "for imgId in os.listdir(unet_pathTo1ChanLabels):\n",
    "    \n",
    "    label = imread(unet_pathTo1ChanLabels + imgId)\n",
    "    labelMask = label.astype(bool)\n",
    "    \n",
    "    \n",
    "    pred = imread(unet_pathToSavedResults + imgId)\n",
    "    predMask = np.zeros((pred.shape[0], pred.shape[1]), bool)\n",
    "    predPixels = np.where(pred == 2)\n",
    "    predMask[predPixels] = 1\n",
    "\n",
    "\n",
    "    pos_preds = np.where(predMask == 1)\n",
    "    neg_preds = np.where(predMask == 0)\n",
    "\n",
    "    pos_overlap = predMask * labelMask\n",
    "    neg_overlap = np.logical_not(predMask) * np.logical_not(labelMask)\n",
    "\n",
    "\n",
    "    if verbose==True:\n",
    "        imshow(label)\n",
    "        plt.title('label')\n",
    "        plt.show()\n",
    "\n",
    "        imshow(labelMask)\n",
    "        plt.title('labelMask')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        imshow(pred)\n",
    "        plt.title('pred')\n",
    "        plt.show()\n",
    "\n",
    "        imshow(predMask)\n",
    "        plt.title('pred')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    tp = np.count_nonzero(pos_overlap)\n",
    "    tn = np.count_nonzero(neg_overlap)\n",
    "    fp = len(pos_preds[0]) - tp\n",
    "    fn = len(neg_preds[0]) - tn\n",
    "\n",
    "    total_fp += fp\n",
    "    total_fn += fn\n",
    "    total_tp += tp\n",
    "    total_tn += tn\n",
    "\n",
    "    rowCount += 1\n",
    "\n",
    "\n",
    "\n",
    "sensitivity = float(total_tp) / (total_tp + total_fn)\n",
    "specificity = float(total_tn) / (total_tn + total_fp)\n",
    "precision = float(total_tp) / (total_tp + total_fp)\n",
    "f_score = 2 * precision * sensitivity / (precision + sensitivity)\n",
    "\n",
    "print(\"-Sensitivity: \" + str(sensitivity) +\n",
    "      \" ,    -Specificity: \" + str(specificity) +\n",
    "      \" ,    -Precision: \" + str(precision) +\n",
    "      \" ,    -F_score: \" + str(f_score)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Calculating performance for only the images that the existing networks can find bucket boundaries in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gt_rows = readCsvRows(\"/home/hooman/dataPreparation/testSet_noBbxImagesIncluded_singleClass_bucketBound_NoTeeth_NoCase.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ex_rows = readCsvRows(\"/home/hooman/resultsFromExistingNetwork/testSetFregmentationResults/testSetOutputConverted_noBoundariesRemoved.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_rows = readCsvRows(\"/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try1/result_minScore09_ckpt-72237/result_minScore09_ckpt-72237.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     7
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Get PredictRowDictionary\n",
    "predDict = {}\n",
    "for row in pred_rows[1:255]:\n",
    "    vals = row.split(',')\n",
    "    predDict[vals[0]] = vals[2:6]\n",
    "    \n",
    "existNetRowsFromPredDict = {}\n",
    "for row in ex_rows[1:61]:\n",
    "    vals = row.split(',')\n",
    "    existNetRowsFromPredDict[vals[0]] = predDict[vals[0]]\n",
    "    \n",
    "print(\"preDict has: \" + str(len(predDict)) + \" rows\")\n",
    "print(\"existNetRowsFromPredDict has: \" + str(len(existNetRowsFromPredDict)) + \" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_,_,_,_ = calcPerformance(pred_rows[1:len(pred_rows)-1], gt_rows[1:len(gt_rows)-1], \"/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try1/result_minScore09_ckpt-72237/predictedBbMasks/\", gtMaskPath, predictedRowDict=existNetRowsFromPredDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_,_,_,_ = calcPerformance(pred_rows[1:len(pred_rows)-1], gt_rows[1:len(gt_rows)-1],  \"/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try1/result_defaultParams_ckpt-72237/predictedBbMasks/\", gtMaskPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font color='red'> Sandbox Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
