{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#imports \n",
    "import skimage\n",
    "from skimage.io import imread, imshow, imsave, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage import img_as_ubyte\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "\n",
    "#from tqdm import tqdm\n",
    "\n",
    "#get file names\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import shutil\n",
    "\n",
    "#calculate mode\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font color='blue'/> DataSet Exploration Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Different dataset formats:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "YOLO: <object-class> <x_center> <y_center> <width> <height>\n",
    "BrainWash: (xmin, ymin, xmax, ymax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def convert__xmin_ymin_xmax_ymax__2__class_xcent_ycent_width_height(box, imageW, imageH):\n",
    "    xmin = (float(box[0])) / imageW\n",
    "    ymin = (float(box[1])) / imageH\n",
    "    xmax = (float(box[2])) / imageW\n",
    "    ymax = (float(box[3])) / imageH\n",
    "    \n",
    "    h = (ymax - ymin)\n",
    "    w = (xmax - xmin)\n",
    "    xcent = xmin + w/2\n",
    "    ycent = ymin + h/2\n",
    "\n",
    "    # add 0 for class head\n",
    "    return (0, xcent, ycent, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def convert__class_xmin_ymin_w_h__2__xcent_ycent_width_height(box):\n",
    "    classN = int(box[0])\n",
    "    xmin = float(box[1])\n",
    "    ymin = float(box[2])\n",
    "    w = float(box[3])\n",
    "    h = float(box[4])\n",
    "    \n",
    "    xcent = xmin + w/2\n",
    "    ycent = ymin + h/2\n",
    "    \n",
    "    return (classN, xcent, ycent, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def parseBrainWashLabelString(stringsList, imageW, imageH):\n",
    "    outList = []\n",
    "    \n",
    "    split2 = stringsList[1][1:-2].split(\"),\")\n",
    "    for i in range(len(split2)):\n",
    "        split2[i] = split2[i].replace(\"(\", '')\n",
    "        split2[i] = split2[i].replace(\")\", '')\n",
    "        split2[i] = split2[i].replace(' ', '')\n",
    "        \n",
    "        outList.append(split2[i].split(','))\n",
    "        #use below to convert to yolo. Use above to keep original format\n",
    "#         outList.append(\n",
    "#             convert__xmin_ymin_xmax_ymax__2__class_xcent_ycent_width_height(\n",
    "#                 split2[i].split(','), imageW, imageH\n",
    "#             )\n",
    "#         )\n",
    "        \n",
    "    return outList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def processIDL_file(filePath, headLabelsDict):\n",
    "    idlFile = open(filePath, 'r')\n",
    "    fileLines = idlFile.readlines()\n",
    "    \n",
    "    for fileLine in fileLines:\n",
    "        split1 = fileLine.split(\":\")\n",
    "        imageName = split1[0][:-1].split(\"/\")[-1]\n",
    "        split2 = imageName.split('_')[1].split('.')[0].split('x')\n",
    "        imgWidth = int(split2[0])\n",
    "        imgHeight = int(split2[1])\n",
    "        \n",
    "        saveImageName = imageName.replace(\".png\",\".jpg\")\n",
    "        saveImageName = saveImageName.replace('\\\"','')\n",
    "        saveImageName = saveImageName.replace(';','')\n",
    "        \n",
    "        if not(imgWidth == 640 and imgHeight == 480):\n",
    "            print(\"\\n***different image size obsereved****\\n\")\n",
    "        \n",
    "        if len(split1) > 1:\n",
    "            headLabelsDict[saveImageName] = parseBrainWashLabelString(split1, imgWidth, imgHeight)\n",
    "        else:\n",
    "            headLabelsDict[saveImageName] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def processBordPredFile__xmin_ymin_w_h(imageId, boardPredsPath):\n",
    "    labelsList = []\n",
    "    \n",
    "    resFile = open(boardPredsPath + imageId.replace('.jpg', '.txt'), 'r')\n",
    "    resLines =resFile.readlines()\n",
    "    \n",
    "    for line in resLines: \n",
    "        line = line.replace(\"\\n\", '')\n",
    "        split1 = line.split(' ')\n",
    "        labelsList.append(convert__class_xmin_ymin_w_h__2__xcent_ycent_width_height(split1))\n",
    "            \n",
    "    return labelsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def writeLabelFile__class_xcent_ycent_width_height(imageId, outputLabelsPath, labelsList):\n",
    "    outFile = open(outputLabelsPath + imageId.replace('.jpg', '.txt'), 'w')\n",
    "    \n",
    "    for label in labelsList:\n",
    "        strL = str(label[0]) + ' ' + str(label[1]) + ' ' + str(label[2]) + ' ' +\\\n",
    "        str(label[3]) + ' ' + str(label[4]) + '\\n' \n",
    "        outFile.write(strL)\n",
    "    \n",
    "    outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def visualizeLabelLine(labelList, img):\n",
    "    xcent = float(labelList[1]) * img.shape[1]\n",
    "    ycent = float(labelList[2]) * img.shape[0]\n",
    "    w = float(labelList[3]) * img.shape[1]\n",
    "    h = float(labelList[4]) * img.shape[0]\n",
    "    \n",
    "    xmin = int(xcent - w/2)\n",
    "    ymin = int(ycent - h/2)\n",
    "    xmax = int(xcent + w/2)\n",
    "    ymax = int(ycent + h/2)\n",
    "    cv2.rectangle(img,(xmin, ymin),(xmax, ymax),(255,0,0),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def visualizePredLine(labelList, img):\n",
    "    xcent = float(labelList[2]) * img.shape[1]\n",
    "    ycent = float(labelList[3]) * img.shape[0]\n",
    "    w = float(labelList[4]) * img.shape[1]\n",
    "    h = float(labelList[5]) * img.shape[0]\n",
    "    \n",
    "    xmin = int(xcent - w/2)\n",
    "    ymin = int(ycent - h/2)\n",
    "    xmax = int(xcent + w/2)\n",
    "    ymax = int(ycent + h/2)\n",
    "    cv2.rectangle(img,(xmin, ymin),(xmax, ymax),(255,0,0),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## pipeline (using above methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Visualizing BrainWash Original  xmin_ymin_xmax_ymax\n",
    "headLabelsDict = {}\n",
    "processIDL_file('/home/hooman/brainwash_headDetection_dataset/brainwash/brainwash_test.idl',\n",
    "                headLabelsDict)\n",
    "processIDL_file('/home/hooman/brainwash_headDetection_dataset/brainwash/brainwash_val.idl',\n",
    "                headLabelsDict)\n",
    "processIDL_file('/home/hooman/brainwash_headDetection_dataset/brainwash/brainwash_train.idl',\n",
    "                headLabelsDict)\n",
    "\n",
    "imagesPath = \"/home/hooman/brainwash_headDetection_dataset/brainwash/11_13_2014/brainwash_11_13_2014_images_hsJPG/\"\n",
    "visPath = \"/home/hooman/brainwash_headDetection_dataset/brainwash/trainSetVis_11_13_2014/\"\n",
    "\n",
    "for imgId in os.listdir(imagesPath):\n",
    "    print(imgId)\n",
    "    img = imread(imagesPath + imgId)\n",
    "\n",
    "    labels = headLabelsDict[imgId]\n",
    "    for label in labels:\n",
    "        xmin = int(float(label[0]))\n",
    "        ymin = int(float(label[1]))\n",
    "        xmax = int(float(label[2]))\n",
    "        ymax = int(float(label[3]))\n",
    "\n",
    "        cv2.rectangle(img,(xmin, ymin),(xmax, ymax),(255,0,0),3)\n",
    "\n",
    "    imsave(visPath + imgId, img)\n",
    "#     plt.imshow(img)\n",
    "#     plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# converting brain wash original and board preds to YOLO\n",
    "imagesPath = \"/home/hooman/brainwash_headDetection_dataset/brainwash/brainwash_10_27_2014_images_hsJPG/\"\n",
    "outputLabelsPath = \"/home/hooman/brainwash_headDetection_dataset/brainwash/brainwash_10_27_2014_hsLabels_justHead/\"\n",
    "boardPredsPath = \"/home/hooman/brainwash_headDetection_dataset/work_results_text/\"\n",
    "\n",
    "headLabelsDict = {}\n",
    "processIDL_file('/home/hooman/brainwash_headDetection_dataset/brainwash/brainwash_test.idl',\n",
    "                headLabelsDict)\n",
    "processIDL_file('/home/hooman/brainwash_headDetection_dataset/brainwash/brainwash_val.idl',\n",
    "                headLabelsDict)\n",
    "processIDL_file('/home/hooman/brainwash_headDetection_dataset/brainwash/brainwash_train.idl',\n",
    "                headLabelsDict)\n",
    "\n",
    "for imageId in os.listdir(imagesPath):\n",
    "    predLabelsList = processBordPredFile__xmin_ymin_w_h(imageId, boardPredsPath)\n",
    "    combinedList = headLabelsDict[imageId] + predLabelsList\n",
    "    writeLabelFile__class_xcent_ycent_width_height(imageId, outputLabelsPath, combinedList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# spliting test,valid,train for Brainwash\n",
    "filePath = '/home/hooman/brainwash_headDetection_dataset/brainwash/brainwash_train.idl'\n",
    "outFilePath = '/home/hooman/brainwash_headDetection_dataset/brainwash/official_trainSet2.txt'\n",
    "path2Append = '/home/hooman/brainwash_headDetection_dataset/brainwash/'\n",
    "\n",
    "outFile = open(outFilePath, 'w')\n",
    "\n",
    "idlFile = open(filePath, 'r')\n",
    "fileLines = idlFile.readlines()\n",
    "\n",
    "headLabelsDict = {}\n",
    "for fileLine in fileLines:\n",
    "    split1 = fileLine.split(\":\")\n",
    "    imageName = split1[0][:-1].split(\"/\")[-1]\n",
    "    finalImageName = imageName.replace(\".png\",\".jpg\")\n",
    "    finalImageName = finalImageName.replace('\\\"','')\n",
    "    finalImageName = finalImageName.replace(';','')\n",
    "    \n",
    "    imagePath = split1[0][:-1].split(\"/\")[0]\n",
    "    \n",
    "    if \"10_27_2014\" in imagePath:\n",
    "        savePath = path2Append + \"10_27_2014_all/\" +finalImageName\n",
    "    elif \"11_13_2014\" in imagePath:\n",
    "        savePath = path2Append + \"11_13_2014_all/\" +finalImageName\n",
    "    elif \"11_24_2014\" in imagePath:\n",
    "        savePath = path2Append + \"11_24_2014_all/\" +finalImageName\n",
    "    else:\n",
    "        print(imageName)\n",
    "        print(imagePath)\n",
    "        print(\"Error cannot decide what folder this belongs to.\")\n",
    "        break\n",
    "\n",
    "    outStr = str(savePath) + '\\n'\n",
    "    outFile.write(outStr)\n",
    "    #print(outStr)\n",
    "    \n",
    "outFile.close()\n",
    "idlFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# visualizing the training or test set from txt files\n",
    "path2TrainingSet = \"/home/hooman/brainwash_headDetection_dataset/brainwash/official_valSet.txt\"\n",
    "path2Vis = \"/home/hooman/brainwash_headDetection_dataset/brainwash/valSetVis/\"\n",
    "\n",
    "trains = open(path2TrainingSet, 'r')\n",
    "fileLines = trains.readlines()\n",
    "\n",
    "for fileLine in fileLines:\n",
    "    imagePath = fileLine.replace(\"\\n\", '')\n",
    "    img = imread(imagePath)\n",
    "    \n",
    "    labelFile = open(imagePath.replace(\".jpg\", \".txt\"), 'r')\n",
    "    labelLines = labelFile.readlines()\n",
    "    for line in labelLines:\n",
    "        visualizeLabelLine(line.split(\" \"), img)\n",
    "    \n",
    "    #print(path2Vis + imagePath.split(\"/\")[-1])\n",
    "    imsave(path2Vis + imagePath.split(\"/\")[-1], img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#vis labels on images from directory\n",
    "pathIm = \"/home/hooman/justHead_testSet_fromTensent/images/\"\n",
    "pathLabels = '/home/hooman/justHead_testSet_fromTensent/yoloLabels_40-40/'\n",
    "path2Vis = '/home/hooman/justHead_testSet_fromTensent/vis_GT_40-40/'\n",
    "for imId in os.listdir(pathIm):\n",
    "    img = imread(pathIm + imId)\n",
    "    \n",
    "    try:\n",
    "        labelFile = open(pathLabels + imId.replace(\".jpg\",\".txt\"), 'r')\n",
    "    except:\n",
    "        print(\"Error didnot find labels for image\")\n",
    "        print(imId)\n",
    "#         shutil.copy(pathIm + imId, \"/home/hooman/brainwash_headDetection_dataset/brainwash/\"\\\n",
    "#                     \"11_13_2014_imagesWithNoCombinedLabels/\" +imId)\n",
    "        break\n",
    "\n",
    "    labelLines = labelFile.readlines()\n",
    "    for line in labelLines:\n",
    "        visualizeLabelLine(line.split(\" \"), img)\n",
    "\n",
    "    #print(path2Vis + imagePath.split(\"/\")[-1])\n",
    "    try:\n",
    "        imsave(path2Vis + imId, img)\n",
    "    except:\n",
    "        print(\"Error could not save image\")\n",
    "        print(imId)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#vis preds on images from directory\n",
    "pathIm = \"/home/hooman/coco/hsTest100_images/\"\n",
    "for imId in os.listdir(pathIm):\n",
    "    img = imread(pathIm + imId)\n",
    "    \n",
    "   \n",
    "    labelFile = open(\n",
    "        \"/home/hooman/headAndTorso_detection/release/text_res_balTestSetHH_3Class/\" + imId.replace(\".jpg\",\".txt\"), 'r')\n",
    "    labelLines = labelFile.readlines()\n",
    "    for line in labelLines:\n",
    "        visualizePredLine(line.split(\" \"), img)\n",
    "\n",
    "    #print(path2Vis + imagePath.split(\"/\")[-1])\n",
    "    imsave(\"/home/hooman/headAndTorso_detection/release/visFormahdi/\" + imId, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# concat multiple label files\n",
    "labelDir1 = \"/home/hooman/AlphaPose/11_13_2014_torosLabels_all/\"\n",
    "labelDir2 = \"/home/hooman/AlphaPose/11_13_2014_personLabels_all/\"\n",
    "labelDir3 = \"/home/hooman/brainwash_headDetection_dataset/brainwash/brainwash_11_13_2014_hsLabels_justHead/\"\n",
    "filanLabelDir = \"/home/hooman/brainwash_headDetection_dataset/brainwash/11_13_2014_combinedLabels_yoloAndPose/\"\n",
    "\n",
    "for textFileName in os.listdir(labelDir1):\n",
    "    with open(filanLabelDir + textFileName, 'w') as outfile:\n",
    "        with open(labelDir1 + textFileName) as infile:\n",
    "            outfile.write(infile.read())\n",
    "            \n",
    "        with open(labelDir2 + textFileName) as infile:\n",
    "            outfile.write(infile.read())\n",
    "            \n",
    "        with open(labelDir3 + textFileName) as infile:\n",
    "            outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# concat hs and mahdi labels for hardhat1\n",
    "labelDir1 = \"/home/hooman/hardHat_dataset/labels_hs/\"\n",
    "labelDir2 = \"/home/hooman/hardHat_dataset/labels_mahdi/\"\n",
    "\n",
    "filanLabelDir = \"/home/hooman/hardHat_dataset/combined_labels/\"\n",
    "\n",
    "for textFileName in os.listdir(labelDir1):\n",
    "    with open(filanLabelDir + textFileName, 'w') as outfile:\n",
    "        \n",
    "        lab1F = open(labelDir1 + textFileName, 'r')\n",
    "        lab1Lines = lab1F.readlines()\n",
    "        for ln in lab1Lines:\n",
    "            newLine1 = ln[0] + ln[10:]\n",
    "            outfile.write(newLine1)\n",
    "\n",
    "            \n",
    "        lab2F = open(labelDir2 + textFileName, 'r')\n",
    "        lab2Lines = lab2F.readlines()\n",
    "        for ln in lab2Lines:\n",
    "            if ln[0] == \"0\":\n",
    "                newLine = \"2\" + ln[1:]\n",
    "            if ln[0] == \"1\" or ln[0] == \"2\":\n",
    "                newLine = \"1\" + ln[1:]\n",
    "                \n",
    "            outfile.write(newLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# concat hs and mahdi labels for hardhat2\n",
    "labelDir1 = \"/home/hooman/hardHat_dataset/5class_labels/\"\n",
    "labelDir2 = \"/home/hooman/hardHat_dataset/labels_mahdi/\"\n",
    "\n",
    "filanLabelDir = \"/home/hooman/hardHat_dataset/combined_labels/\"\n",
    "\n",
    "for textFileName in os.listdir(labelDir1):\n",
    "    with open(filanLabelDir + textFileName, 'w') as outfile:\n",
    "        \n",
    "        lab1F = open(labelDir1 + textFileName, 'r')\n",
    "        lab1Lines = lab1F.readlines()\n",
    "        for ln in lab1Lines:\n",
    "            if ln[0] == \"0\" or ln[0] == \"1\" or ln[0] == \"2\" or ln[0] == \"3\" or ln[0] == \"4\":\n",
    "                newLine1 = \"0\" + ln[1:]\n",
    "            outfile.write(newLine1)\n",
    "\n",
    "            \n",
    "        lab2F = open(labelDir2 + textFileName, 'r')\n",
    "        lab2Lines = lab2F.readlines()\n",
    "        for ln in lab2Lines:\n",
    "            if ln[0] == \"0\":\n",
    "                newLine = \"2\" + ln[1:]\n",
    "            if ln[0] == \"1\" or ln[0] == \"2\":\n",
    "                newLine = \"1\" + ln[1:]\n",
    "                \n",
    "            outfile.write(newLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#creating labels for Mahdi\n",
    "labelDir1 = \"/home/hooman/hardHat_dataset/5class_labels/\"\n",
    "labelDir2 = \"/home/hooman/hardHat_dataset/labels_mahdi/\"\n",
    "\n",
    "filanLabelDir = \"/home/hooman/hardHat_dataset/labels4Mahdi/\"\n",
    "\n",
    "for textFileName in os.listdir(labelDir1):\n",
    "    with open(filanLabelDir + textFileName, 'w') as outfile:\n",
    "        \n",
    "        lab1F = open(labelDir1 + textFileName, 'r')\n",
    "        lab1Lines = lab1F.readlines()\n",
    "        for ln in lab1Lines:\n",
    "            if ln[0] == \"1\" or ln[0] == \"2\" or ln[0] == \"3\" or ln[0] == \"0\":\n",
    "                newLine1 = \"4\" + ln[1:]\n",
    "            if ln[0] == \"4\":\n",
    "                newLine1 = \"3\" + ln[1:]\n",
    "            outfile.write(newLine1)\n",
    "\n",
    "            \n",
    "        lab2F = open(labelDir2 + textFileName, 'r')\n",
    "        lab2Lines = lab2F.readlines()\n",
    "        for ln in lab2Lines:   \n",
    "            outfile.write(ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pick random images\n",
    "import random\n",
    "path1 = \"/home/hooman/work_uniform/hardHatFromMahdi/justPreds/\"\n",
    "path2 = \"/home/hooman/work_uniform/hardHatFromMahdi/randomTestSet_200/\"\n",
    "nbOfItems2pick = 200\n",
    "\n",
    "all_list = os.listdir(path1)\n",
    "random.shuffle(all_list) #shuffle method\n",
    "\n",
    "for i in range(nbOfItems2pick):\n",
    "    shutil.copy(path1 + all_list[i], path2 + all_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# convert vest,noVest,hat,NoHat predsOrLabels to torso, head\n",
    "labelDir1 = \"/home/hooman/hardHat_dataset/randomTestSet_200_correctedLabels_vest/\"\n",
    "filanLabelDir = \"/home/hooman/hardHat_dataset/randomTestSet_200_correctedLabels_hs/\"\n",
    "\n",
    "for textFileName in os.listdir(labelDir1):\n",
    "    with open(filanLabelDir + textFileName, 'w') as outfile:\n",
    "        \n",
    "        lab1F = open(labelDir1 + textFileName, 'r')\n",
    "        lab1Lines = lab1F.readlines()\n",
    "        for ln in lab1Lines:\n",
    "            if ln[0] == \"0\": #person\n",
    "                newLine1 = \"2\" + ln[1:]\n",
    "            \n",
    "            if ln[0] == \"1\" or ln[0] == \"2\": #torso\n",
    "                newLine1 = \"1\" + ln[1:]\n",
    "            \n",
    "            if ln[0] == \"3\" or ln[0] == \"4\": #head\n",
    "                newLine1 = \"0\" + ln[1:]\n",
    "\n",
    "            outfile.write(newLine1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make text file out of folder and shuffle\n",
    "import random\n",
    "outFile = open(\"/home/hooman/hardHat_dataset/trainingSet_1000_hsClasses.txt\", 'w')\n",
    "locPath = \"/home/hooman/hardHat_dataset/images_1000/\"\n",
    "putInFilePath = \"/home/hooman/hardHat_dataset/imagesAndLabels_hs/\"\n",
    "\n",
    "namesList = os.listdir(locPath)\n",
    "random.shuffle(namesList) #shuffle method\n",
    "\n",
    "for fileName in namesList:\n",
    "    outStr = putInFilePath + fileName + '\\n'\n",
    "    outFile.write(outStr)\n",
    "\n",
    "outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check how many of each class in the entire set\n",
    "\n",
    "path = '/home/hooman/hardHat_dataset/temp_1000/'\n",
    "countHat = 0\n",
    "countNoHat = 0\n",
    "countPersonFromHead = 0\n",
    "countPerson = 0\n",
    "for fileName in os.listdir(path):\n",
    "    file = open(path + fileName, 'r')\n",
    "    lines = file.readlines()\n",
    "\n",
    "    for ln in lines:\n",
    "        if ln[0] == \"3\":\n",
    "            countNoHat +=1\n",
    "        if ln[0] == \"4\":\n",
    "            countHat +=1\n",
    "            \n",
    "        if ln[0] == \"0\":\n",
    "            countPerson +=1\n",
    "            \n",
    "        if ln[0] == \"3\" or ln[0] == \"4\":\n",
    "            countPersonFromHead+=1\n",
    "            \n",
    "print(\"noHatCount:   \" + str(countNoHat))\n",
    "print(\"hatCount:   \" + str(countHat))\n",
    "print(\"countPersonFromHead:   \" + str(countPersonFromHead))      \n",
    "print(\"countPerson:   \" + str(countPerson))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# vest preds to just head\n",
    "labelDir1 = \"/home/hooman/darknet_alex/hsHeadDetector_try6_onHH_vestClasses_1000Images/preds_BW_ck1000_0.05/\"\n",
    "filanLabelDir = \"/home/hooman/darknet_alex/hsHeadDetector_try6_onHH_vestClasses_1000Images/preds_BW_ck1000_0.05_justHead/\"\n",
    "\n",
    "for textFileName in os.listdir(labelDir1):\n",
    "    if \".txt\" in textFileName:\n",
    "        with open(filanLabelDir + textFileName, 'w') as outfile:\n",
    "\n",
    "            lab1F = open(labelDir1 + textFileName, 'r')\n",
    "            lab1Lines = lab1F.readlines()\n",
    "            for ln in lab1Lines:\n",
    "                if ln[0] == \"3\" or ln[0] == \"4\": #head\n",
    "                    newLine1 = \"0\" + ln[1:]\n",
    "\n",
    "                outfile.write(newLine1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# hs (head torso person) preds to just head\n",
    "labelDir1 = \"/home/hooman/justHead_testSet_fromTensent/predsText/\"\n",
    "filanLabelDir = \"/home/hooman/justHead_testSet_fromTensent/predsText_justHead/\"\n",
    "for textFileName in os.listdir(labelDir1):\n",
    "    if \".txt\" in textFileName:\n",
    "        with open(filanLabelDir + textFileName, 'w') as outfile:\n",
    "\n",
    "            lab1F = open(labelDir1 + textFileName, 'r')\n",
    "            lab1Lines = lab1F.readlines()\n",
    "            for ln in lab1Lines:\n",
    "                if ln[0] == \"0\": #head\n",
    "                    newLine1 = ln\n",
    "                    outfile.write(newLine1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# convert preds to labels\n",
    "labelDir1 = \"/home/hooman/otherHardHat_dataset/Test/dirty/\"\n",
    "filanLabelDir = \"/home/hooman/otherHardHat_dataset/Test/cleaned/\"\n",
    "\n",
    "for textFileName in os.listdir(labelDir1):\n",
    "    with open(filanLabelDir + textFileName, 'w') as outfile:\n",
    "        \n",
    "        lab1F = open(labelDir1 + textFileName, 'r')\n",
    "        lab1Lines = lab1F.readlines()\n",
    "        for ln in lab1Lines:\n",
    "            newLine1 = ln[0] + ln[8:]\n",
    "            outfile.write(newLine1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#remove labels less than 40*40\n",
    "path2Labels = \"/home/hooman/justHead_testSet_fromTensent/yoloLabels/\"\n",
    "filanLabelDir = \"/home/hooman/justHead_testSet_fromTensent/yoloLabels_40-40/\"\n",
    "\n",
    "for textFileName in os.listdir(path2Labels):\n",
    "    labelFile = open(path2Labels+ textFileName, 'r')\n",
    "    labelLines = labelFile.readlines()\n",
    "    \n",
    "    with open(filanLabelDir + textFileName, 'w') as outfile:\n",
    "        for line in labelLines:\n",
    "            labelList = line.split(\" \")\n",
    "            xcent = float(labelList[1]) * img.shape[1]\n",
    "            ycent = float(labelList[2]) * img.shape[0]\n",
    "            w = float(labelList[3]) * img.shape[1]\n",
    "            h = float(labelList[4]) * img.shape[0]\n",
    "\n",
    "            if w > 40.0 and h > 40.0:\n",
    "                outfile.write(line)\n",
    "                \n",
    "        labelFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#remove preds less than 40*40\n",
    "path2Labels = \"/home/hooman/headAndTorso_detection/release/text_res_balTestSetHH_3Class_justHead/\"\n",
    "filanLabelDir = \"/home/hooman/headAndTorso_detection/release/text_res_balTestSetHH_3Class_justHead_above40x40/\"\n",
    "\n",
    "for textFileName in os.listdir(path2Labels):\n",
    "    labelFile = open(path2Labels + textFileName, 'r')\n",
    "    labelLines = labelFile.readlines()\n",
    "    \n",
    "    with open(filanLabelDir + textFileName, 'w') as outfile:\n",
    "        for line in labelLines:\n",
    "            labelList = line.split(\" \")\n",
    "            xcent = float(labelList[2]) * img.shape[1]\n",
    "            ycent = float(labelList[3]) * img.shape[0]\n",
    "            w = float(labelList[4]) * img.shape[1]\n",
    "            h = float(labelList[5]) * img.shape[0]\n",
    "\n",
    "            if w > 40.0 and h > 40.0:\n",
    "                outfile.write(line)\n",
    "                \n",
    "        labelFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Convert tensent json labels(xmin, xmax, ymin, ymax) to yolo(xcent, ycent, w, h)\n",
    "\n",
    "imagesPath = '/home/hooman/justHead_testSet_fromTensent/images/'\n",
    "path2SaveLabels = '/home/hooman/justHead_testSet_fromTensent/yoloLabels/'\n",
    "jsonFile = open('/home/hooman/justHead_testSet_fromTensent/gongdi_results.json')\n",
    "data = json.load(jsonFile)\n",
    "\n",
    "for item in data:\n",
    "    imageName = item['name'].split('//')[-1]\n",
    "    if '.jpeg' in imageName:\n",
    "        imageName = imageName.replace('.jpeg', '.jpg')\n",
    "    if '.png' in imageName:\n",
    "        imageName = imageName.replace('.png', '.jpg')\n",
    "\n",
    "    try:\n",
    "        image = imread(imagesPath + imageName)\n",
    "        imH, imW, _ = image.shape\n",
    "    except:\n",
    "        print('Error could not open image:')\n",
    "        print(imageName) \n",
    "        print('\\n')\n",
    "        break\n",
    "        \n",
    "    with open(path2SaveLabels + imageName.replace(\".jpg\", \".txt\"), 'w') as outfile:\n",
    "        if item[\"labels\"]:\n",
    "            for lab in item[\"labels\"]:\n",
    "                classId = -1\n",
    "                if lab[\"category\"] == \"nohelmet\":\n",
    "                    classId = 0\n",
    "                elif lab[\"category\"] == \"helmet\":\n",
    "                    #classId = 1\n",
    "                    classId = 0\n",
    "                else:\n",
    "                    print(\"ERROR unexpected category\")\n",
    "                    print(imageName)\n",
    "                    print('\\n')\n",
    "                    break\n",
    "\n",
    "                xmin = lab[\"box2d\"][\"x1\"] / imW\n",
    "                xmax = lab[\"box2d\"][\"x2\"] / imW\n",
    "                ymin = lab[\"box2d\"][\"y1\"] / imH\n",
    "                ymax = lab[\"box2d\"][\"y2\"] / imH\n",
    "\n",
    "                xcent = (xmax + xmin)/2\n",
    "                ycent = (ymax + ymin)/2\n",
    "                width = xmax - xmin\n",
    "                height = ymax - ymin\n",
    "\n",
    "                newLine = str(classId) + ' ' + str(xcent) + ' ' + str(ycent) +\\\n",
    "                ' ' + str(width) + ' ' + str(height) + '\\n'\n",
    "                outfile.write(newLine)\n",
    "        else:\n",
    "            print('imageWith no label')\n",
    "            print(imageName)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#find missing labels\n",
    "imagesPath = \"/home/hooman/justHead_testSet_fromTensent/head/gongdi_67603/images/\"\n",
    "labelsPath = \"/home/hooman/justHead_testSet_fromTensent/head/gongdi_67603/yoloLabels/\"\n",
    "path2MvImagesWithNoLabels = '/home/hooman/justHead_testSet_fromTensent/head/gongdi_67603/temp/'\n",
    "\n",
    "labelsDic = {}\n",
    "for labelName in os.listdir(labelsPath):\n",
    "    labelsDic[labelName.replace(\".txt\", \".jpg\")] = 1\n",
    "    \n",
    "for imgName in os.listdir(imagesPath):\n",
    "    if imgName not in labelsDic.keys():\n",
    "        shutil.move(imagesPath + imgName, path2MvImagesWithNoLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font color='blue'/> Image Manipulation Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Images: Copying, Moving, Deleting from different directoreis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# deleting files that are not in one dir from another\n",
    "fileToKeepDict = {}\n",
    "\n",
    "for fileName in os.listdir('/home/hooman/Downloads/MOTIONMETRICS (2)/FM/preds/'):\n",
    "    fileToKeepDict[fileName[:-3]+'gmp'] = 1\n",
    "\n",
    "\n",
    "    \n",
    "for fileName in os.listdir('/home/hooman/Downloads/MOTIONMETRICS (2)/FM/1947EFC0-16D8-1588-A042-3534DFB3FA0F/'):\n",
    "    if fileName not in fileToKeepDict:\n",
    "        print(fileName)\n",
    "        os.remove('/home/hooman/Downloads/MOTIONMETRICS (2)/FM/1947EFC0-16D8-1588-A042-3534DFB3FA0F/' + fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# deleting images that cannot be opened (usaully after augmentation)\n",
    "dirToDeleteFrom = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/randomCroppedImages/'\n",
    "\n",
    "for fileName in os.listdir(dirToDeleteFrom):\n",
    "    try:\n",
    "        img = imread(dirToDeleteFrom + fileName)\n",
    "    except:\n",
    "        os.remove(dirToDeleteFrom + fileName)\n",
    "        os.remove('/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/randomCroppedMasks/' + fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# copying files from one dir to another\n",
    "\n",
    "import shutil\n",
    "\n",
    "for imgId in os.listdir('/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/poseNet/hydraulic/data/dataCleanup_round1/goodLabels'):\n",
    "    shutil.copy('/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/poseNet/hydraulic/data/images/' + imgId, '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/poseNet/hydraulic/data/try1_only_dataCleanup_round1_goodImages/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Exclusing testSet images from trainingSet for BucketTracking\n",
    "# copying files from one dir to another\n",
    "\n",
    "dirWithListOfimages = \"/media/hooman/hsSsdPartUbuntu/FM_PROJECT/FMDL_3.1/cable/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_cable__try1/goodMatInsides_forBBLabelingOfYolo/\"\n",
    "\n",
    "dir2RemoveFrom = \"/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/cable/fmdl-cable-trainingData/images/\"\n",
    "\n",
    "\n",
    "import shutil\n",
    "\n",
    "movedLabels = []\n",
    "\n",
    "for imgId in os.listdir(dirWithListOfimages):\n",
    "    \n",
    "    movedLabels.append(imgId)\n",
    "\n",
    "    imgName = imgId.replace('.jpg', '.xml')\n",
    "    \n",
    "    \n",
    "    if os.path.isfile(dir2RemoveFrom + imgId):\n",
    "    #if os.path.isfile(dir2RemoveFrom + imgName):\n",
    "    \n",
    "        #shutil.move(dir2RemoveFrom + imgName, '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/cable/validationsSet_hsPicked_labels')\n",
    "        \n",
    "        shutil.copy(dir2RemoveFrom + imgId, '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/FMDL_3.1/cable/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_cable__try1/temp')\n",
    "    \n",
    "        #os.remove(dir2RemoveFrom + imgId)\n",
    "        #os.remove(dir2RemoveFrom + imgName)\n",
    "        print(dir2RemoveFrom + imgName)\n",
    "        \n",
    "    \n",
    "print(\"\")\n",
    "print(\"Moved labels and deleted images for  \" + str(len(movedLabels))  + \"  examples\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Images: resizing, converting formats and channels, correcting ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Resize and downsample all images to (128, 160, 3)\n",
    "resizedImagesPath = '/home/hooman/dataPreparation/hsTestSet/images0PaddedForUNet/'\n",
    "\n",
    "for fileName in os.listdir(imagesPath):\n",
    "\n",
    "    img = imread(imagesPath + fileName) \n",
    "    \n",
    "    imgResized = cv2.resize(img, (640, 480)) \n",
    "\n",
    "    # you can downsample with numpy too. I use opencv to be consistant.    imgDs = img[::4, ::4, :]\n",
    "    imgDs = cv2.resize(imgResized, (0,0), fx=0.25, fy=0.25) \n",
    "\n",
    "    imgPadded = cv2.copyMakeBorder(imgDs,4,4,0,0,cv2.BORDER_CONSTANT,value=(0,0,0))\n",
    "    \n",
    "    cv2.imwrite(resizedImagesPath + fileName, imgPadded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# converting single channel images to 3 channels\n",
    "imagesPath = '/home/hooman/justHead_testSet_fromTensent/head/gongdi_67603/images/'\n",
    "\n",
    "for imId in os.listdir(imagesPath):\n",
    "    try:  \n",
    "        img = imread(imagesPath + imId)\n",
    "    except:\n",
    "        print('couldnt open')\n",
    "        print(imId)\n",
    "        print('\\n')\n",
    "        \n",
    "    if len(img.shape) < 3:\n",
    "        print(imId)\n",
    "        print(img.shape)\n",
    "        print('\\n')\n",
    "        \n",
    "        img3Chan = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "        cv2.imwrite('/home/hooman/justHead_testSet_fromTensent/head/gongdi_67603/conv/' + imId, img3Chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# converting single channel images to 3 channels (LOOPING OVER MULTIPLE FOLDERS)\n",
    "\n",
    "img_dest_dir = '/home/hooman/Desktop/i2lData_cropped/'\n",
    "\n",
    "\n",
    "\n",
    "for mainDir in os.listdir(img_dest_dir):\n",
    "    \n",
    "\n",
    "    for imId in os.listdir(img_dest_dir + mainDir):\n",
    "\n",
    "        img = imread(img_dest_dir + mainDir + '/' + imId)\n",
    "        if len(img.shape) < 3:\n",
    "            img3Chan = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "            cv2.imwrite(img_dest_dir + mainDir + '/' + imId, img3Chan)\n",
    "\n",
    "        else:\n",
    "            print(img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Converting jpg image to png, and removing the jpgs\n",
    "img_dest_dir = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/allImages/'\n",
    "\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "imageFileNameDic = {}\n",
    "\n",
    "for file in os.listdir(img_dest_dir):\n",
    "    fileName = file.replace(\".jpg\", \"\")\n",
    "    #fileName = file.replace(\".png\", \"\")\n",
    "    if fileName in imageFileNameDic:\n",
    "        imageFileNameDic[fileName] += 1\n",
    "    else:\n",
    "        imageFileNameDic[fileName] = 0\n",
    "\n",
    "        \n",
    "        \n",
    "for name in imageFileNameDic.keys():\n",
    "    print(name)\n",
    "    im = Image.open(img_dest_dir + '/' + name + '.jpg')\n",
    "    im.save(img_dest_dir + '/' + name + '.png')\n",
    "    os.remove(img_dest_dir + '/' + name + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Converting png image to jpg\n",
    "jpgSavePath = '/home/hooman/brainwash_headDetection_dataset/brainwash/brainwash_10_27_2014_images_hsJPG/'\n",
    "pngLoadPath = \"/home/hooman/brainwash_headDetection_dataset/brainwash/brainwash_10_27_2014_images/\"\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "for name in os.listdir(pngLoadPath):\n",
    "    print(name)\n",
    "    im = Image.open(pngLoadPath + name)\n",
    "    im.save(jpgSavePath + name.replace(\".png\",\".jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Converting jpg image to png, and removing the jpgs (looping over multiple folders)\n",
    "\n",
    "img_dest_dir = '/home/hooman/Desktop/i2lData_cropped/'\n",
    "\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "for mainDir in os.listdir(img_dest_dir):\n",
    "\n",
    "\n",
    "    imageFileNameDic = {}\n",
    "\n",
    "    for file in os.listdir(img_dest_dir + mainDir):\n",
    "        \n",
    "        fileName = file.replace(\".jpg\", \"\")\n",
    "        #fileName = file.replace(\".png\", \"\")\n",
    "        if fileName in imageFileNameDic:\n",
    "            imageFileNameDic[fileName] += 1\n",
    "        else:\n",
    "            imageFileNameDic[fileName] = 0\n",
    "\n",
    "\n",
    "\n",
    "    for name in imageFileNameDic.keys():\n",
    "        print(name)\n",
    "        im = Image.open(img_dest_dir + mainDir + '/' + name + '.jpg')\n",
    "        im.save(img_dest_dir + mainDir + '/' + name + '.png')\n",
    "        os.remove(img_dest_dir + mainDir + '/' + name + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# compressing png images with jpeg\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "saveDir = '/home/hooman/FM_PROJECT/dataPreparation/fmdlTestData-optical-hydraulic/compressedJpeg80/'\n",
    "\n",
    "for imId in os.listdir('/home/hooman/FM_PROJECT/dataPreparation/fmdlTestData-optical-hydraulic/Frame/'):\n",
    "    img = Image.open('/home/hooman/FM_PROJECT/dataPreparation/fmdlTestData-optical-hydraulic/Frame/'+ imId)\n",
    "    \n",
    "    fileName = imId.replace(\".png\", \"\")\n",
    "    \n",
    "    img.save(saveDir + '/' + fileName + '.jpg', quality=80,optimize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Correcting image Ids by content matching singleImage\n",
    "#HSNOTE: this does not work with abs error must be squared.\n",
    "\n",
    "pathToCorrectNames = '/home/hooman/dataPreparation/testingMahdisNetworkOnMyLatestTestSetForComparison/input-orig/'\n",
    "pathToWrongNames   = '/home/hooman/dataPreparation/testingMahdisNetworkOnMyLatestTestSetForComparison/outputOfSaveH5/'\n",
    "pathToWrongPreds = '/home/hooman/dataPreparation/testingMahdisNetworkOnMyLatestTestSetForComparison/ouputOfNetworkJustOutput/'\n",
    "\n",
    "\n",
    "for srcId in os.listdir(pathToWrongNames):\n",
    "\n",
    "    minScore = 100000000\n",
    "    minId = ''\n",
    "    \n",
    "    for targId in os.listdir(pathToCorrectNames):\n",
    "        srcIm = imread(pathToWrongNames + srcId)\n",
    "\n",
    "        temp= imread(pathToCorrectNames + targId)\n",
    "        targIm = cv2.resize(temp, (srcIm.shape[1], srcIm.shape[0])) \n",
    "\n",
    "        dif = np.square((srcIm - targIm))\n",
    "        score = np.sum(dif)\n",
    "\n",
    "        if score < minScore:\n",
    "            minScore = score\n",
    "            minId = targId\n",
    "            \n",
    "\n",
    "    print(\"src: \" + srcId + \"  matched with: \" + minId)\n",
    "    os.rename(pathToWrongNames + srcId, pathToWrongNames + minId)\n",
    "    os.rename(pathToWrongPreds + srcId, pathToWrongPreds + minId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Correcting image Ids by content matching allChannels\n",
    "\n",
    "\n",
    "pathToCorrectNames = '/home/hooman/dataPreparation/testingMahdisNetworkOnMyLatestTestSetForComparison/input-orig/'\n",
    "pathToWrongNames   = '/home/hooman/dataPreparation/testingMahdisNetworkOnMyLatestTestSetForComparison/outputOfSaveH5/'\n",
    "\n",
    "pathToCorrectNamesIn = '/home/hooman/dataPreparation/testingMahdisNetworkOnMyLatestTestSetForComparison/ouputOfNetworkAllChannels/' \n",
    "\n",
    "namesDic = {}\n",
    "for srcId in os.listdir(pathToWrongNames):\n",
    "\n",
    "    minScore = 100000000\n",
    "    minId = ''\n",
    "    \n",
    "    for targId in os.listdir(pathToCorrectNames):\n",
    "        srcIm = imread(pathToWrongNames + srcId)\n",
    "\n",
    "        temp= imread(pathToCorrectNames + targId)\n",
    "        targIm = cv2.resize(temp, (srcIm.shape[1], srcIm.shape[0])) \n",
    "\n",
    "        dif = np.square((srcIm - targIm))\n",
    "        score = np.sum(dif)\n",
    "\n",
    "        if score < minScore:\n",
    "            minScore = score\n",
    "            minId = targId\n",
    "            \n",
    "    print(srcId + \"___\" + minId)\n",
    "    namesDic[srcId] = minId\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import glob\n",
    "\n",
    "for srcId in namesDic.keys():\n",
    "\n",
    "    #print(\"src: \" + srcId + \"  matched with: \" + minId)\n",
    "    \n",
    "    nameAr = srcId.split('_')\n",
    "    nameAr = nameAr[0:2]\n",
    "\n",
    "    shortName = \"\"\n",
    "    for i in range(len(nameAr)):\n",
    "        shortName = shortName + nameAr[i] + '_'\n",
    "\n",
    "    chanFiles = glob.glob1(pathToCorrectNamesIn, shortName + '*')\n",
    "    \n",
    "    for fil in chanFiles:\n",
    "        chan = fil.split('_')[2]\n",
    "        #print(chan)\n",
    "        \n",
    "        if chan[0:2] == \"ch\":\n",
    "            newname = chan + \"_\" + namesDic[srcId]\n",
    "            print(\"renamed CH: \" + fil + \" to: \" + newname + \"\\n\")\n",
    "            os.rename(pathToCorrectNamesIn + fil, pathToCorrectNamesIn + newname)\n",
    "        else:\n",
    "            newname = namesDic[srcId]\n",
    "            print(\"renamed: \" + fil + \" to: \" + newname + \"\\n\")\n",
    "            os.rename(pathToCorrectNamesIn + fil, pathToCorrectNamesIn + namesDic[srcId])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# convert .JPEG to .JPG\n",
    "path2Jpeg = '/home/hooman/justHead_testSet_fromTensent/head/gongdi_67603/jpeg/'\n",
    "path2SaveJpg = '/home/hooman/justHead_testSet_fromTensent/head/gongdi_67603/conv/'\n",
    "\n",
    "for imId in os.listdir(path2Jpeg):\n",
    "    try:\n",
    "        image = imread(path2Jpeg + imId)\n",
    "        imsave(path2SaveJpg + imId.replace('.jpeg', '.jpg'), image)\n",
    "    except:\n",
    "        print(imId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Images: Displaying side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Showing Images side-by-side\n",
    "\n",
    "predsDir1 = '/home/hooman/brainwash_headDetection_dataset/brainwash/10_27_2014_combinedLabels_yoloAndPose_vis/'\n",
    "\n",
    "predsDir2 = '/home/hooman/brainwash_headDetection_dataset/brainwash/10_27_2014_combinedLabels_justPose_vis/'\n",
    "\n",
    "dirToSaveResults = '/home/hooman/brainwash_headDetection_dataset/brainwash/yoloAndPose_sidebySide/'\n",
    "\n",
    "for imgId in os.listdir(predsDir1):  \n",
    "    #if '.png' in imgId:\n",
    "    if '.jpg' in imgId:\n",
    "        pred1 = imread(predsDir1 + imgId)\n",
    "        pred2 = imread(predsDir2 + imgId)\n",
    "\n",
    "        try:\n",
    "\n",
    "\n",
    "            combImg = np.zeros((pred1.shape[0],1400, 3), np.uint8)\n",
    "\n",
    "            combImg[:, 0:pred1.shape[1], :] = pred1\n",
    "            combImg[:, 700:pred2.shape[1]+700, :] = pred2\n",
    "\n",
    "            '''\n",
    "            combImg = np.zeros((pred1.shape[0],1400), np.uint8)\n",
    "\n",
    "            combImg[:, 0:pred1.shape[1]] = pred1\n",
    "            combImg[:, 700:pred2.shape[1]+700] = pred2\n",
    "            '''\n",
    "\n",
    "\n",
    "\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(combImg,'personFromYolo',(30,70), font, 2,(255,255,255), 2, 0)\n",
    "            cv2.putText(combImg,'personFromPose',(730,70), font, 2,(255,255,255), 2, 0)\n",
    "\n",
    "\n",
    "            #plt.imshow(combImg)\n",
    "            #plt.show()\n",
    "            #break\n",
    "\n",
    "            cv2.imwrite(dirToSaveResults + imgId, combImg)\n",
    "        except:\n",
    "            print(imgId)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Showing Images side-by-side 3 images large\n",
    "predsDir1 = '/home/hooman/justHead_testSet_fromTensent/examples/labels_above40-40/'\n",
    "predsDir2 = '/home/hooman/justHead_testSet_fromTensent/examples/preds_all/'\n",
    "predsDir3 = '/home/hooman/justHead_testSet_fromTensent/examples/preds_onlyAbove40-40/'\n",
    "\n",
    "dirToSaveResults = '/home/hooman/justHead_testSet_fromTensent/examples/side/'\n",
    "\n",
    "for imgId in os.listdir(predsDir1):\n",
    "\n",
    "    pred1 = imread(predsDir1 + imgId)\n",
    "    pred2 = imread(predsDir2 + imgId)\n",
    "    pred3 = imread(predsDir3 + imgId)\n",
    "\n",
    "    totalW = pred1.shape[1] + pred2.shape[1] + pred2.shape[1] + 20\n",
    "    combImg = np.zeros((pred1.shape[0],totalW, 3), np.uint8)\n",
    "\n",
    "    combImg[:, 0:pred1.shape[1], :] = pred1\n",
    "    offset1 = pred1.shape[1] + 10\n",
    "    combImg[:, offset1:pred2.shape[1]+offset1, :] = pred2\n",
    "    offset2 = pred2.shape[1]+offset1 + 10\n",
    "    combImg[:, offset2:pred3.shape[1]+offset2, :] = pred3\n",
    "    \n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    textloc1 = int(pred1.shape[1] / 2) - 30\n",
    "    textloc2 = int((offset1 + pred2.shape[1]+offset1)/2)- 30\n",
    "    textloc3 = int((offset2 + pred3.shape[1]+offset2)/2)- 30\n",
    "    \n",
    "    cv2.putText(combImg,'groundTruth',(textloc1,70), font, 2,(0,255,0), 2, 0)\n",
    "    cv2.putText(combImg,'allPreds',(textloc2,70), font, 2,(0,255,0), 2, 0)\n",
    "    cv2.putText(combImg,'predsAbove40-40',(textloc3,70), font, 2,(0,255,0), 2, 0)\n",
    "\n",
    "    cv2.imwrite(dirToSaveResults + imgId, combImg)\n",
    "    #cv2.imwrite(dirToSaveResults + imgId, combImg)\n",
    "    imsave(dirToSaveResults + imgId, combImg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Putting the optical flow and U-Net outputs sidebyside.  \n",
    "\n",
    "#FMDL_2018.04.30_11.38.09.png\n",
    "\n",
    "temp = imread('/home/hooman/dataPreparation/fmdlTestData-optical-hydraulic/Frame/' + 'FMDL_2018.04.30_11.38.09.png')\n",
    "\n",
    "frame = cv2.cvtColor(temp, cv2.COLOR_GRAY2BGR) \n",
    "\n",
    "plt.imshow(frame)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "of = imread('/home/hooman/dataPreparation/fmdlTestData-optical-hydraulic/OpticalFlowMagnitude/' + 'FMDL_2018.04.30_11.38.09.png')\n",
    "\n",
    "plt.imshow(of)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "no = imread('/home/hooman/dataPreparation/fmdlTestData-optical-hydraulic/NetOut/' + 'FMDL_2018.04.30_11.38.09.png')\n",
    "\n",
    "plt.imshow(no)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "temp2 = imread('/home/hooman/dataPreparation/fmdlTestData-optical-hydraulic/VES_finalOutput/fragmentation_results/all/' + 'FMDL_2018.04.30_11.38.09.png')\n",
    "\n",
    "fo = cv2.cvtColor(temp2, cv2.COLOR_GRAY2BGR) \n",
    "\n",
    "plt.imshow(fo)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(np.amax(of))\n",
    "\n",
    "\n",
    "combImg = np.zeros((frame.shape[0],2800, 3), np.uint8)\n",
    "\n",
    "combImg[:, 0:frame.shape[1], :] = frame\n",
    "combImg[:, 700:frame.shape[1]+700, :] = cv2.resize(cv2.cvtColor(of, cv2.COLOR_GRAY2BGR), (frame.shape[1], frame.shape[0])) \n",
    "combImg[:, 1400:frame.shape[1]+1400, :] = cv2.resize(cv2.cvtColor(no, cv2.COLOR_GRAY2BGR), (frame.shape[1], frame.shape[0])) \n",
    "combImg[:, 2100:fo.shape[1]+2100, :] = fo\n",
    "\n",
    "\n",
    "plt.imshow(combImg)\n",
    "plt.show()\n",
    "cv2.imwrite('/home/hooman/' + 'combined_FMDL_2018.04.30_11.38.09.png', combImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Converting legecy fm/wm and fontend stuff to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# converting .GMP to .FMDL\n",
    "import os\n",
    "import glob\n",
    "import base64\n",
    "\n",
    "\n",
    "parentInputPath = \"/media/hooman/New Volume/FM_PROJECT_STORAGE/QC-Tests/Hydraulics/OyuTolgoi-CAT6060/good/in/\"\n",
    "\n",
    "outputPath = \"/media/hooman/New Volume/FM_PROJECT_STORAGE/QC-Tests/Hydraulics/OyuTolgoi-CAT6060/good/out/\"\n",
    "\n",
    "#for dires in os.listdir(parentInputPath):\n",
    " #   inputPath = parentInputPath + '/' + dires + '/'\n",
    "    \n",
    "    #files = glob.glob(inputPath+'*.gmp')\n",
    "\n",
    "for filename in os.listdir(parentInputPath):\n",
    "\n",
    "    print(filename)\n",
    "\n",
    "    f = open(parentInputPath + filename,'r')\n",
    "\n",
    "    text = f.read()\n",
    "\n",
    "    outFileName = text[text.find(\"filename\")+11:text.find(\"data\") -3]\n",
    "    print(outFileName)\n",
    "\n",
    "    if (text.find(\"FMDL\") > 0) & (text.find(\"FMDL\") < text.find(\"data\")):\n",
    "\n",
    "        img_txt = text[text.find(\"data\")+7:-4];\n",
    "        print(img_txt)\n",
    "\n",
    "        with open(outputPath+outFileName,\"wb\") as ff:\n",
    "\n",
    "            ff.write(base64.b64decode(img_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# YAML to WMDL\n",
    "\n",
    "import glob\n",
    "from base64 import decodestring\n",
    "import base64\n",
    "\n",
    "\n",
    "import zlib\n",
    "import yaml\n",
    "filename = \"C:/Software/Dev/DLWM-20171026-105/resources/CNRL/SH1006/DLWM_reference.yaml\"\n",
    "with open(filename, 'r') as stream:\n",
    "    yamlfile = yaml.load(stream)\n",
    "    \n",
    "stream = open(filename, 'r')\n",
    "\n",
    "import cv2\n",
    "fs_read = cv2.FileStorage(\"D:/temp/test.yml\", cv2.FILE_STORAGE_READ)\n",
    "import yaml\n",
    "filename = \"D:/temp/test.yml\"\n",
    "with open(filename, 'r') as stream:\n",
    "    yamlfile = yaml.load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#WMDL to YAML\n",
    "import glob\n",
    "from base64 import decodestring\n",
    "import base64\n",
    "\n",
    "inputPath = \"/media/hooman/New Volume/WM_PROJECT_STORAGE/logsFromCobrePanama/Shovel03/oldLog/logs/\"\n",
    "outputPath = \"/media/hooman/New Volume/WM_PROJECT_STORAGE/logsFromCobrePanama/Shovel03/oldLog/yaml/\"\n",
    "files = glob.glob(inputPath+'*.wmdl')\n",
    "import zlib  \n",
    "import os\n",
    "for filename in files:\n",
    "    wmdl = open(filename,'rb').read()\n",
    "    wmyaml = zlib.decompress(wmdl)\n",
    "    with open(outputPath+os.path.basename(filename)[:-5]+\".yaml\",\"wb\") as f:\n",
    "        f.write(wmyaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#WMDL GMP            \n",
    "import glob\n",
    "from base64 import decodestring\n",
    "import base64\n",
    "\n",
    "inputPath = \"N:/randd/temp/WMDL_Logs/WMDL_CVE_S20/\"\n",
    "outputPath = \"C:/Software/Dev/DLWM-20180201/resources/CV/SH20/input_2/\"\n",
    "files = glob.glob(inputPath+'*.gmp')\n",
    "for filename in files:\n",
    "    f = open(filename,'r')\n",
    "    text = f.read()\n",
    "    print(text[text.find(\"filename\")+11:text.find(\"data\")])\n",
    "    if (text.find(\"WMDL\") > 0) & (text.find(\"WMDL\") < text.find(\"data\")):\n",
    "        img_txt = text[text.find(\"data\")+7:-4];\n",
    "        with open(outputPath+text[text.find(\"filename\")+11:text.find(\".wmdl\")+5],\"wb\") as f:\n",
    "            f.write(base64.b64decode(img_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# MTDL GMP\n",
    "import glob\n",
    "import base64\n",
    "\n",
    "inputPath = \"N:/temp/MTDL-Sishen/PH03_4100/\"\n",
    "outputPath = \"N:/randd/MachineLearning/Temp/Sishen/PH03_4100/\"\n",
    "files = glob.glob(inputPath+'*.gmp')\n",
    "for filename in files:\n",
    "    f = open(filename,'r')\n",
    "    text = f.read()\n",
    "    if (text.find(\"MTDL-LEGACY\") > 0) & (text.find(\"MTDL-LEGACY\") < text.find(\"data\")):\n",
    "        img_txt = text[text.find(\"data\")+7:-4];\n",
    "        with open(outputPath+text[text.find(\"filename\")+13:text.find(\".jpg\")+4],\"wb\") as f:\n",
    "            f.write(base64.b64decode(img_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# hs saving YAML from FMDL\n",
    "import zlib\n",
    "\n",
    "logFile = '/media/hooman/New Volume/WM_PROJECT_STORAGE/logsFromCobrePanama/Shovel03/oldLog/logs/WMDL_2017.11.25_08.36.15.wmdl'\n",
    "\n",
    "\n",
    "dl_log = open(logFile, 'rb').read()\n",
    "\n",
    "print(dl_log)\n",
    "\n",
    "#decompressed_log = zlib.decompress(dl_log)\n",
    "\n",
    "#decompressed_log_corrected = decompressed_log.replace(b\"\\t\",b\"\")\n",
    "\n",
    "#decompressed_log = zlib.decompress(dl_log).decode(\"ascii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# hs Saving Frames from YAML (this works)\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as PilImage\n",
    "\n",
    "path2Yamls = '/media/hooman/New Volume/WM_PROJECT_STORAGE/logsFromCobrePanama/Shovel03/oldLog/yaml/'\n",
    "path2SaveFrames = '/media/hooman/New Volume/WM_PROJECT_STORAGE/logsFromCobrePanama/Shovel03/oldLog/out/'\n",
    "\n",
    "\n",
    "for yaml_file_name in os.listdir(path2Yamls):\n",
    "    if '.yaml' in yaml_file_name:\n",
    "        print('opening file:')\n",
    "        print(path2Yamls + yaml_file_name)\n",
    "\n",
    "        # Read YAML file\n",
    "        with open(path2Yamls + yaml_file_name, 'r') as stream:\n",
    "            data_loaded = yaml.load(stream)\n",
    "\n",
    "        #print(data_loaded['Frame'])\n",
    "\n",
    "        img_byteArray =  base64.b64decode(data_loaded['Frame'])\n",
    "\n",
    "        image = PilImage.open(io.BytesIO(img_byteArray)).convert(\"RGB\")\n",
    "        #image.save(path2SaveFrames + yaml_file_name.replace(\".yaml\", \".png\"),\"PNG\")\n",
    "\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening file:\n",
      "/media/hooman/New Volume/WM_PROJECT_STORAGE/logsFromCobrePanama/Shovel03/oldLog/yaml/WMDL_2017.11.25_08.36.15.yaml\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument should be a bytes-like object or ASCII string, not 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-40d341532de2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#print(data_loaded['Frame'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mjson_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb64decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mjson_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ascii\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fullAlgo/lib/python3.5/base64.py\u001b[0m in \u001b[0;36mb64decode\u001b[0;34m(s, altchars, validate)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mbinascii\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_bytes_from_decode_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maltchars\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0maltchars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_bytes_from_decode_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fullAlgo/lib/python3.5/base64.py\u001b[0m in \u001b[0;36m_bytes_from_decode_data\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         raise TypeError(\"argument should be a bytes-like object or ASCII \"\n\u001b[0;32m---> 46\u001b[0;31m                         \"string, not %r\" % s.__class__.__name__) from None\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument should be a bytes-like object or ASCII string, not 'dict'"
     ]
    }
   ],
   "source": [
    "# hs Saving Frames from YAML (This decompresses too but hasn't worked for me yet)\n",
    "import os\n",
    "import io\n",
    "import zlib\n",
    "import base64\n",
    "from base64 import b64encode, b64decode\n",
    "import yaml\n",
    "from PIL import Image as PilImage\n",
    "\n",
    "path2Yamls = '/media/hooman/New Volume/WM_PROJECT_STORAGE/logsFromCobrePanama/Shovel03/oldLog/yaml/'\n",
    "path2SaveFrames = '/media/hooman/New Volume/WM_PROJECT_STORAGE/logsFromCobrePanama/Shovel03/oldLog/out/'\n",
    "\n",
    "\n",
    "for yaml_file_name in os.listdir(path2Yamls):\n",
    "    if '.yaml' in yaml_file_name:\n",
    "        print('opening file:')\n",
    "        print(path2Yamls + yaml_file_name)\n",
    "\n",
    "        # Read YAML file\n",
    "        with open(path2Yamls + yaml_file_name, 'r') as stream:\n",
    "            data_loaded = yaml.safe_load(stream)\n",
    "\n",
    "        #print(data_loaded['Frame'])\n",
    "\n",
    "        json_data = b64decode(data_loaded)\n",
    "        json_data = json.loads(zlib.decompress(json_data).decode(\"ascii\"))\n",
    "\n",
    "        img_byteArray =  base64.b64decode(json_data['Frame'])\n",
    "\n",
    "        image = PilImage.open(io.BytesIO(img_byteArray)).convert(\"RGB\")\n",
    "        image.save(path2SaveFrames + yaml_file_name.replace(\".yaml\", \".png\"),\"PNG\")\n",
    "\n",
    "        #plt.imshow(image)\n",
    "        #plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Cleaning up CSVs with bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# shuffling a csv  (adds an empty line somewhere, and moves the header)\n",
    "\n",
    "csvRows = readCsvRows('/media/hooman/hsSsdPartUbuntu/FM_PROJECT/FMDL_3.1/backhoe/boxDetector_V2_multiclass/try2-withCaseObject-newData/trainingSet.csv')\n",
    "\n",
    "\n",
    "\n",
    "# shuffle the rows\n",
    "from random import shuffle\n",
    "shuffle(csvRows)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#write the shuffled rows to csv\n",
    "csv_file = open('/media/hooman/hsSsdPartUbuntu/FM_PROJECT/FMDL_3.1/backhoe/boxDetector_V2_multiclass/try2-withCaseObject-newData/trainingSet_shuffled.csv', \"w\") \n",
    "\n",
    "\n",
    "# write rows\n",
    "for row in csvRows:\n",
    "    csv_file.write(row + '\\n')\n",
    "\n",
    "csv_file.close()\n",
    "\n",
    "print(\"wrote \" + str(len(csvRows)) + \" rows to csv file\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#read rows from the file you wanna append to\n",
    "existingRowsDic = getCertainClassRowsDictFromCsv('/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try5/trainSet_multiClass_bucket_fineRock_try5_manuallyCleaned.csv', ['matInside'])\n",
    "\n",
    "\n",
    "\n",
    "#read rows from the file you wanna get the new rows from\n",
    "rowsDicToAddFrom = getCertainClassRowsDictFromCsv('/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/unusedCsvFiles/trainSet_multiClass_bucket_fineRockInapp_try3_uncleaned.csv', ['matInside'])\n",
    "\n",
    "\n",
    "\n",
    "#Append the missing rows\n",
    "n = 0\n",
    "rowsDicToAddTo = {}\n",
    "for imId in os.listdir('/home/hooman/dataPreparation/hsTrainingSet/imsToAddMatInsideFor/'):\n",
    "    n += 1\n",
    "    print(imId)\n",
    "    if imId not in existingRowsDic:\n",
    "        if imId in rowsDicToAddFrom:\n",
    "            rowsDicToAddTo[imId] = rowsDicToAddFrom[imId]\n",
    "        else:\n",
    "            print(\"error didn't find:  \" + imId + \"\\n\")\n",
    "    else:\n",
    "        print(\"already there\\n\")\n",
    "\n",
    "print(\"processed \" + str(n) + \" rows\")\n",
    "\n",
    "writeRowDicToCsv(rowsDicToAddTo, '/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try4/trainSet_multiClass_bucket_fineRock_try4_manuallyCleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# delete images from csv\n",
    "imIdsToDelete = os.listdir('/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/cable/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_cable__try1/examplesToRemove/')\n",
    "\n",
    "csvToWorkWith = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/cable/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_cable__try1/firstTry_final.csv'\n",
    "\n",
    "\n",
    "existingRows = readCsvRows(csvToWorkWith)\n",
    "\n",
    "n1 = 0\n",
    "for row in existingRows:\n",
    "    vals = row.split(',')\n",
    "\n",
    "    if vals[0] not in imIdsToDelete:\n",
    "        existingRows.remove(row)\n",
    "        n1 += 1\n",
    "        \n",
    "print(\"in the first run deleted \" + str(n1) +' rows\\n')\n",
    "\n",
    "n2 = 0\n",
    "for row in existingRows:\n",
    "    vals = row.split(',')\n",
    "\n",
    "    if vals[0] not in imIdsToDelete:\n",
    "        existingRows.remove(row)\n",
    "        n2 += 1\n",
    "        \n",
    "print(\"in the second run deleted \" + str(n2) +' rows\\n')\n",
    "print(\"deleted \" + str(n1+n2) + \" rows in total\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# open the file\n",
    "csv_file = open(csvToWorkWith, \"w\") \n",
    "\n",
    "# define column names\n",
    "columnTitles = \"filename,pathname,xmins,xmax,ymins,ymax,class\\n\"\n",
    "csv_file.write(columnTitles)\n",
    "\n",
    "# write rows\n",
    "for r in existingRows:\n",
    "    row = r + '\\n'\n",
    "    csv_file.write(row)\n",
    "\n",
    "csv_file.close()\n",
    "\n",
    "print(\"wrote \" + str(len(existingRows)) + \" rows to csv file\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add no bucket rows to existing csv and shuffle its rows\n",
    "\n",
    "csvRows = readCsvRows('/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try5/trainSet_multiClass_bucket_fineRock_try5_manuallyCleaned.csv')\n",
    "\n",
    "#getRid of the empty row at the end\n",
    "csvRows = csvRows[0:len(csvRows)-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# add the no bucket rows for the images in dir\n",
    "for imId in os.listdir('/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try6/noShovelImagesToAdd/'):\n",
    "    newRow = str(str(imId) + ',' + str(imagesPath) + str(imId) + ',' + '' + ',' + '' + ',' + '' + ',' + '' + ',' + '')\n",
    "    print(newRow)\n",
    "    \n",
    "    csvRows.append(newRow)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# shuffle the rows\n",
    "from random import shuffle\n",
    "shuffle(csvRows)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#write the shuffled rows to csv\n",
    "csv_file = open('/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try5/trainSet_multiClass_bucket_fineRock_try5_manuallyCleaned_new.csv', \"w\") \n",
    "\n",
    "\n",
    "# write rows\n",
    "for row in csvRows:\n",
    "    csv_file.write(row + '\\n')\n",
    "\n",
    "csv_file.close()\n",
    "\n",
    "print(\"wrote \" + str(len(csvRows)) + \" rows to csv file\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# remove matInsideBoundary rows from CSV\n",
    "\n",
    "rowsDic = getCertainClassRowsDictFromCsv('/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/trainSet_bucketAndMatInsideBoundaries_allImages_BucAndPnH_cleaned.csv', ['bucket'])\n",
    "\n",
    "writeRowDicToCsv(rowsDic, '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/trainSet_justBucketBoundaries_allImages_BucAndPnH_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "source": [
    "## Converting existing network CSVs to out csv format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The CSVs produced by the existing networks provide the topLeft cornor's x value, yvalu, a width, and a height. This must be converted to the format used by us which provides top left and bottom right cornors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "existNetRows = readCsvRows(\"/home/hooman/resultsFromExistingNetwork/testSetFregmentationResults/output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "existNetRowsDict = {}\n",
    "for row in existNetRows[0:60]:\n",
    "    vals = row.split(',')\n",
    "    existNetRowsDict[vals[0]] = vals[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gt_rows = readCsvRows(\"/home/hooman/dataPreparation/testSet_noBbxImagesIncluded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#write rows\n",
    "rows = []\n",
    "for row in gt_rows[1:len(gt_rows)-1]:\n",
    "    vals = row.split(',')\n",
    "    fileName = vals[0]\n",
    "    filePath = imagesPath + fileName\n",
    "    print(\"processing file:\\n\", filePath)\n",
    "    \n",
    "    if fileName in existNetRowsDict:\n",
    "        topx, topy, width, height = existNetRowsDict[fileName]\n",
    "\n",
    "        (topx, topy, width, height) = (int(round(float(topx))), int(round(float(topy))), int(round(float(width))), int(round(float(height)))) \n",
    "\n",
    "        xmin = topx\n",
    "        xmax = topx + width\n",
    "        ymin = topy\n",
    "        ymax = topy + height\n",
    "        \n",
    "        row = fileName + \",\" + filePath + \",\" + str(xmin) +\",\"+ str(xmax) + \",\" + str(ymin) + \",\" + str(ymax) + \",\" + \"bucket\" + \"\\n\"\n",
    "        \n",
    "    else:\n",
    "        row = fileName + \",\" + filePath + \",\" + \"\" +\",\"+ \"\" + \",\" + \"\" + \",\" + \"\" + \",\" + \"bucket\" + \"\\n\"\n",
    "        print(\"Found no bucket boundary\\n\")\n",
    "        \n",
    "    rows.append(row)\n",
    "    \n",
    "print(\"processes \"+ str(len(rows)) + \" rows\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "writeRowsToCsv(rows, \"/home/hooman/resultsFromExistingNetwork/testSetFregmentationResults/testSetOutputConverted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Converting .pdn files to .png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#converting .pdn (dot net) to pnd\n",
    "\n",
    "import pypdn\n",
    "\n",
    "pdnsDir = \"/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/pdnLabels/\"\n",
    "finalDir = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/regen/'\n",
    "\n",
    "#fileName = '1_20161115-222501_0001n0_16697.pdn'\n",
    "for fileName in os.listdir(pdnsDir):\n",
    "\n",
    "    #read the layer info\n",
    "    layeredImage = pypdn.read(pdnsDir + fileName)\n",
    "    #print(layeredImage)\n",
    "\n",
    "\n",
    "    #make the background invisible\n",
    "    layer = layeredImage.layers[0]\n",
    "    layer.visible = False\n",
    "\n",
    "\n",
    "    #Combine the layers into a numpy image\n",
    "    flatImage = layeredImage.flatten(asByte=True)\n",
    "\n",
    "    #plt.figure()\n",
    "    #plt.imshow(flatImage)\n",
    "    #plt.show()\n",
    "\n",
    "    newFileName = fileName.replace('.pdn', '.png')\n",
    "    cv2.imwrite(finalDir + newFileName, flatImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## working with h5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#import skimage\n",
    "#from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "#from skimage import img_as_ubyte\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "#from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import h5py\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read an H5 file\n",
    "filename = 'C:\\\\Users\\\\hooman\\\\Desktop\\\\WM2.0Project\\\\oldOutputOfH5maker\\\\60x150_Synt_False_Norm_True_Enhance_False_HistEqu_False_HistNorm_False\\\\Test.h5'\n",
    "file = h5py.File(filename, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Reading and desplaying one image\n",
    "imgnb = 30\n",
    "\n",
    "for imgnb in range(23584):\n",
    "    image10 = list(file['data'][imgnb])\n",
    "    height10 = list(file['height'][imgnb])\n",
    "    label10 = list(file['label'][imgnb])\n",
    "    mask10 = list(file['mask'][imgnb])\n",
    "\n",
    "    img = cv2.cvtColor(image10[0], cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    print(len(img))\n",
    "    print(len(img[0]))\n",
    "\n",
    "    print(height10)\n",
    "    print(label10)\n",
    "    print(mask10)\n",
    "\n",
    "\n",
    "    cv2.circle(img,(30, int((1-height10[0])*150)), 2, (0,255,0), -1)\n",
    "    cv2.circle(img,(30, int((1-height10[1])*150)), 2, (0,0,255), -1)\n",
    "    cv2.circle(img,(30, int((1-height10[2])*150)), 2, (255,0,0), -1)\n",
    "    cv2.circle(img,(30, int((1-height10[3])*150)), 2, (255,255,0), -1)\n",
    "\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save an array of images into an h5 file\n",
    "outputH5Path = \"N:\\\\randd\\\\MachineLearning\\\\Projects\\\\ShovelMetrics\\\\Optical\\\\Dataset\\\\BucketPattern\\\\nLS_163_Backhoe\\\\WM_FM_TM_EMDUBUO_CACA\\\\h5\\\\Telfer_test_h5\\\\h5\\\\TestB.h5\"\n",
    "with h5py.File(outputH5Path, \"w\") as outputFile:\n",
    "    images = outputFile.create_dataset('data', (108,1,222,254), dtype='f')    \n",
    "    outputFile.flush()\n",
    "    \n",
    "    i = 0\n",
    "    for fImg in imgPyAr:\n",
    "        images[i, :, :, :]  = np.expand_dims(fImg[:,:, 0], axis=0)\n",
    "        \n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Writing just 100 of images to h5 file\n",
    "\n",
    "inputFile = h5py.File('C:\\\\Users\\\\hooman\\\\Desktop\\\\WM2.0Project\\\\h5MakerOutput_10-0\\\\60x150_Synt_False_Norm_True_Enhance_False_HistEqu_False_HistNorm_False\\\\Test.h5', 'r')\n",
    "\n",
    "with h5py.File('C:\\\\Users\\\\hooman\\\\Desktop\\\\WM2.0Project\\\\oldOutputOfH5maker\\\\reduced.h5', \"w\") as outputFile:\n",
    "    images = outputFile.create_dataset('data', (804828,1,150,60), dtype='f')\n",
    "    heights = outputFile.create_dataset('height', (804828,4), dtype='f')\n",
    "    labels = outputFile.create_dataset('label', (804828,4), dtype='f')\n",
    "    masks = outputFile.create_dataset('mask', (804828,4), dtype='f')\n",
    "    \n",
    "    outputFile.flush()\n",
    "    \n",
    "    i = 0\n",
    "    for imgnb in range(0,10000,50):\n",
    "        images[i]  = inputFile['data'][imgnb]\n",
    "        heights[i] = inputFile['height'][imgnb]\n",
    "        labels[i]  = inputFile['label'][imgnb]\n",
    "        masks[i]   = inputFile['mask'][imgnb]\n",
    "        \n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font color='red'>To combine multiple files into one use external links. h5 has the functionality that you can make external links to multiple files (no matter whre they are) inside one file. Your progrtams can then use that one file as if it has the entire data in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Legacy U-Net padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Identify top left and bottom right corners of an image with black margin\n",
    "\n",
    "\n",
    "for i in range(222) :\n",
    "    for j in range(254):\n",
    "        flag = False\n",
    "        if not img[i,j,:].all() == 0:\n",
    "            print(i)\n",
    "            print(j)\n",
    "            flag = True\n",
    "            break\n",
    "    if flag:\n",
    "        break\n",
    "        \n",
    "print(\"\\n\\n\\n\")        \n",
    "for i in reversed(range(222)) :\n",
    "    for j in reversed(range(254)):\n",
    "        flag = False\n",
    "        if not img[i,j,:].all() == 0:\n",
    "            print(i)\n",
    "            print(j)\n",
    "            flag = True\n",
    "            break\n",
    "    if flag:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# resize and pad a directory of images for unet\n",
    "\n",
    "input_dir = \"N:\\\\randd\\\\MachineLearning\\\\Projects\\\\ShovelMetrics\\\\Optical\\\\Dataset\\\\BucketPattern\\\\nLS_163_Backhoe\\\\WM_FM_TM_EMDUBUO_CACA\\\\h5\\\\Telfer_test_h5\\\\image\\\\\"\n",
    "imgPyAr = []\n",
    "\n",
    "for img_name in os.listdir(input_dir):\n",
    "    img = cv2.imread(input_dir + img_name)\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "\n",
    "    orig_h, orig_w, _ = img.shape\n",
    "    print('orig_h: ' + str(orig_h) + '\\norig_w: ' + str(orig_w))\n",
    "\n",
    "\n",
    "\n",
    "    resized_img = cv2.resize(img,(orig_w/4, orig_h/4))\n",
    "    #plt.imshow(resized_img)\n",
    "    #plt.show()\n",
    "\n",
    "    resized_h, resized_w, _ = resized_img.shape\n",
    "    print('resized_h: ' + str(resized_h) + '\\nresized_w: ' + str(resized_w))\n",
    "\n",
    "\n",
    "    final_h = 222\n",
    "    final_w = 254\n",
    "    margin_r = 49\n",
    "    margin_b = 57\n",
    "    final_img = np.zeros((final_h, final_w, 3),dtype = np.float32)\n",
    "    print(final_img.shape)\n",
    "    margin_l = final_w - margin_r - resized_w\n",
    "    margin_t = final_h - margin_b - resized_h\n",
    "    print('margin_l: ' + str(margin_l) + '\\nmargin_t: ' + str(margin_t))\n",
    "\n",
    "\n",
    "    final_img[margin_t:(final_h - margin_b), margin_l:(final_w - margin_r), :] = resized_img[:, :, :]/float(255)\n",
    "\n",
    "    #plt.imshow(final_img)\n",
    "    #plt.show()\n",
    "    imgPyAr.append(final_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Image Augmentation using imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get and resize train images and masks (same as in unet notebook except just one image)\n",
    "TRAIN_PATH = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameNetworkAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/finalTrainingSet_images_fullSize/'\n",
    "\n",
    "MASK_PATH  = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameNetworkAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/finalTrainingSet_masks_fullSize/'\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "train_ids = os.listdir(TRAIN_PATH)\n",
    "train_ids = train_ids[4:6]\n",
    "\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "\n",
    "for n, fileName in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    img = imread(TRAIN_PATH + fileName)[:,:,:IMG_CHANNELS]\n",
    "    \n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    \n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    \n",
    "    mask_ = imread(MASK_PATH + fileName )\n",
    "\n",
    "    #expand dim just converts the (h,w,) image to (h,w,1) look at above for experimentation with np.expand_dim\n",
    "    mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                  preserve_range=True), axis=-1)\n",
    "\n",
    "    #hs this in effect adds all the masks together into one mask of the same size.Since masks are bindary.\n",
    "    mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check if the data we just loaded looks all right\n",
    "ix = 0\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Generatign FM-FrameSelection Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Generatign FM-FrameSelection Plots\n",
    "\n",
    "allFramesDir = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/frameSelection/try7_t40b10_0,150,200,125,1,outSideImageObjRemoved/allFrames_1004_ESP_S04_017/'\n",
    "\n",
    "bufferedFramesDir = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/frameSelection/try7_t40b10_0,150,200,125,1,outSideImageObjRemoved/bufferedFrames_1004_ESP_S04_017/'\n",
    "\n",
    "selectedFramesDir = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/frameSelection/try7_t40b10_0,150,200,125,1,outSideImageObjRemoved/selectedFrames_1004_ESP_S04_017/'\n",
    "\n",
    "vidName = '1004_ESP_S04_017_fmSelection.png'\n",
    "\n",
    "savePath = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/frameSelection/try7_t40b10_0,150,200,125,1,outSideImageObjRemoved/'\n",
    "\n",
    "allFrames = []\n",
    "for imName in os.listdir(allFramesDir):\n",
    "    allFrames.append(int(imName.split('_')[-1][:-4]))\n",
    "    \n",
    "allFrames.sort()\n",
    "\n",
    "\n",
    "\n",
    "bufferedFrames = []\n",
    "for imName in os.listdir(bufferedFramesDir):\n",
    "    bufferedFrames.append(int(imName.split('_')[-1][:-4]))\n",
    "    \n",
    "bufferedFrames.sort()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "selectedFrames = []\n",
    "for imName in os.listdir(selectedFramesDir):\n",
    "    selectedFrames.append(int(imName.split('_')[-1][:-4]))\n",
    "    \n",
    "selectedFrames.sort()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30,5))\n",
    "ax = plt.axes()\n",
    "loc = plticker.MultipleLocator(base=1800.0)\n",
    "ax.xaxis.set_major_locator(loc)\n",
    "ax.grid()\n",
    "\n",
    "plt.plot(allFrames, len(allFrames) * [0], label='received')\n",
    "plt.plot(bufferedFrames, len(bufferedFrames) * [0.2], 'bo', label='buffered')\n",
    "plt.plot(selectedFrames, len(selectedFrames) * [0.5], 'go', label='selected')\n",
    "plt.ylabel('buffered=Blue,  Selected=Green')\n",
    "plt.xlabel('frameNumber(1 minute tick)')\n",
    "\n",
    "\n",
    "plt.savefig(savePath + vidName)\n",
    "plt.legend('best')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "\n",
    "hsDic = {'received': len(allFrames), 'buffered':len(bufferedFrames), 'selected':len(selectedFrames)}\n",
    "plt.bar(hsDic.keys(), hsDic.values(), color='g')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# library's example of mask augmentation\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "ia.seed(1)\n",
    "\n",
    "\n",
    "image = X_train[0]\n",
    "segmap = Y_train[0]\n",
    "segmap = ia.SegmentationMapOnImage(segmap, shape=image.shape, nb_classes=1+1)\n",
    "\n",
    "# Define our augmentation pipeline.\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Dropout([0.05, 0.2]),      # drop 5% or 20% of all pixels\n",
    "    iaa.Sharpen((0.0, 1.0)),       # sharpen the image\n",
    "    iaa.Affine(rotate=(-45, 45)),  # rotate by -45 to 45 degrees (affects heatmaps)\n",
    "    iaa.ElasticTransformation(alpha=50, sigma=5)  # apply water effect (affects heatmaps)\n",
    "], random_order=True)\n",
    "\n",
    "# Augment images and heatmaps.\n",
    "images_aug = []\n",
    "segmaps_aug = []\n",
    "for _ in range(5):\n",
    "    seq_det = seq.to_deterministic()\n",
    "    images_aug.append(seq_det.augment_image(image))\n",
    "    segmaps_aug.append(seq_det.augment_segmentation_maps([segmap])[0])\n",
    "\n",
    "# We want to generate an image of original input images and heatmaps before/after augmentation.\n",
    "# It is supposed to have five columns: (1) original image, (2) augmented image,\n",
    "# (3) augmented heatmap on top of augmented image, (4) augmented heatmap on its own in jet\n",
    "# color map, (5) augmented heatmap on its own in intensity colormap,\n",
    "# We now generate the cells of these columns.\n",
    "#\n",
    "# Note that we add a [0] after each heatmap draw command. That's because the heatmaps object\n",
    "# can contain many sub-heatmaps and hence we draw command returns a list of drawn sub-heatmaps.\n",
    "# We only used one sub-heatmap, so our lists always have one entry.\n",
    "cells = []\n",
    "for image_aug, segmap_aug in zip(images_aug, segmaps_aug):\n",
    "    cells.append(image)                                      # column 1\n",
    "    cells.append(segmap.draw_on_image(image))                # column 2\n",
    "    cells.append(image_aug)                                  # column 3\n",
    "    cells.append(segmap_aug.draw_on_image(image_aug))        # column 4\n",
    "    cells.append(segmap_aug.draw(size=image_aug.shape[:2]))  # column 5\n",
    "\n",
    "# Convert cells to grid image and save.\n",
    "grid_image = ia.draw_grid(cells, cols=5)\n",
    "imageio.imwrite(\"/home/hooman/sdc1Storage/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameNetworkAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/example_segmaps.jpg\", grid_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Hs example of mask augmentation\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "ia.seed(1)\n",
    "\n",
    "\n",
    "image = X_train[1]\n",
    "segmap = Y_train[1]\n",
    "segmap = ia.SegmentationMapOnImage(segmap, shape=image.shape, nb_classes=1+1)\n",
    "\n",
    "\n",
    "\n",
    "X_train_final_augmented = []\n",
    "Y_train_final_augmented= []\n",
    "\n",
    "\n",
    "cropAug = iaa.Sequential([\n",
    "    iaa.CropAndPad(\n",
    "    percent=(-0.3, 0.3),\n",
    "    pad_mode=[\"edge\"]),\n",
    "], random_order=False)\n",
    "\n",
    "\n",
    "scaleAug = iaa.Sequential([\n",
    "    iaa.Scale((0.5, 1.0)),\n",
    "], random_order=False)\n",
    "\n",
    "\n",
    "rotateAug = iaa.Sometimes(0.5, iaa.Affine(rotate=(-10, 10)))\n",
    "\n",
    "dropOutAug = iaa.Sometimes(0.5, iaa.Dropout([0.05, 0.1]))\n",
    "\n",
    "pixelValAddAug = iaa.Sometimes(0.5, iaa.Add((-40,40)))\n",
    "\n",
    "sharpenAug = iaa.Sometimes(0.2, iaa.Sharpen(alpha=(0.05, 0.2)))\n",
    "\n",
    "contrastNormAug = iaa.Sometimes(0.2, iaa.ContrastNormalization((0.5, 1.5)))\n",
    "\n",
    "\n",
    "    \n",
    "# X translation\n",
    "augResIm = iaa.Affine(translate_px={\"x\":-5}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"x\":-5}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "augResIm = iaa.Affine(translate_px={\"x\":-10}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"x\":-10}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "   \n",
    "augResIm = iaa.Affine(translate_px={\"x\":-15}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"x\":-15}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "augResIm = iaa.Affine(translate_px={\"x\":5}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"x\":5}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "   \n",
    "    \n",
    "augResIm = iaa.Affine(translate_px={\"x\":10}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"x\":10}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "augResIm = iaa.Affine(translate_px={\"x\":15}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"x\":15}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "\n",
    "# Y translation\n",
    "augResIm = iaa.Affine(translate_px={\"y\":5}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"y\":5}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "augResIm = iaa.Affine(translate_px={\"y\":10}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"y\":10}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "augResIm = iaa.Affine(translate_px={\"y\":15}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"y\":15}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "#horizantal flip\n",
    "augResIm = iaa.Fliplr(1).augment_image(image)\n",
    "augResMask = iaa.Fliplr(1).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "    \n",
    "#Random crop\n",
    "cropAug_det = cropAug.to_deterministic()\n",
    "augResIm = cropAug_det.augment_image(image)\n",
    "augResMask = cropAug_det.augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "\n",
    "#Random rotate or elastically transform\n",
    "rotateAug_det = rotateAug.to_deterministic()\n",
    "augResIm = rotateAug_det.augment_image(image)\n",
    "augResMask = rotateAug_det.augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "#drop some pixels at random 50% of the time\n",
    "dropOutAug_det = dropOutAug.to_deterministic()\n",
    "augResIm = dropOutAug_det.augment_image(image)\n",
    "augResMask = dropOutAug_det.augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "# add rand nb between -40,40 to some pixels 50% of the time \n",
    "pixelValAddAug_det = pixelValAddAug.to_deterministic()\n",
    "augResIm = pixelValAddAug_det.augment_image(image)\n",
    "augResMask = pixelValAddAug_det.augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "#sharpen images 20% of the time\n",
    "sharpenAug_det = sharpenAug.to_deterministic()\n",
    "augResIm = sharpenAug_det.augment_image(image)\n",
    "augResMask = sharpenAug_det.augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "#contrastNorm images 20% of the time\n",
    "contrastNormAug_det = contrastNormAug.to_deterministic()\n",
    "augResIm = contrastNormAug_det.augment_image(image)\n",
    "augResMask = contrastNormAug_det.augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "cells = []\n",
    "for image_aug, segmap_aug in zip(X_train_final_augmented, segmaps_aug):\n",
    "    imshow(image_aug)\n",
    "    plt.show()\n",
    "    imshow(np.squeeze(segmap_aug))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# hs list of all augmentations I've looked at\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Dropout([0.0, 0.2]),\n",
    "    iaa.Add((-40,40)),\n",
    "    iaa.AddElementwise((-10, 10)),\n",
    "    iaa.AdditiveGaussianNoise(scale=0.1*255),\n",
    "    iaa.GaussianBlur(sigma=1.0),\n",
    "    iaa.Sharpen(alpha=0.2),\n",
    "    iaa.ElasticTransformation(alpha=50, sigma=5),\n",
    "    iaa.Scale((0.5, 1.0)),\n",
    "    iaa.CropAndPad(\n",
    "    percent=(-0.3, 0.3),\n",
    "    pad_mode=[\"constant\"],\n",
    "    pad_cval=(0, 128)),\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.ContrastNormalization((0.5, 1.5)),\n",
    "    iaa.Affine(rotate=(-10, 10)),  # rotate by -10 to 10 degrees (affects heatmaps)\n",
    "    iaa.Affine(translate_px={\"x\":-5}),\n",
    "    iaa.Affine(translate_px={\"x\":-10}),\n",
    "    iaa.Affine(translate_px={\"x\":-15}),\n",
    "    iaa.Affine(translate_px={\"x\":5}),\n",
    "    iaa.Affine(translate_px={\"x\":10}),\n",
    "    iaa.Affine(translate_px={\"x\":15}),\n",
    "    iaa.Affine(translate_px={\"y\":5}),\n",
    "    iaa.Affine(translate_px={\"y\":10}),\n",
    "    iaa.Affine(translate_px={\"y\":15}),\n",
    "], random_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Adding external links to concatenate files\n",
    "\n",
    "import h5py\n",
    "\n",
    "outFile =  h5py.File('C:\\\\Users\\\\hooman\\\\Desktop\\\\WM2.0Project\\\\oldOutputOfH5maker\\\\combinedTrainingSetJustLinks.h5', \"a\")\n",
    "\n",
    "\n",
    "outFile['data'] = h5py.ExternalLink(\"C:\\\\Users\\\\hooman\\\\Desktop\\\\WM2.0Project\\\\h5MakerOutput_10-0\\\\60x150_Synt_False_Norm_True_Enhance_False_HistEqu_False_HistNorm_False\\\\Train.h5\", \"/data\")\n",
    "outFile['height'] = h5py.ExternalLink(\"C:\\\\Users\\\\hooman\\\\Desktop\\\\WM2.0Project\\\\h5MakerOutput_10-0\\\\60x150_Synt_False_Norm_True_Enhance_False_HistEqu_False_HistNorm_False\\\\Train.h5\", \"/height\")\n",
    "outFile['label'] = h5py.ExternalLink(\"C:\\\\Users\\\\hooman\\\\Desktop\\\\WM2.0Project\\\\h5MakerOutput_10-0\\\\60x150_Synt_False_Norm_True_Enhance_False_HistEqu_False_HistNorm_False\\\\Train.h5\", \"/label\")\n",
    "outFile['mask'] = h5py.ExternalLink(\"C:\\\\Users\\\\hooman\\\\Desktop\\\\WM2.0Project\\\\h5MakerOutput_10-0\\\\60x150_Synt_False_Norm_True_Enhance_False_HistEqu_False_HistNorm_False\\\\Train.h5\", \"/mask\")\n",
    "\n",
    "\n",
    "\n",
    "outFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'/> Parking Occupancy demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def loadFrameNames(path2textPreds):\n",
    "    frameNamesDict = {}\n",
    "    for textId in os.listdir(path2textPreds):\n",
    "        frameNb = int(textId.split('_')[-1].replace('.txt',''))\n",
    "        frameNamesDict[frameNb] = textId\n",
    "    return frameNamesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def addDistance2zone(det):\n",
    "    zone_xmin = int(450)\n",
    "    zone_xmax = int(750)\n",
    "    zone_ymin = int(350)\n",
    "    zone_ymax = int(750)\n",
    "    zone_xcent = int((zone_xmin + zone_xmax)/2)\n",
    "    zone_ycent = int((zone_ymin + zone_ymax)/2)\n",
    "    \n",
    "    dist = np.sqrt( (zone_xcent - det['xcent'])**2 + (zone_ycent - det['ycent'])**2 )\n",
    "    det['dist'] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def readPredClosest2zoneIntoDict(predLines, imgW, imgH):\n",
    "    finalDet = {'xmin':0,'xmax':0,'ymin':0,'ymax':0,'xcent':0,\\\n",
    "                'ycent':0,'w':0,'h':0,'valid':0}\n",
    "    minDistanceSoFar = 10000000\n",
    "    for line in predLines:\n",
    "        labelList = line.split(\" \")\n",
    "\n",
    "        xcent = float(labelList[2]) * imgW\n",
    "        ycent = float(labelList[3]) * imgH\n",
    "        w = float(labelList[4]) * imgW\n",
    "        h = float(labelList[5]) * imgH\n",
    "\n",
    "        xmin = int(xcent - w/2)\n",
    "        ymin = int(ycent - h/2)\n",
    "        xmax = int(xcent + w/2)\n",
    "        ymax = int(ycent + h/2)\n",
    "        \n",
    "        thisDet = {\n",
    "            'xmin':xmin,\n",
    "            'xmax':xmax,\n",
    "            'ymin':ymin,\n",
    "            'ymax':ymax,\n",
    "            'xcent':xcent,\n",
    "            'ycent':ycent,\n",
    "            'w':w,\n",
    "            'h':h,\n",
    "        }\n",
    "        \n",
    "        addDistance2zone(thisDet)\n",
    "        if thisDet['dist'] < minDistanceSoFar:\n",
    "            minDistanceSoFar = thisDet['dist']\n",
    "            finalDet = thisDet\n",
    "            finalDet['valid'] = 1\n",
    "        \n",
    "    return finalDet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def isStationary(det, previousDet):\n",
    "    maxAllowedMovement = 10\n",
    "    dist = np.sqrt( (previousDet['xcent'] - det['xcent'])**2 + (previousDet['ycent'] - det['ycent'])**2 )\n",
    "    return dist < maxAllowedMovement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def updateBuffer(buffer, det, previousDet, previousDecision):\n",
    "    from statistics import mode\n",
    "    # returns (noDecision) (Empty) (Occupied) ('Error')\n",
    "    maxAllowedDist2pump = 100\n",
    "    bufferSize2makeDecision = 5\n",
    "    \n",
    "    occupied =\\\n",
    "    det['valid'] and det['dist'] < maxAllowedDist2pump and isStationary(det, previousDet)\n",
    "    \n",
    "    buffer.append(occupied)\n",
    "    \n",
    "#     print('valid')\n",
    "#     print(det['valid'])\n",
    "#     if det['valid']:\n",
    "#         print('dist')\n",
    "#         print(det['dist'])\n",
    "#         print('station')\n",
    "#         print(isStationary(det, previousDet))\n",
    "#         print('occ')\n",
    "#         print(occupied)\n",
    "#     print('\\n')\n",
    "    \n",
    "    if len(buffer) >= bufferSize2makeDecision:\n",
    "        m = mode(buffer)\n",
    "        buffer.clear()\n",
    "        \n",
    "#         print('mode')\n",
    "#         print(m)\n",
    "#         print('\\n')\n",
    "        \n",
    "        if m == 1:\n",
    "            return 'Occupied'\n",
    "        elif m == 0:\n",
    "            return 'Empty'\n",
    "        else:\n",
    "            return 'Error'\n",
    "    else:\n",
    "        return previousDecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def writeResultOnImage(text, img):\n",
    "    zone_xmin = int(450)\n",
    "    zone_xmax = int(750)\n",
    "    zone_ymin = int(350)\n",
    "    zone_ymax = int(750)\n",
    "    zone_xcent = int((zone_xmin + zone_xmax)/2)\n",
    "    zone_ycent = int((zone_ymin + zone_ymax)/2)\n",
    "    \n",
    "    cv2.rectangle(img,(zone_xmin, zone_ymin),(zone_xmax, zone_ymax),(255,0,0),1)\n",
    "    cv2.circle(img,(zone_xcent, zone_ycent),5, (255,0,0), -1)\n",
    "    \n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    textlocX = 210\n",
    "    textlocY = 250\n",
    "    \n",
    "    cv2.putText(img,text,(textlocX,textlocY), font, 2,(0,255,0), 3, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path2textPreds = '/home/hooman/gasstation_videos/03000002242000000/predsText_1fps/'\n",
    "path2imagePreds = '/home/hooman/gasstation_videos/03000002242000000/predsImage_1fps/'\n",
    "path2saveOverlays = '/home/hooman/gasstation_videos/03000002242000000/overlays_1fps/'\n",
    "\n",
    "buffer = []\n",
    "previousDet = {'xmin':0,'xmax':0,'ymin':0,'ymax':0,'xcent':0,\\\n",
    "               'ycent':0,'w':0,'h':0,'valid':0}\n",
    "previousDecision = 'noDecision'\n",
    "\n",
    "textPredNamesDict = loadFrameNames(path2textPreds)\n",
    "for frameNb in sorted(list(textPredNamesDict.keys())):\n",
    "    textId = textPredNamesDict[frameNb]\n",
    "    labelFile = open(path2textPreds + textId, 'r')\n",
    "    \n",
    "    imageId = textId.replace('.txt', '.jpg')\n",
    "    image = imread(path2imagePreds + imageId)\n",
    "    imH, imW, _ = image.shape\n",
    "    \n",
    "    det = readPredClosest2zoneIntoDict(labelFile.readlines(), imW, imH)\n",
    "    \n",
    "    decision = updateBuffer(buffer, det, previousDet, previousDecision)\n",
    "    previousDet = det\n",
    "    previousDecision = decision\n",
    "    \n",
    "#     print(textId)\n",
    "    writeResultOnImage(decision, image)\n",
    "    imsave(path2saveOverlays + imageId, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font color='blue'/> FMDL Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Method Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sortLabelsDic(labelsDic, imgLabel, img=[]):\n",
    "\n",
    " #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "            \n",
    "    '''\n",
    "    if len(img) >0 :\n",
    "        print(sortedLabelColsDic)\n",
    "        print(\"\\n\")\n",
    "        print(sortedLabelRowsDic)\n",
    "        print(\"\\n\")\n",
    "    ''' \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ############## Bucket Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    \n",
    "    lowColValsTeeth = []\n",
    "    highColValsTeeth = []\n",
    "    for itemKey in sortedLabelColsDic.keys():\n",
    "        if itemKey == 'teethCols':\n",
    "            labV = sortedLabelColsDic[itemKey]\n",
    "            for v in labV:\n",
    "                lowColValsTeeth.append(v[0])\n",
    "                highColValsTeeth.append(v[len(v)-1])\n",
    "        \n",
    "        labV = sortedLabelColsDic[itemKey]\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    \n",
    "    lowRowValsTeeth = []\n",
    "    highRowValsTeeth = []\n",
    "    for itemKey in sortedLabelRowsDic.keys():\n",
    "        if itemKey == 'teethRows':\n",
    "            labV = sortedLabelRowsDic[itemKey]\n",
    "            for v in labV:\n",
    "                lowRowValsTeeth.append(v[0])\n",
    "                highRowValsTeeth.append(v[len(v)-1])\n",
    "\n",
    "        labV = sortedLabelRowsDic[itemKey]\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "\n",
    "    \n",
    "\n",
    "    #get the bucket boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    yminsTeeth = np.sort(np.array(lowRowValsTeeth))\n",
    "    ymaxsTeeth = np.sort(np.array(highRowValsTeeth))\n",
    "    \n",
    "    '''\n",
    "    print('lowColValsTeeth:')\n",
    "    print(lowColValsTeeth)\n",
    "    print('highColValsTeeth:')\n",
    "    print(highColValsTeeth)\n",
    "    \n",
    "    print('imageShape')\n",
    "    print(imgLabel.shape)\n",
    "    '''\n",
    "    \n",
    "    return xmins, xmaxs, ymins, ymaxs, yminsTeeth, ymaxsTeeth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getBucketBoundariesTooth2ToothV2(imgLabel, img=[]):\n",
    "\n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        \n",
    "                \n",
    "        '''\n",
    "        \n",
    "        #for Cable\n",
    "        'sheave'     :np.where(np.all(imgLabel == sheave, axis=-1)),\n",
    "        'teeth'     :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'fmInapp'     :np.where(np.all(imgLabel == fmInapp, axis=-1)),\n",
    "        'fineInside'     :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'emptyInside'     :np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'     :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'dust'     :np.where(np.all(imgLabel == dust, axis=-1)),\n",
    "        'rockInside'     :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'wmInapp'     :np.where(np.all(imgLabel == wmInapp, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1))\n",
    "        '''\n",
    "        \n",
    "        #for Hydraulics\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        'wmInapp':np.where(np.all(imgLabel == wmInapp, axis=-1)),\n",
    "        'fineInside2' : np.where(np.all(imgLabel == fineInside2, axis=-1))\n",
    "    }\n",
    "    \n",
    "    if len(img) >0 :\n",
    "        plt.imshow(imgLabel)\n",
    "        plt.show()\n",
    "        print(labelsDic)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "    xmins, xmaxs, ymins, ymaxs, yminsTeeth, ymaxsTeeth = sortLabelsDic(labelsDic, imgLabel, img)\n",
    "    \n",
    "          \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0:\n",
    "          \n",
    "        if len(yminsTeeth) > 0 and len(ymaxsTeeth) > 0 and (ymaxsTeeth[len(ymaxsTeeth)-1] - yminsTeeth[0]) > (0.5 * imgLabel.shape[1]):\n",
    "            boundariesDict['bucketInit'] = [xmins[0], xmaxs[len(xmaxs)-1], yminsTeeth[0], ymaxsTeeth[len(ymaxsTeeth)-1]]\n",
    "        \n",
    "        else:\n",
    "            boundariesDict['bucketInit'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1]]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    if 'bucketInit' in boundariesDict:\n",
    "        #(xmin, xmax, ymin, ymax) = boundariesDict['bucketInit']\n",
    "        #cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(255,0,0),3)\n",
    "        \n",
    "        bucketInitHeight = boundariesDict['bucketInit'][1] - boundariesDict['bucketInit'][0]\n",
    "        quart = int(boundariesDict['bucketInit'][0] + bucketInitHeight * 0.4)\n",
    "        \n",
    "        labelsDic2 = {\n",
    "            'fineInside_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == fineInside, axis=-1)),\n",
    "            'fineInside2_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == fineInside2, axis=-1)),\n",
    "            'inapInside_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == inapInside, axis=-1)),\n",
    "            'emptyInside_q':np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == emptyInside, axis=-1)),\n",
    "            'wmInside_q'   :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == wmInside, axis=-1)),\n",
    "            'teeth_q'      :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == teeth, axis=-1)),\n",
    "            'shadow_q'     :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == shadow, axis=-1)),\n",
    "            'wmInapp_q':np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == wmInapp, axis=-1)),\n",
    "            \n",
    "            'rockInside_q' : np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == rockInside, axis=-1)),\n",
    "            #'dust_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == dust, axis=-1)),\n",
    "            #'case_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == case, axis=-1)),\n",
    "        }\n",
    "        \n",
    "        \n",
    "        \n",
    "        xmins2, xmaxs2, ymins2, ymaxs2, yminsTeeth2, ymaxsTeeth2 = sortLabelsDic(labelsDic2, imgLabel, img)\n",
    "        \n",
    "        if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins2) > 0 and len(ymaxs2) > 0:\n",
    "\n",
    "            if len(yminsTeeth2) > 0 and len(ymaxsTeeth2) > 0 and (ymaxsTeeth2[len(ymaxsTeeth2)-1] - yminsTeeth2[0]) > (0.5 * imgLabel.shape[1]):\n",
    "                boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], yminsTeeth2[0], ymaxsTeeth2[len(ymaxsTeeth2)-1]]\n",
    "\n",
    "            else:\n",
    "                boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins2[0], ymaxs2[len(ymaxs2)-1]]\n",
    "        \n",
    "                \n",
    "\n",
    "        ##############################################\n",
    "        ######### Draw Boundaries if Verbose #########\n",
    "        ##############################################\n",
    "        if len(img) > 0:\n",
    "            print(boundariesDict)\n",
    "\n",
    "\n",
    "            #draw bucket boundaries\n",
    "            if 'bucket' in boundariesDict:\n",
    "                (xmin, xmax, ymin, ymax) = boundariesDict['bucket']\n",
    "                cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,255,255),3)\n",
    "\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getMatInsideBoundaries(imgLabel, img=[]):\n",
    "    '''\n",
    "    HS: \n",
    "    ---This method returs a list of boundaries: 1 matInside boundary (if present), which is combination of fineInside, rockInside and inappropritate.\n",
    "    '''\n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        #For Cable  FMDL3.1\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'fmInapp' :np.where(np.all(imgLabel == fmInapp, axis=-1)),\n",
    "\n",
    "        'dust' :np.where(np.all(imgLabel == dust, axis=-1)),\n",
    "        '''\n",
    "        \n",
    "        #For Hydraulics  FMDL3.1\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        \n",
    "        #with the new labels this is the new fmAppropriate mat\n",
    "        'fineInside2' :np.where(np.all(imgLabel == fineInside2, axis=-1))\n",
    "\n",
    "       \n",
    "    }\n",
    "    \n",
    "    if len(img) >0 :\n",
    "        plt.imshow(imgLabel)\n",
    "        plt.show()\n",
    "        print(labelsDic)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "    if len(img) >0 :\n",
    "        print(sortedLabelColsDic)\n",
    "        print(\"\\n\")\n",
    "        print(sortedLabelRowsDic)\n",
    "        print(\"\\n\")\n",
    "         \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ############## matInside Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    for labV in sortedLabelColsDic.values():\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    for labV in sortedLabelRowsDic.values():\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0 : \n",
    "        boundariesDict['matInside'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1]]\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "                \n",
    "\n",
    "    ##############################################\n",
    "    ######### Draw Boundaries if Verbose #########\n",
    "    ##############################################\n",
    "    if len(img) > 0:\n",
    "        print(boundariesDict)\n",
    "        \n",
    "        \n",
    "        #draw boundaries\n",
    "        if 'matInside' in boundariesDict:\n",
    "            (xmin, xmax, ymin, ymax) = boundariesDict['matInside']\n",
    "            cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,0,255),3)\n",
    "        \n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getBucketBoundariesTooth2Tooth(imgLabel, img=[]):\n",
    "\n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        'wmInapp':np.where(np.all(imgLabel == wmInapp, axis=-1)),\n",
    "        'fineInside2' : np.where(np.all(imgLabel == fineInside2, axis=-1)),\n",
    "        \n",
    "        #for Bucyrus\n",
    "        #'sheave'     :np.where(np.all(imgLabel == sheave, axis=-1)),\n",
    "        #'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "    }\n",
    "    \n",
    "    if len(img) >0 :\n",
    "        plt.imshow(imgLabel)\n",
    "        plt.show()\n",
    "        print(labelsDic)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "    if len(img) >0 :\n",
    "        print(sortedLabelColsDic)\n",
    "        print(\"\\n\")\n",
    "        print(sortedLabelRowsDic)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ############## Bucket Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    \n",
    "    lowColValsTeeth = []\n",
    "    highColValsTeeth = []\n",
    "    for itemKey in sortedLabelColsDic.keys():\n",
    "        if itemKey == 'teethCols':\n",
    "            labV = sortedLabelColsDic[itemKey]\n",
    "            for v in labV:\n",
    "                lowColValsTeeth.append(v[0])\n",
    "                highColValsTeeth.append(v[len(v)-1])\n",
    "        \n",
    "        labV = sortedLabelColsDic[itemKey]\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    \n",
    "    lowRowValsTeeth = []\n",
    "    highRowValsTeeth = []\n",
    "    for itemKey in sortedLabelRowsDic.keys():\n",
    "        if itemKey == 'teethRows':\n",
    "            labV = sortedLabelRowsDic[itemKey]\n",
    "            for v in labV:\n",
    "                lowRowValsTeeth.append(v[0])\n",
    "                highRowValsTeeth.append(v[len(v)-1])\n",
    "\n",
    "        labV = sortedLabelRowsDic[itemKey]\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "\n",
    "    \n",
    "\n",
    "    #get the bucket boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    yminsTeeth = np.sort(np.array(lowRowValsTeeth))\n",
    "    ymaxsTeeth = np.sort(np.array(highRowValsTeeth))\n",
    "    \n",
    "    print('lowColValsTeeth:')\n",
    "    print(lowColValsTeeth)\n",
    "    print('highColValsTeeth:')\n",
    "    print(highColValsTeeth)\n",
    "    \n",
    "    print('imageShape')\n",
    "    print(imgLabel.shape)\n",
    "    \n",
    "          \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0:\n",
    "          \n",
    "        if len(yminsTeeth) > 0 and len(ymaxsTeeth) > 0 and (ymaxsTeeth[len(ymaxsTeeth)-1] - yminsTeeth[0]) > (0.5 * imgLabel.shape[1]):\n",
    "            boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], yminsTeeth[0], ymaxsTeeth[len(ymaxsTeeth)-1]]\n",
    "        \n",
    "        else:\n",
    "            boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1]]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "                \n",
    "\n",
    "    ##############################################\n",
    "    ######### Draw Boundaries if Verbose #########\n",
    "    ##############################################\n",
    "    if len(img) > 0:\n",
    "        print(boundariesDict)\n",
    "        \n",
    "        \n",
    "        #draw bucket boundaries\n",
    "        if 'bucket' in boundariesDict:\n",
    "            (xmin, xmax, ymin, ymax) = boundariesDict['bucket']\n",
    "            cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,0,255),3)\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getBucketBoundaries(imgLabel, img=[]):\n",
    "\n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        \n",
    "        #for Bucyrus\n",
    "        #'sheave'     :np.where(np.all(imgLabel == sheave, axis=-1)),\n",
    "        #'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "    }\n",
    "    \n",
    "    if len(img) >0 :\n",
    "        plt.imshow(imgLabel)\n",
    "        plt.show()\n",
    "        print(labelsDic)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "    if len(img) >0 :\n",
    "        print(sortedLabelColsDic)\n",
    "        print(\"\\n\")\n",
    "        print(sortedLabelRowsDic)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ############## Bucket Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    for labV in sortedLabelColsDic.values():\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    for labV in sortedLabelRowsDic.values():\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "\n",
    "    \n",
    "\n",
    "    #get the bucket boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0 : \n",
    "        boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1]]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "                \n",
    "\n",
    "    ##############################################\n",
    "    ######### Draw Boundaries if Verbose #########\n",
    "    ##############################################\n",
    "    if len(img) > 0:\n",
    "        print(boundariesDict)\n",
    "        \n",
    "        \n",
    "        #draw bucket boundaries\n",
    "        (xmin, xmax, ymin, ymax) = boundariesDict['bucket']\n",
    "        cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,0,255),3)\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getAllBoundaries(imgLabel, img=[]):\n",
    "    '''\n",
    "    HS: \n",
    "    ---This method returs a list of boundaries: 1 bucket boundary, 1 fineInside boundary (if present) and several     rockInside boundaries (if present). \n",
    "    '''\n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        \n",
    "        #for Bucyrus\n",
    "        #'sheave'     :np.where(np.all(imgLabel == sheave, axis=-1)),\n",
    "        #'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "    }\n",
    "    \n",
    "    if len(img) >0 :\n",
    "        plt.imshow(imgLabel)\n",
    "        plt.show()\n",
    "        print(labelsDic)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "    if len(img) >0 :\n",
    "        print(sortedLabelColsDic)\n",
    "        print(\"\\n\")\n",
    "        print(sortedLabelRowsDic)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    ##############################################\n",
    "    ############# FineInside Boundary ############\n",
    "    ##############################################'\n",
    "    if 'fineInsideCols' in sortedLabelColsDic and 'fineInsideRows' in sortedLabelRowsDic:\n",
    "        boundariesDict['fineInside'] = [\n",
    "            int(sortedLabelColsDic[\"fineInsideCols\"][0][0]),\n",
    "            int(sortedLabelColsDic[\"fineInsideCols\"][0][len(sortedLabelRowsDic[\"fineInsideRows\"][0])-1]),\n",
    "            int(sortedLabelRowsDic[\"fineInsideRows\"][0][0]),\n",
    "            int(sortedLabelRowsDic[\"fineInsideRows\"][0][len(sortedLabelColsDic[\"fineInsideCols\"][0])-1]),\n",
    "        ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ############# teeth Boundary ############\n",
    "    ##############################################\n",
    "    if 'teethCols' in sortedLabelColsDic and 'teethRows' in sortedLabelRowsDic:\n",
    "        boundariesDict['teeth'] = [\n",
    "            int(sortedLabelColsDic[\"teethCols\"][0][0]),\n",
    "            int(sortedLabelColsDic[\"teethCols\"][0][len(sortedLabelRowsDic[\"teethRows\"][0])-1]),\n",
    "            int(sortedLabelRowsDic[\"teethRows\"][0][0]),\n",
    "            int(sortedLabelRowsDic[\"teethRows\"][0][len(sortedLabelColsDic[\"teethCols\"][0])-1]),\n",
    "        ]   \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ############## Bucket Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    for labV in sortedLabelColsDic.values():\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    for labV in sortedLabelRowsDic.values():\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "\n",
    "    \n",
    "\n",
    "    #get the bucket boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0 : \n",
    "        boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1]]\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    ##############################################\n",
    "    ############# RockInside Boundary ############\n",
    "    ##############################################\n",
    "    if 'rockInsideCols' in sortedLabelColsDic and 'rockInsideRows' in sortedLabelRowsDic:\n",
    "        # Getting the rock maks used to find rock boundaries        \n",
    "        rockMask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "        rockMask[labelsDic['rockInside']] = 1\n",
    "\n",
    "        # This converts any np.array to opencv image.\n",
    "        cv_rockMask = img_as_ubyte(rockMask)\n",
    "\n",
    "        contours, _ = cv2.findContours(cv_rockMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Getting bounding boxes from contours\n",
    "        rockBoundaries = []\n",
    "        for cnt in contours:\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            (xmin, xmax, ymin, ymax) = (y, (y+h), x, (x+w))\n",
    "\n",
    "            # only consider large boundaries.\n",
    "            if h>3 and w >3:\n",
    "                rockBoundaries.append([xmin, xmax, ymin, ymax])\n",
    "\n",
    "        boundariesDict['rockInside'] = rockBoundaries\n",
    "\n",
    "\n",
    "    \n",
    "                \n",
    "\n",
    "    ##############################################\n",
    "    ######### Draw Boundaries if Verbose #########\n",
    "    ##############################################\n",
    "    if len(img) > 0:\n",
    "        print(boundariesDict)\n",
    "        \n",
    "        \n",
    "        #draw bucket boundaries\n",
    "        (xmin, xmax, ymin, ymax) = boundariesDict['bucket']\n",
    "        cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,0,255),3)\n",
    "        \n",
    "        \n",
    "        #draw rockInside boundaries\n",
    "        for rockBb in boundariesDict['rockInside']:\n",
    "            cv2.rectangle(img,(rockBb[2], rockBb[0]),(rockBb[3], rockBb[1]),(255,0,0),3)\n",
    "\n",
    "        \n",
    "        #draw fineInside boundaries\n",
    "        (xmin, xmax, ymin, ymax) = boundariesDict['fineInside']\n",
    "        cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,255,0),3)\n",
    "        \n",
    "        \n",
    "        #draw teeth boundaries\n",
    "        (xmin, xmax, ymin, ymax) = boundariesDict['teeth']\n",
    "        cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(255,255,0),3)\n",
    "        \n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def writeRowsToCsv(rows, csvFullPath):\n",
    "    # open the file\n",
    "    csv_file = open(csvFullPath, \"w\") \n",
    "    \n",
    "    # define column names\n",
    "    columnTitles = \"filename,pathname,xmins,xmax,ymins,ymax,class\\n\"\n",
    "    csv_file.write(columnTitles)\n",
    "\n",
    "    # write rows\n",
    "    for row in rows:\n",
    "        csv_file.write(row)\n",
    "\n",
    "    csv_file.close()\n",
    "    \n",
    "    print(\"wrote \" + str(len(rows)) + \" rows to csv file\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def writeRowDicToCsv(rowsDic, csvFullPath):\n",
    "    # open the file\n",
    "    #use w for mode to override existing\n",
    "    csv_file = open(csvFullPath, \"a\") \n",
    "    \n",
    "    # define column names\n",
    "    columnTitles = \"filename,pathname,xmins,xmax,ymins,ymax,class\\n\"\n",
    "    csv_file.write(columnTitles)\n",
    "\n",
    "    # write rows\n",
    "    for imId in rowsDic:\n",
    "        if imId != 'fileName':\n",
    "            row = rowsDic[imId] + '\\n'\n",
    "            csv_file.write(row)\n",
    "\n",
    "    csv_file.close()\n",
    "    \n",
    "    print(\"wrote \" + str(len(rowsDic)) + \" rows to csv file\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def readCsvRows(fullCsvPath):\n",
    "    # open the file\n",
    "    csv_file = open(fullCsvPath, \"r\") \n",
    "    data = csv_file.read()\n",
    "    csv_file.close()\n",
    "    \n",
    "    rows = data.split('\\n')\n",
    "    \n",
    "    print(\"read \" + str(len(rows)) + \" rows\")\n",
    "    \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getRowsDictFromCsv(fullCsvPath):\n",
    "    csv_file = open(fullCsvPath, \"r\") \n",
    "    data = csv_file.read()\n",
    "    csv_file.close()\n",
    "\n",
    "    rows = data.split('\\n')\n",
    "\n",
    "    rowsDict = {}\n",
    "\n",
    "    for row in rows[1 : len(rows)-1]:\n",
    "        vals = row.split(',')\n",
    "\n",
    "        if vals[0] not in rowsDict:\n",
    "            rowsDict[vals[0]] = []\n",
    "\n",
    "        rowsDict[vals[0]].append(vals[2:7])\n",
    "        \n",
    "    print(\"read \" + str(len(rowsDict)) + \" examples\")\n",
    "    return rowsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getRowsDictFromCsvSaveJustBucketBoundingBox(fullCsvPath):\n",
    "    csv_file = open(fullCsvPath, \"r\") \n",
    "    data = csv_file.read()\n",
    "    csv_file.close()\n",
    "\n",
    "    rows = data.split('\\n')\n",
    "\n",
    "    rowsDict = {}\n",
    "\n",
    "    for row in rows[1 : len(rows)-1]:\n",
    "        vals = row.split(',')\n",
    "\n",
    "        if vals[-1] == 'bucket':\n",
    "            rowsDict[vals[0]] = vals[2:7]\n",
    "        \n",
    "    print(\"read \" + str(len(rowsDict)) + \" examples\")\n",
    "    return rowsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getCertainClassRowsDictFromCsv(fullCsvPath, classesToLookFor):\n",
    "    csv_file = open(fullCsvPath, \"r\") \n",
    "    data = csv_file.read()\n",
    "    csv_file.close()\n",
    "\n",
    "    rows = data.split('\\n')\n",
    "\n",
    "    rowsDict = {}\n",
    "\n",
    "    for row in rows[1 : len(rows)-1]:\n",
    "        vals = row.split(',')\n",
    "        \n",
    "        if vals[6] in classesToLookFor:\n",
    "\n",
    "            if vals[0] not in rowsDict:\n",
    "                rowsDict[vals[0]] = row\n",
    "            else:\n",
    "                print(\"error. duplicateRow. This shouldn't happen\")\n",
    "        \n",
    "    print(\"read \" + str(len(rowsDict)) + \" examples\")\n",
    "    return rowsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def visualizeRowDict(rowDict, writeToDisk=False, outputDirPath=\"\", saveLabelToo=False):\n",
    "    for imgId in rowsDict:\n",
    "\n",
    "        img = imread(imagesPath + imgId)\n",
    "        if saveLabelToo==True:\n",
    "            label = imread(labelsPath + imgId)\n",
    "\n",
    "        for box in rowsDict[imgId]:\n",
    "            \n",
    "            if(box[0] != \"\"):\n",
    "\n",
    "                if box[4] == 'bucket':\n",
    "                    (xmin, xmax, ymin, ymax) = box[0:4]\n",
    "                    int(round(float(xmin)))\n",
    "                    cv2.rectangle(img,(int(round(float(xmin))), int(round(float(ymin)))),(int(round(float(xmax))), int(round(float(ymax)))),(0,0,255),3)\n",
    "                    \n",
    "                    \n",
    "                if box[4] == 'matInside':\n",
    "                    (xmin, xmax, ymin, ymax) = box[0:4]\n",
    "                    cv2.rectangle(img,(int(round(float(xmin))), int(round(float(ymin)))),(int(round(float(xmax))), int(round(float(ymax)))),(0,255,0),3)\n",
    "\n",
    "\n",
    "                if box[4] == 'fineInside':\n",
    "                    (xmin, xmax, ymin, ymax) = box[0:4]\n",
    "                    cv2.rectangle(img,(int(round(float(xmin))), int(round(float(ymin)))),(int(round(float(xmax))), int(round(float(ymax)))),(0,255,0),3)\n",
    "\n",
    "\n",
    "                if box[4] == 'rockInside':\n",
    "                    (xmin, xmax, ymin, ymax) = box[0:4]\n",
    "                    cv2.rectangle(img,(int(round(float(xmin))), int(round(float(ymin)))),(int(round(float(xmax))), int(round(float(ymax)))),(255,0,0),3)\n",
    "\n",
    "\n",
    "        if writeToDisk==True and outputDirPath != \"\":\n",
    "            cv2.imwrite(outputDirPath + imgId, img)\n",
    "            \n",
    "            if saveLabelToo==True:\n",
    "                cv2.imwrite(outputDirPath + \"_label_\" + imgId, label)\n",
    "        else:\n",
    "            print(imgId)\n",
    "            if saveLabelToo==True:\n",
    "                plt.imshow(label)\n",
    "                plt.show()\n",
    "\n",
    "            plt.imshow(img)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def visualizeRow(row):\n",
    "    vals = row.split(',')\n",
    "    \n",
    "    img = imread(imagesPath + vals[0])\n",
    "    label = imread(labelsPath + vals[0])\n",
    "    \n",
    "    xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "    if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "        (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "        \n",
    "        \n",
    "        if vals[6] == 'matInside':\n",
    "            cv2.rectangle(img,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(0,255,0),3)\n",
    "            cv2.rectangle(label,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(0,255,0),3)\n",
    "            \n",
    "        if vals[6] == 'matInside':\n",
    "            cv2.rectangle(img,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(0,0,255),3)\n",
    "            cv2.rectangle(label,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(0,0,255),3)\n",
    "            \n",
    "        else:\n",
    "            #read in notebook\n",
    "            cv2.rectangle(img,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(255,0,0),3)\n",
    "            cv2.rectangle(label,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(255,0,0),3)\n",
    "            \n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(label)\n",
    "    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def writeRowToDisk(row, writeLabelsToo=False):\n",
    "    vals = row.split(',')\n",
    "    \n",
    "    img = imread(imagesPath + vals[0])\n",
    "    \n",
    "    xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "    cv2.rectangle(img,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(255,0,0),3)\n",
    "    \n",
    "    cv2.imwrite(imgBoundariesPath + vals[0], img)\n",
    "    \n",
    "    if writeLabelsToo:\n",
    "        label = imread(labelsPath + vals[0])\n",
    "        cv2.rectangle(label,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(255,0,0),3)\n",
    "        cv2.imwrite(labelBoundariesPath + vals[0], label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def visualizeImg(imgId):\n",
    "    img = imread(imagesPath + imgId)\n",
    "    label = imread(labelsPath + imgId)\n",
    "    \n",
    "    foundBucketBoundary, xmin, xmax, ymin, ymax = getBucketBoundaries(label)\n",
    "    \n",
    "    if(foundBucketBoundary):\n",
    "        cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(255,0,0),3)\n",
    "        cv2.rectangle(label,(ymin, xmin),(ymax, xmax),(255,0,0),3)\n",
    "\n",
    "        plt.imshow(img)\n",
    "        plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(label)\n",
    "        plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(\"could not find bucket boundary\\n\")\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(label)\n",
    "        plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getBbxMask(row, writeToDisk=False, mask_direct_path=None, verbose=False):\n",
    "    vals = row.split(',')\n",
    "    \n",
    "    img = imread(imagesPath + vals[0])\n",
    "    mask = np.zeros((img.shape[0], img.shape[1]), bool)\n",
    "    \n",
    "    xmin, xmax, ymin, ymax = vals[2:6]\n",
    "    if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "        (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "        mask[ymin:ymax, xmin:xmax] = 1\n",
    "    \n",
    "    if writeToDisk == True and mask_direct_path != None:\n",
    "        mask.dtype='uint8'\n",
    "        cv2.imwrite(mask_direct_path + vals[0], mask)\n",
    "        \n",
    "    if verbose:\n",
    "        if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "            cv2.rectangle(img,(xmin, ymin),(xmax, ymax),(255,0,0),3)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def calcPerformance(pred_rows, gt_rows, predictedBbMasks_path, gtBbMaks_path, verbose=False, predictedRowDict=None):\n",
    "    total_tn = 0\n",
    "    total_tp = 0\n",
    "    total_fn = 0\n",
    "    total_fp = 0\n",
    "    \n",
    "    rowCount = 0\n",
    "\n",
    "    if predictedRowDict == None:\n",
    "        print(\"using pred_rows\")\n",
    "        for pred_row, gt_row in zip(pred_rows, gt_rows):\n",
    "            pred_vals = pred_row.split(',')\n",
    "            gt_vals = gt_row.split(',')\n",
    "\n",
    "            if gt_vals[0] == pred_vals[0]:\n",
    "                pred_mask = imread(predictedBbMasks_path + pred_vals[0])\n",
    "                gt_mask = imread(gtBbMaks_path + gt_vals[0])\n",
    "\n",
    "                pos_preds = np.where(pred_mask == 1)\n",
    "                neg_preds = np.where(pred_mask == 0)\n",
    "\n",
    "                pos_overlap = pred_mask * gt_mask\n",
    "                neg_overlap = np.logical_not(pred_mask) * np.logical_not(gt_mask)\n",
    "\n",
    "                tp = np.count_nonzero(pos_overlap)\n",
    "                tn = np.count_nonzero(neg_overlap)\n",
    "                fp = len(pos_preds[0]) - tp\n",
    "                fn = len(neg_preds[0]) - tn\n",
    "\n",
    "                total_fp += fp\n",
    "                total_fn += fn\n",
    "                total_tp += tp\n",
    "                total_tn += tn\n",
    "                \n",
    "                rowCount += 1\n",
    "\n",
    "            else:\n",
    "                print(\"ERROR image id's don't match between gt csv file and predictions csv file\")\n",
    "\n",
    "    else:\n",
    "        print(\"using predictedRowDict\")\n",
    "        for gt_row in gt_rows:\n",
    "            gt_vals = gt_row.split(',')\n",
    "\n",
    "            if gt_vals[0] in predictedRowDict:\n",
    "                pred_vals = predictedRowDict[gt_vals[0]]\n",
    "                pred_mask = imread(predictedBbMasks_path + gt_vals[0])\n",
    "                gt_mask = imread(gtBbMaks_path + gt_vals[0])\n",
    "\n",
    "                pos_preds = np.where(pred_mask == 1)\n",
    "                neg_preds = np.where(pred_mask == 0)\n",
    "\n",
    "                pos_overlap = pred_mask * gt_mask\n",
    "                neg_overlap = np.logical_not(pred_mask) * np.logical_not(gt_mask)\n",
    "\n",
    "                tp = np.count_nonzero(pos_overlap)\n",
    "                tn = np.count_nonzero(neg_overlap)\n",
    "                fp = len(pos_preds[0]) - tp\n",
    "                fn = len(neg_preds[0]) - tn\n",
    "\n",
    "                total_fp += fp\n",
    "                total_fn += fn\n",
    "                total_tp += tp\n",
    "                total_tn += tn\n",
    "                \n",
    "                rowCount += 1\n",
    "                \n",
    "        \n",
    "    print(\"Processed \" + str(rowCount) + \" rows:\" )\n",
    "                \n",
    "\n",
    "                \n",
    "    if verbose:\n",
    "        plt.imshow(pred_mask)\n",
    "        plt.title(\"pred\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(gt_mask)\n",
    "        plt.title(\"gt\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(pos_overlap)\n",
    "        plt.title(\"pos_overlap\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(neg_overlap)\n",
    "        plt.title(\"neg_overlap\")\n",
    "        plt.show()\n",
    "\n",
    "        print(\"tp: \" + str(tp) + \" ,    fp: \" + str(fp) + \" ,    tn: \" + str(tn) + \" ,    fn: \" + str(fn) + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    sensitivity = float(total_tp) / (total_tp + total_fn)\n",
    "    specificity = float(total_tn) / (total_tn + total_fp)\n",
    "    precision = float(total_tp) / (total_tp + total_fp)\n",
    "    f_score = 2 * precision * sensitivity / (precision + sensitivity)\n",
    "\n",
    "    print(\"-Sensitivity: \" + str(sensitivity) +\n",
    "          \" ,    -Specificity: \" + str(specificity) +\n",
    "          \" ,    -Precision: \" + str(precision) +\n",
    "          \" ,    -F_score: \" + str(f_score)\n",
    "         )\n",
    "    \n",
    "    return sensitivity, specificity, precision, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def calcPerformance_insideBucket_multiClass(unet_pathToSavedResults, unet_pathTo1ChanLabels, verbose = False):\n",
    "\n",
    "    total_tn = 0\n",
    "    total_tp = 0\n",
    "    total_fn = 0\n",
    "    total_fp = 0\n",
    "\n",
    "    rowCount = 0\n",
    "\n",
    "\n",
    "    for imgId in os.listdir(unet_pathTo1ChanLabels):\n",
    "\n",
    "        label = imread(unet_pathTo1ChanLabels + imgId)\n",
    "        pred = imread(unet_pathToSavedResults + imgId)\n",
    "\n",
    "        labelMask = np.zeros((label.shape[0], label.shape[1]), bool)\n",
    "        predMask = np.zeros((pred.shape[0], pred.shape[1]), bool)\n",
    "\n",
    "\n",
    "\n",
    "        labelPixels = np.where(label == 2)\n",
    "        predPixels = np.where(pred == 2)\n",
    "\n",
    "        labelMask[labelPixels] = 1\n",
    "        predMask[predPixels] = 1\n",
    "\n",
    "\n",
    "\n",
    "        pos_preds = np.where(predMask == 1)\n",
    "        neg_preds = np.where(predMask == 0)\n",
    "\n",
    "        pos_overlap = predMask * labelMask\n",
    "        neg_overlap = np.logical_not(predMask) * np.logical_not(labelMask)\n",
    "\n",
    "\n",
    "        if verbose==True:\n",
    "            imshow(label)\n",
    "            plt.title('label')\n",
    "            plt.show()\n",
    "\n",
    "            imshow(labelMask)\n",
    "            plt.title('labelMask')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            imshow(pred)\n",
    "            plt.title('pred')\n",
    "            plt.show()\n",
    "\n",
    "            imshow(predMask)\n",
    "            plt.title('pred')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        tp = np.count_nonzero(pos_overlap)\n",
    "        tn = np.count_nonzero(neg_overlap)\n",
    "        fp = len(pos_preds[0]) - tp\n",
    "        fn = len(neg_preds[0]) - tn\n",
    "\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "        total_tp += tp\n",
    "        total_tn += tn\n",
    "\n",
    "        rowCount += 1\n",
    "\n",
    "\n",
    "\n",
    "    sensitivity = float(total_tp) / (total_tp + total_fn)\n",
    "    specificity = float(total_tn) / (total_tn + total_fp)\n",
    "    precision = float(total_tp) / (total_tp + total_fp)\n",
    "    f_score = 2 * precision * sensitivity / (precision + sensitivity)\n",
    "\n",
    "    print(\"-Sensitivity: \" + str(sensitivity) +\n",
    "          \" ,    -Specificity: \" + str(specificity) +\n",
    "          \" ,    -Precision: \" + str(precision) +\n",
    "          \" ,    -F_score: \" + str(f_score)\n",
    "         )\n",
    "\n",
    "\n",
    "    return sensitivity, specificity, precision, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cropImgFromRow(row, showResult = True , saveResult=False, cropImgPath = \"\", cropLabelPath = \"\"):\n",
    "    vals = row.split(',')\n",
    "\n",
    "    img = imread(imagesPath + vals[0])\n",
    "    label = imread(labelsPath + vals[0])\n",
    "\n",
    "    xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "    if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "        (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "\n",
    "        img = img[ymin:ymax, xmin:xmax,]\n",
    "        label = label[ymin:ymax, xmin:xmax]\n",
    "        \n",
    "        \n",
    "        \n",
    "    if saveResult==True:\n",
    "        cv2.imwrite(cropImgPath + vals[0], img)\n",
    "        cv2.imwrite(cropLabelPath + vals[0], label)\n",
    "\n",
    "        \n",
    "    if showResult==True:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(label)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cropImgFromRowV2(vals, imgName, margin, showResult = True , saveResult=False, cropImgPath = \"\", cropLabelPath = \"\"):\n",
    "\n",
    "    bestVal = vals[0]\n",
    "    for val in vals:\n",
    "        if val[4] == 'matInside':\n",
    "            bestVal = val\n",
    "    \n",
    "    img = imread(imagesPath + imgName)\n",
    "    label = imread(labelsPath + imgName)\n",
    "\n",
    "    xmin, xmax, ymin, ymax = bestVal[0:4]\n",
    "\n",
    "    if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "        (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "\n",
    "        \n",
    "        \n",
    "        if (ymin-margin) > 0:\n",
    "            yminAdj = (ymin-margin)\n",
    "        else:\n",
    "            yminAdj = ymin\n",
    "\n",
    "\n",
    "        if (xmin-margin) > 0:\n",
    "            xminAdj = (xmin-margin)\n",
    "        else:\n",
    "            xminAdj = xmin\n",
    "\n",
    "\n",
    "\n",
    "        if (ymax + margin) < img.shape[0]:\n",
    "            ymaxAdj = (ymax + margin)\n",
    "        else:\n",
    "            ymaxAdj = ymax\n",
    "\n",
    "\n",
    "\n",
    "        if (xmax + margin) < img.shape[1]:\n",
    "            xmaxAdj = (xmax + margin)\n",
    "        else:\n",
    "            xmaxAdj = xmax\n",
    "\n",
    "\n",
    "        img = img[yminAdj:ymaxAdj, xminAdj:xmaxAdj,]\n",
    "        label = label[yminAdj:ymaxAdj, xminAdj:xmaxAdj]\n",
    "\n",
    "        \n",
    "\n",
    "    if saveResult==True:\n",
    "        cv2.imwrite(cropImgPath + imgName, img)\n",
    "        cv2.imwrite(cropLabelPath + imgName, label)\n",
    "\n",
    "\n",
    "    if showResult==True:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(label)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def randomCropImgFromRow(row, showResult = True , saveResult=False, cropImgPath = \"\", cropLabelPath = \"\", offsetsToApply = []):\n",
    "    vals = row.split(',')\n",
    "\n",
    "    img = imread(imagesPath + vals[0])\n",
    "    label = imread(labelsPath + vals[0])\n",
    "\n",
    "    xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "    if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "        (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "\n",
    "        imgWidth = img.shape[1]\n",
    "        imgHeight = img.shape[0]\n",
    "        \n",
    "        if showResult==True:\n",
    "            plt.imshow(img)\n",
    "            plt.title('imgOrig')\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            \n",
    "        imgAct = img[ymin:ymax, xmin:xmax,]\n",
    "        labelAct = label[ymin:ymax, xmin:xmax]\n",
    "\n",
    "        if saveResult==True:\n",
    "            cv2.imwrite(cropImgPath + vals[0].replace('.png', '_RCAct.png'), imgAct)\n",
    "            cv2.imwrite(cropLabelPath + vals[0].replace('.png', '_RCAct.png'), labelAct)\n",
    "\n",
    "        if showResult==True:\n",
    "            plt.imshow(imgAct)\n",
    "            plt.title('imgAct')\n",
    "            plt.show()\n",
    "            \n",
    "\n",
    "            \n",
    "        for offset in offsetsToApply:\n",
    "            \n",
    "            img1 =     img[ymin + offset:ymax + offset, xmin:xmax]\n",
    "            label1 = label[ymin + offset:ymax + offset, xmin:xmax]\n",
    "            \n",
    "            if saveResult==True:\n",
    "                cv2.imwrite(cropImgPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_1.png', img1)\n",
    "                cv2.imwrite(cropLabelPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_1.png', label1)\n",
    "            \n",
    "            if showResult==True:\n",
    "                plt.imshow(img1)\n",
    "                plt.title('img1')\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            img2 =     img[ymin:ymax, xmin + offset:xmax + offset]\n",
    "            label2 = label[ymin:ymax, xmin + offset:xmax + offset]\n",
    "\n",
    "            if saveResult==True:\n",
    "                cv2.imwrite(cropImgPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_2.png', img2)\n",
    "                cv2.imwrite(cropLabelPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_2.png', label2)\n",
    "            \n",
    "            if showResult==True:\n",
    "                plt.imshow(img2)\n",
    "                plt.title('img2')\n",
    "                plt.show()\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "            if (ymin - offset) >= 0:\n",
    "                img3 =     img[ymin - offset:ymax - offset, xmin:xmax]\n",
    "                label3 = label[ymin - offset:ymax - offset, xmin:xmax]\n",
    "\n",
    "                if saveResult==True:\n",
    "                    cv2.imwrite(cropImgPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_3.png', img3)\n",
    "                    cv2.imwrite(cropLabelPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_3.png', label3)\n",
    "\n",
    "                if showResult==True:\n",
    "                    plt.imshow(img3)\n",
    "                    plt.title('img3')\n",
    "                    plt.show()\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "            if (xmin - offset) >= 0:\n",
    "                img4 =     img[ymin:ymax, xmin - offset:xmax - offset]\n",
    "                label4 = label[ymin:ymax, xmin - offset:xmax - offset]\n",
    "\n",
    "                if saveResult==True:\n",
    "                    cv2.imwrite(cropImgPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_4.png', img4)\n",
    "                    cv2.imwrite(cropLabelPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_4.png', label4)\n",
    "\n",
    "                if showResult==True:\n",
    "                    plt.imshow(img4)\n",
    "                    plt.title('img4')\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## SSD Data Generation: Cable and Hydraulics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### FMDL 3.1 Automated data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Automatically generating training data from directory of images\n",
    "imagesPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/hydraulics/images_fromJira/'\n",
    "labelsPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/hydraulics/labels_fromJira/'\n",
    "\n",
    "dir2PutRejectedImages='/home/hooman/Desktop/deleteThis/negExamples/'\n",
    "dir2PutAcceptedImages='/home/hooman/Desktop/deleteThis/goodExamples/'\n",
    "dir2PutBadMatInsideImages='/home/hooman/Desktop/deleteThis/badExamples/'\n",
    "verbose=False\n",
    "\n",
    "\n",
    "rows = []\n",
    "for fileName in os.listdir(imagesPath):\n",
    "    \n",
    "    filePath = labelsPath + fileName\n",
    "    \n",
    "    imgLabel = imread(filePath)\n",
    "    \n",
    "    #I added this for try3  ssd-multiclass-tries 1 and 2 didnt have this.\n",
    "    imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "    img = imread(imagesPath + fileName)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"processing file:\\n\" + filePath + '\\n')\n",
    "    \n",
    "    boundariesDict = seperateTrainingImages_hydraulics(imgLabel, img, fileName, dir2PutRejectedImages, dir2PutAcceptedImages, dir2PutBadMatInsideImages, verbose)\n",
    "\n",
    "    print('\\nboundariesDict:')\n",
    "    print(boundariesDict)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if boundariesDict and ('bucket' in boundariesDict):\n",
    "        # write up the rows\n",
    "        (xmin, xmax, ymin, ymax) = boundariesDict['bucket']\n",
    "        row = fileName + \",\" + filePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"bucket\" + \"\\n\"\n",
    "    \n",
    "        rows.append(row)\n",
    "\n",
    "        \n",
    "        if('matInside' in boundariesDict):\n",
    "            if len(boundariesDict['matInside']) == 4:\n",
    "                (xmin, xmax, ymin, ymax) = boundariesDict['matInside']\n",
    "                row = fileName + \",\" + filePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"matInside\" + \"\\n\"\n",
    "            else:\n",
    "                print(\"ERROR: Found more than one matInside Boundaries. This should NOT happen\\n\")\n",
    "\n",
    "            rows.append(row)  \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "print(\"processed \"+ str(len(rows)) + \" rows\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "writeRowsToCsv(rows, \"/home/hooman/Desktop/deleteThis/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for row in rows[0:38]:\n",
    "    visualizeRow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Visualizing existing csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rowsDict = getRowsDictFromCsv(\"/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may10-2019/trainingSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "visualizeRowDict(rowsDict, True, '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may10-2019/boundariesVisualized/', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## U-Net Data Generation: Cable and Hydraulics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Cropping images to contain only ROI (V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rowDict = getRowsDictFromCsv('/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameNetworkAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/unetBoxes_finalTrainingSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for imgName in os.listdir(imagesPath):\n",
    "    cropImgFromRowV2(rowDict[imgName],imgName, 100, False , True,'/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameNetworkAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/finalTrainingSet_images_croped/','/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameNetworkAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/finalTrainingSet_masks_croped/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Random Cropping images for U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gt_rows = readCsvRows('/home/hooman/backhoeOpticalScene/roiDelineators/try1-csvFrom-ssdTry2/fromSSdTry2_fineAndRockAndInapInMatInside_backhoe_shuffled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# random crop images and masks\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "offsetsToApply = [50,75, 100, 125, 150, 175]\n",
    "dirToSaveImages = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/randomCroppedImages/'\n",
    "dirToSaveMasks = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/randomCroppedMasks/'\n",
    "\n",
    "\n",
    "dirToReadImages = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/allImages/'\n",
    "dirToReadMasks = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/fullMaks/'\n",
    "\n",
    "\n",
    "for row in gt_rows[1:len(gt_rows)-1]:\n",
    "    \n",
    "    vals = row.split(',')\n",
    "\n",
    "    if os.path.exists(dirToReadImages + vals[0]) and os.path.exists(dirToReadMasks + vals[0]):\n",
    "        \n",
    "        #This causes a \"Too many open files error\"\n",
    "        #img = imread(dirToReadImages + vals[0])\n",
    "        #label = imread(dirToReadMasks + vals[0])\n",
    "        \n",
    "        imgPil = Image.open(dirToReadImages + vals[0])\n",
    "        img = np.array(imgPil) \n",
    "        imgPil.close()\n",
    "\n",
    "        labelPil = Image.open(dirToReadMasks + vals[0])\n",
    "        label = np.array(labelPil)\n",
    "        labelPil.close()\n",
    "        \n",
    "        \n",
    "\n",
    "        xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "        if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "            (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "\n",
    "            imgWidth = img.shape[1]\n",
    "            imgHeight = img.shape[0]\n",
    "\n",
    "\n",
    "            imgAct = img[ymin:ymax, xmin:xmax,]\n",
    "            labelAct = label[ymin:ymax, xmin:xmax]\n",
    "\n",
    "            if imgAct.shape[0] > 0 and imgAct.shape[1] > 0 and labelAct.shape[0] > 0 and labelAct.shape[1] > 0: \n",
    "                cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '_RCAct.png'), imgAct)\n",
    "                cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '_RCAct.png'), labelAct)\n",
    "\n",
    "\n",
    "\n",
    "            for offset in offsetsToApply:\n",
    "\n",
    "                img1 =     img[ymin + offset:ymax + offset, xmin:xmax]\n",
    "                label1 = label[ymin + offset:ymax + offset, xmin:xmax]\n",
    "                \n",
    "                if img1.shape[0] > 0 and img1.shape[1] > 0 and label1.shape[0] > 0 and label1.shape[1] > 0: \n",
    "                    cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_1.png', img1)\n",
    "                    cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_1.png', label1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                img2 =     img[ymin:ymax, xmin + offset:xmax + offset]\n",
    "                label2 = label[ymin:ymax, xmin + offset:xmax + offset]\n",
    "         \n",
    "                if img2.shape[0] > 0 and img2.shape[1] > 0 and label2.shape[0] > 0 and label2.shape[1] > 0: \n",
    "                    cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_2.png', img2)\n",
    "                    cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_2.png', label2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                if (ymin - offset) > 0:\n",
    "                    img3 =     img[ymin - offset:ymax - offset, xmin:xmax]\n",
    "                    label3 = label[ymin - offset:ymax - offset, xmin:xmax]\n",
    "                    \n",
    "                    if img3.shape[0] > 0 and img3.shape[1] > 0 and label3.shape[0] > 0 and label3.shape[1] > 0: \n",
    "                        cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_3.png', img3)\n",
    "                        cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_3.png', label3)\n",
    "\n",
    "\n",
    "\n",
    "                if (xmin - offset) > 0:\n",
    "                    img4 =     img[ymin:ymax, xmin - offset:xmax - offset]\n",
    "                    label4 = label[ymin:ymax, xmin - offset:xmax - offset]\n",
    "                    \n",
    "                    if img4.shape[0] > 0 and img4.shape[1] > 0 and label4.shape[0] > 0 and label4.shape[1] > 0: \n",
    "\n",
    "                        cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_4.png', img4)\n",
    "                        cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_4.png', label4)\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"one of the provided directories doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#random cropping images and labels\n",
    "\n",
    "offsetsToApply = [50,75, 100, 125, 150, 175]\n",
    "dirToSaveImages = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCroppedImages/'\n",
    "dirToSaveLabels = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCroppedLabels/'\n",
    "\n",
    "for row in gt_rows[1:len(gt_rows)-1]:\n",
    "    randomCropImgFromRow(row, False , True, dirToSaveImages, dirToSaveLabels, offsetsToApply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Creating semantic segmentation Masks for U-Net from Cropped images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# creating masks for u-net CORRECT (using BGR for labels) more efficent to use with augmentations quickly\n",
    "\n",
    "\n",
    "croppedImagesPath = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCropped_images/'\n",
    "croppedLabelsPath = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCropped_labels/'\n",
    "croppedMasksPath  = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCropped_masks/'\n",
    "\n",
    "\n",
    "n = 0\n",
    "for fileName in os.listdir(croppedLabelsPath):\n",
    "    \n",
    "    try:\n",
    "        img = imread(croppedImagesPath + fileName)\n",
    "        imgLabel = imread(croppedLabelsPath + fileName)\n",
    "        #imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGB2BGR)  This is wrong too\n",
    "        imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "\n",
    "        labelsDic = {\n",
    "            'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "            'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "            'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        #    'emptyInside' :np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        }\n",
    "\n",
    "\n",
    "        #print(labelsDic)\n",
    "\n",
    "        mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "        mask[labelsDic['fineInside']] = 1\n",
    "        mask[labelsDic['rockInside']] = 1\n",
    "        mask[labelsDic['inapInside']] = 1\n",
    "        #mask[labelsDic['emptyInside']] = 1\n",
    "\n",
    "\n",
    "        mask.dtype='uint8'\n",
    "        cv2.imwrite(croppedMasksPath + fileName, mask)\n",
    "\n",
    "        n += 1\n",
    "    except:\n",
    "        print(\"couldnt open file: \" + fileName)\n",
    "\n",
    "print(\"created  \" + str(n) + \"  binary masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# creating masks for u-net CORRECT (using BGR for labels) with overlay\n",
    "\n",
    "'''\n",
    "croppedImagesPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/images/'\n",
    "croppedLabelsPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/labels/'\n",
    "croppedMasksPath  = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/masks/'\n",
    "croppedOverlayedPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/overlayed/'\n",
    "'''\n",
    "\n",
    "'''\n",
    "croppedImagesPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/finalTrainingSet_images/'\n",
    "croppedLabelsPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/labels_fromJira/'\n",
    "\n",
    "croppedMasksPath  = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/images_frmJira__fullSizeImages_masks/'\n",
    "croppedOverlayedPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/images_frmJira__fullSizeImages_overlays/'\n",
    "'''\n",
    "\n",
    "croppedImagesPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/images_manuallyLabeled/'\n",
    "\n",
    "croppedLabelsPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/labeles_manuallyLabeled/'\n",
    "\n",
    "croppedMasksPath  = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/manuallyLabeled_masks/'\n",
    "\n",
    "croppedOverlayedPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/manuallyLabeled_overlays/'\n",
    "\n",
    "\n",
    "\n",
    "n = 0\n",
    "for fileName in os.listdir(croppedImagesPath):\n",
    "    img = imread(croppedImagesPath + fileName)\n",
    "    imgLabel = imread(croppedLabelsPath + fileName)\n",
    "    #imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGB2BGR)  This is wrong too\n",
    "    imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "\n",
    "    labelsDic = {\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        \n",
    "        #for V3 with the new labels this is the new fmAppropriate mat\n",
    "        'fineInside2' :np.where(np.all(imgLabel == fineInside2, axis=-1)),\n",
    "        \n",
    "        #V2 for Hydraulics U-Net I had the inapInside labels but not for BucyrucAndPnH  for V3 no inapp.\n",
    "        #'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        \n",
    "    #    'emptyInside' :np.where(np.all(imgLabel == emptyInside, axis=-1)), bad idea\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "    #print(labelsDic)\n",
    "    #print(img.shape)\n",
    "\n",
    "    mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "    mask[labelsDic['fineInside']] = 1\n",
    "    mask[labelsDic['fineInside2']] = 1\n",
    "    mask[labelsDic['rockInside']] = 1\n",
    "    #mask[labelsDic['inapInside']] = 1\n",
    "    #mask[labelsDic['emptyInside']] = 1\n",
    "\n",
    "\n",
    "\n",
    "    mask.dtype='uint8'\n",
    "    maskOverlay = cv2.cvtColor(mask*255, cv2.COLOR_GRAY2BGR)\n",
    "    maskOverlay[:,:,0] = 0\n",
    "    maskOverlay[:,:,2] = 0\n",
    "\n",
    "\n",
    "    opacity = 0.2\n",
    "    cv2.addWeighted(maskOverlay, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "\n",
    "\n",
    "    mask.dtype='uint8'\n",
    "    cv2.imwrite(croppedMasksPath + fileName, mask)\n",
    "    cv2.imwrite(croppedOverlayedPath + fileName, img)\n",
    "\n",
    "    n += 1\n",
    "\n",
    "print(\"created  \" + str(n) + \"  binary masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# debugging UNET data generation\n",
    "\n",
    "# creating masks for u-net CORRECT (using BGR for labels) with overlay\n",
    "\n",
    "'''\n",
    "croppedImagesPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/images/'\n",
    "croppedLabelsPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/labels/'\n",
    "croppedMasksPath  = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/masks/'\n",
    "croppedOverlayedPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/overlayed/'\n",
    "'''\n",
    "\n",
    "croppedImagesPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/images_fromJira/'\n",
    "croppedLabelsPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/labels_fromJira/'\n",
    "\n",
    "croppedMasksPath  = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/images_frmJira__fullSizeImages_masks/'\n",
    "croppedOverlayedPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/images_frmJira__fullSizeImages_overlays/'\n",
    "\n",
    "\n",
    "\n",
    "fileName = '1_20161115-073100_0001n0_11017.png'\n",
    "\n",
    "\n",
    "\n",
    "img = imread(croppedImagesPath + fileName)\n",
    "imgLabel = imread(croppedLabelsPath + fileName)\n",
    "#imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGB2BGR)  This is wrong too\n",
    "imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "\n",
    "labelsDic = {\n",
    "    'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "    'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "\n",
    "    #for V3 with the new labels this is the new fmAppropriate mat\n",
    "    'fineInside2' :np.where(np.all(imgLabel == fineInside2, axis=-1)),\n",
    "\n",
    "    #V2 for Hydraulics U-Net I had the inapInside labels but not for BucyrucAndPnH  for V3 no inapp.\n",
    "    #'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "\n",
    "#    'emptyInside' :np.where(np.all(imgLabel == emptyInside, axis=-1)), bad idea\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "#print(labelsDic)\n",
    "#print(img.shape)\n",
    "\n",
    "mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "mask[labelsDic['fineInside']] = 1\n",
    "mask[labelsDic['fineInside2']] = 1\n",
    "mask[labelsDic['rockInside']] = 1\n",
    "#mask[labelsDic['inapInside']] = 1\n",
    "#mask[labelsDic['emptyInside']] = 1\n",
    "\n",
    "\n",
    "\n",
    "mask.dtype='uint8'\n",
    "maskOverlay = cv2.cvtColor(mask*255, cv2.COLOR_GRAY2BGR)\n",
    "maskOverlay[:,:,0] = 0\n",
    "maskOverlay[:,:,2] = 0\n",
    "\n",
    "\n",
    "opacity = 0.2\n",
    "cv2.addWeighted(maskOverlay, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "\n",
    "\n",
    "mask.dtype='uint8'\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "#cv2.imwrite(croppedMasksPath + fileName, mask)\n",
    "#cv2.imwrite(croppedOverlayedPath + fileName, img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Creating padded images for U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating the (128, 160, 1) labels \n",
    "generatedMaskPath = '/home/hooman/dataPreparation/hsTestSet/masks0PaddedForUNet/'\n",
    "\n",
    "for fileName in os.listdir(labelsPath):\n",
    "    \n",
    "    label = imread(labelsPath + fileName) \n",
    "    \n",
    "    \n",
    "    \n",
    "    #resize the label map.\n",
    "    imgLabelResized = cv2.resize(label, (640, 480)) \n",
    "\n",
    "    # you can downsample with numpy too. I use opencv to be consistant.    imgDs = img[::4, ::4, :]\n",
    "    imgLabelDs = cv2.resize(imgLabelResized, (0,0), fx=0.25, fy=0.25) \n",
    "\n",
    "    imgLabel = cv2.copyMakeBorder(imgLabelDs,4,4,0,0,cv2.BORDER_CONSTANT,value=(0,0,0,0))\n",
    "    \n",
    "    \n",
    "\n",
    "    mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), int)\n",
    "\n",
    "\n",
    "    labelsDic = {\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'case'       :np.where(np.all(imgLabel == case, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        'dust'       :np.where(np.all(imgLabel == dust, axis=-1)),\n",
    "    }\n",
    "\n",
    "    #channel 1\n",
    "    if 'wmInside' in labelsDic:\n",
    "        mask[labelsDic['wmInside']] = 1\n",
    "\n",
    "\n",
    "    #channel 2\n",
    "    if 'rockInside' in labelsDic:\n",
    "        mask[labelsDic['rockInside']] = 2\n",
    "\n",
    "    if 'fineInside' in labelsDic:\n",
    "        mask[labelsDic['fineInside']] = 2\n",
    "\n",
    "\n",
    "    #channel 3\n",
    "    if 'teeth' in labelsDic:\n",
    "        mask[labelsDic['teeth']] = 3\n",
    "\n",
    "\n",
    "    #channel 4\n",
    "    if 'emptyInside' in labelsDic:\n",
    "        mask[labelsDic['emptyInside']] = 4\n",
    "\n",
    "    if 'shadow' in labelsDic:\n",
    "        mask[labelsDic['shadow']] = 4\n",
    "\n",
    "    if 'dust' in labelsDic:\n",
    "        mask[labelsDic['dust']] = 4\n",
    "\n",
    "\n",
    "    #channel 5\n",
    "    if 'case' in labelsDic:\n",
    "        mask[labelsDic['case']] = 5\n",
    "\n",
    "        \n",
    "    cv2.imwrite(generatedMaskPath + fileName, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Correct Creating the (128, 160, 6) labels \n",
    "generatedMaskPath = '/home/hooman/dataPreparation/hsTrainingSet/masks6Chan/'\n",
    "\n",
    "for fileName in os.listdir(labelsPath):\n",
    "    \n",
    "    label = imread(labelsPath + fileName) \n",
    "    \n",
    "    \n",
    "    \n",
    "    #resize the label map.\n",
    "    imgLabelResized = cv2.resize(label, (640, 480)) \n",
    "\n",
    "    # you can downsample with numpy too. I use opencv to be consistant.    imgDs = img[::4, ::4, :]\n",
    "    imgLabelDs = cv2.resize(imgLabelResized, (0,0), fx=0.25, fy=0.25) \n",
    "\n",
    "    imgLabel = cv2.copyMakeBorder(imgLabelDs,4,4,0,0,cv2.BORDER_CONSTANT,value=(0,0,0,0))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1], 6), bool)\n",
    "\n",
    "    backGroundMask = np.ones((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "\n",
    "    \n",
    "    \n",
    "    labelsDic = {\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'case'       :np.where(np.all(imgLabel == case, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        'dust'       :np.where(np.all(imgLabel == dust, axis=-1)),\n",
    "    }\n",
    "\n",
    "    \n",
    "    \n",
    "    #channel 1\n",
    "    if 'wmInside' in labelsDic:\n",
    "        mask[labelsDic['wmInside'][0], labelsDic['wmInside'][1], 1] = 1\n",
    "        backGroundMask[labelsDic['wmInside']] = 0\n",
    "\n",
    "\n",
    "    #channel 2\n",
    "    if 'rockInside' in labelsDic:\n",
    "        mask[labelsDic['rockInside'][0], labelsDic['rockInside'][1], 2] = 1\n",
    "        backGroundMask[labelsDic['rockInside']] = 0\n",
    "\n",
    "    if 'fineInside' in labelsDic:\n",
    "        mask[labelsDic['fineInside'][0], labelsDic['fineInside'][1], 2] = 1\n",
    "        backGroundMask[labelsDic['fineInside']] = 0\n",
    "\n",
    "\n",
    "    #channel 3\n",
    "    if 'teeth' in labelsDic:\n",
    "        mask[labelsDic['teeth'][0], labelsDic['teeth'][1], 3] = 1\n",
    "        backGroundMask[labelsDic['teeth']] = 0\n",
    "\n",
    "\n",
    "    #channel 4\n",
    "    if 'emptyInside' in labelsDic:\n",
    "        mask[labelsDic['emptyInside'][0], labelsDic['emptyInside'][1], 4] = 1\n",
    "        backGroundMask[labelsDic['emptyInside']] = 0\n",
    "\n",
    "    if 'shadow' in labelsDic:\n",
    "        mask[labelsDic['shadow'][0], labelsDic['shadow'][1], 4] = 1\n",
    "        backGroundMask[labelsDic['shadow']] = 0\n",
    "\n",
    "    if 'dust' in labelsDic:\n",
    "        mask[labelsDic['dust'][0], labelsDic['dust'][1], 4] = 1\n",
    "        backGroundMask[labelsDic['dust']] = 0\n",
    "\n",
    "\n",
    "    #channel 5\n",
    "    if 'case' in labelsDic:\n",
    "        mask[labelsDic['case'][0], labelsDic['case'][1], 5] = 1\n",
    "        backGroundMask[labelsDic['case']] = 0\n",
    "\n",
    "\n",
    "    #channel 0\n",
    "    mask[:,:, 0] = backGroundMask\n",
    "    \n",
    "    \n",
    "    np.save(generatedMaskPath + fileName.replace(\".png\",\"\"), mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Overlaying Segmentation results for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Overlaying predicted segmentation resutls\n",
    "unet_pathToSavedResults = '/home/hooman/UNet/hsUnet_try13/predicted1chanImages/'\n",
    "testImagesPath = '/home/hooman/dataPreparation/hsTestSet/cropped/croppedImages/'\n",
    "\n",
    "# set this to '' to not save results but desplay the images instead\n",
    "pathToSaveOverlayResults = '/home/hooman/UNet/hsUnet_try13/croppedImagesPredictionsOverlayed/'\n",
    "\n",
    "\n",
    "for imgId in os.listdir(testImagesPath):\n",
    "\n",
    "    img = imread(testImagesPath + imgId)\n",
    "\n",
    "    pred = imread(unet_pathToSavedResults + imgId)\n",
    "    predRes = cv2.resize(pred, (img.shape[1], img.shape[0])) \n",
    "\n",
    "    predCol = cv2.cvtColor(predRes*255, cv2.COLOR_GRAY2BGR)\n",
    "    predCol[:,:,0] = 0\n",
    "    predCol[:,:,2] = 0\n",
    "\n",
    "    \n",
    "    opacity = 0.1\n",
    "    overIm = cv2.addWeighted(predCol, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "    \n",
    "    if pathToSaveOverlayResults != '':\n",
    "        cv2.imwrite(pathToSaveOverlayResults + imgId, overIm)\n",
    "    else:\n",
    "        imshow(overIm)\n",
    "        plt.title('overLayedImage')\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    imgRes = cv2.resize(img, (128, 128)) \n",
    "    imshow(img)\n",
    "    plt.title('img')\n",
    "    plt.show()\n",
    "\n",
    "    imshow(imgRes)\n",
    "    plt.title('imgRes')\n",
    "    plt.show()\n",
    "\n",
    "    imshow(pred)\n",
    "    plt.title('pred')\n",
    "    plt.show()\n",
    "\n",
    "    imshow(predRes)\n",
    "    plt.title('predRes')\n",
    "    plt.show()\n",
    "\n",
    "    imshow(predCol)\n",
    "    plt.title('predCol')\n",
    "    plt.show()\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Overlaying Ground Truth Masks multiple images\n",
    "pathToMasks =  '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCropped_masks/'\n",
    "pathToImages = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCropped_images/'\n",
    "pathToSaveOverlayResults = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCropped_overlay/'\n",
    "\n",
    "\n",
    "for imgId in os.listdir(pathToImages):\n",
    "\n",
    "    img = imread(pathToImages + imgId)\n",
    "    mask = imread(pathToMasks + imgId)\n",
    "\n",
    "    mask.dtype='uint8'\n",
    "    maskOverlay = cv2.cvtColor(mask*255, cv2.COLOR_GRAY2BGR)\n",
    "    maskOverlay[:,:,0] = 0\n",
    "    maskOverlay[:,:,2] = 0\n",
    "\n",
    "\n",
    "    opacity = 0.2\n",
    "    cv2.addWeighted(maskOverlay, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "    \n",
    "\n",
    "    mask.dtype='uint8'\n",
    "    \n",
    "    \n",
    "    cv2.imwrite(pathToSaveOverlayResults + imgId, img)\n",
    "    \n",
    "    #imshow(img)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Overlaying Ground Truth Masks single image\n",
    "\n",
    "pathToMasks = '/home/hooman/dataPreparation/hsTrainingSet/cropped/wrong_croppedMasks/'\n",
    "pathToImages = '/home/hooman/dataPreparation/hsTrainingSet/cropped/croppedImages/'\n",
    "\n",
    "imgId = '1_20161116-155500_0001n0_20737.png'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img = imread(pathToImages + imgId)\n",
    "mask = imread(pathToMasks + imgId)\n",
    "\n",
    "mask.dtype='uint8'\n",
    "maskOverlay = cv2.cvtColor(mask*255, cv2.COLOR_GRAY2BGR)\n",
    "maskOverlay[:,:,0] = 0\n",
    "maskOverlay[:,:,2] = 0\n",
    "\n",
    "\n",
    "opacity = 0.2\n",
    "cv2.addWeighted(maskOverlay, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "\n",
    "\n",
    "mask.dtype='uint8'\n",
    "\n",
    "imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Correcting ROI Points to avoid self intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Converting ROI points from ratio to abs and drawing them on image\n",
    "\n",
    "im = cv2.imread('/media/hooman/New Volume/FM_PROJECT_STORAGE/productionBugs/invalidROI_dueToselfIntersecting/RE__Invalid_FM_ROI/download.jpg')\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "jq = [\n",
    "    (0.1390625,0.5333333333333333),\n",
    "    (0.175,0.9979166666666667),\n",
    "    (0.1625,0.9145833333333333),\n",
    "    (0.209375,0.8958333333333334),\n",
    "    (0.1765625,0.825),\n",
    "    (0.26875,0.7854166666666667),\n",
    "    (0.2421875,0.7020833333333333),\n",
    "    (0.33125,0.6833333333333333),\n",
    "    (0.26875,0.71875),\n",
    "    (0.35,0.7375),\n",
    "    (0.4703125,0.6125),\n",
    "    (0.5265625,0.6145833333333334),\n",
    "    (0.5390625,0.7145833333333333),\n",
    "    (0.503125,0.7208333333333333),\n",
    "    (0.690625,0.825),\n",
    "    (0.6453125,0.8916666666666667),\n",
    "    (0.8328125,0.8604166666666667),\n",
    "    (0.809375,0.5541666666666667),\n",
    "    (0.728125,0.5520833333333334),\n",
    "    (0.6953125,0.47291666666666665),\n",
    "    (0.340625,0.38333333333333336)\n",
    "]\n",
    "\n",
    "\n",
    "jqConv = []\n",
    "for el in jq:\n",
    "    jqConv.append( ((int(el[0]*im.shape[1])),int(el[1]*im.shape[0])) )\n",
    "\n",
    "\n",
    "print(im.shape)\n",
    "print(jqConv)\n",
    "\n",
    "\n",
    "for i in range(len(jqConv)-1):\n",
    "    cv2.line(im, jqConv[i], jqConv[i+1], (255,0,0),2)\n",
    "    \n",
    "cv2.line(im, jqConv[len(jqConv)-1], jqConv[0], (255,0,0),2)\n",
    "\n",
    "cv2.imwrite('/home/hooman/Downloads/RE__Invalid_FM_ROI/res.png', im)\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#don't draw the edge that intersects boundary\n",
    "\n",
    "im = cv2.imread('/home/hooman/Downloads/RE__Invalid_FM_ROI/download.jpg')\n",
    "\n",
    "\n",
    "lines = []\n",
    "for i in range(len(jqConv)):\n",
    "    if i < len(jqConv)-1:\n",
    "        newLine = (jqConv[i], jqConv[i+1])\n",
    "    else:\n",
    "        newLine = (jqConv[len(jqConv)-1], jqConv[0])\n",
    "    \n",
    "    isOk = True\n",
    "    for oldLine in lines[:-1]:\n",
    "        if linesIntersect(oldLine, newLine):\n",
    "            print(i)\n",
    "            isOk = False\n",
    "            \n",
    "    if isOk:\n",
    "        cv2.line(im, newLine[0], newLine[1], (255,0,0),2)\n",
    "        lines.append( newLine )\n",
    "\n",
    "\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#function checking if two lines intersec\n",
    "\n",
    "def pointsCross(A,B,C):\n",
    "    return (C[1]-A[1]) * (B[0]-A[0]) > (B[1]-A[1]) * (C[0]-A[0])\n",
    "\n",
    "# Return true if line segments AB and CD intersect\n",
    "def linesIntersect(line1, line2):\n",
    "    A = np.array(line1[0])\n",
    "    B = np.array(line1[1])\n",
    "\n",
    "    C = np.array(line2[0])\n",
    "    D = np.array(line2[1])\n",
    "    \n",
    "    return pointsCross(A,C,D) != pointsCross(B,C,D) and pointsCross(A,B,C) != pointsCross(A,B,D)\n",
    "\n",
    "def unitTest():\n",
    "    line1 = ( (0, 10), (10,0) )\n",
    "    line2 = ( (15, 12), (10,10) ) \n",
    "    \n",
    "    line3 = ((89, 256), (112, 479))\n",
    "    line4 = ((104, 439), (134, 430))\n",
    "\n",
    "    assert linesIntersect(line1,line2) == False\n",
    "    assert linesIntersect(line3,line4) == True\n",
    "    \n",
    "unitTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# convert the ROI to numpy and save\n",
    "k = np.zeros((21,1,2), np.int32)\n",
    "\n",
    "for i in range(0,21,1):\n",
    "    k[i, 0, :] = jqConv[i]\n",
    "    \n",
    "np.save('path/selfIntersectingROI',k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def areSelfIntersecting_list(boundary_points):\n",
    "    \n",
    "    lines = []\n",
    "\n",
    "    for i in range(len(boundary_points)-1):\n",
    "        newLine = (boundary_points[i], boundary_points[i+1])\n",
    "\n",
    "        for oldLine in lines[:-1]:\n",
    "            if linesIntersect(oldLine, newLine):\n",
    "                return True\n",
    "\n",
    "        lines.append( newLine )\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def areSelfIntersecting_numpy(boundary_points):\n",
    "    \n",
    "    if len(boundary_points) <= 0 or boundary_points.shape[0] < 3:\n",
    "        print(\"The areRoiBoundaryPointsIntersecting received an invalid roi boundary.\\n\")\n",
    "        return True\n",
    "\n",
    "\n",
    "    lines = []\n",
    "\n",
    "    for i in range(len(boundary_points)-1):\n",
    "        newLine = (boundary_points[i], boundary_points[i+1])\n",
    "\n",
    "        for oldLine in lines[:-1]:\n",
    "            if linesIntersect(oldLine, newLine):\n",
    "                print(\"The areRoiBoundaryPointsIntersecting observed that the reduced ROI\\\n",
    "                 boundary self intersects.\\n\")\n",
    "                return True\n",
    "\n",
    "        lines.append( newLine )\n",
    "        \n",
    "    print(\"The areRoiBoundaryPointsIntersecting validated that the reduced ROI boundary\\\n",
    "     does not self intersect.\\n\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# test the functions\n",
    "print(areSelfIntersecting(jqConv[2:]))\n",
    "print(areSelfIntersecting(jqConv))\n",
    "\n",
    "print(areRoiBoundaryPointsIntersecting(k[2:,0,:]))\n",
    "print(areRoiBoundaryPointsIntersecting(k[:,0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gt_rows = readCsvRows(\"/home/hooman/backhoeOpticalScene/boxDetectors/try3_ssdMultiClass_withInappInMatInside_upsideDownShovelsRemoved/fineAndRockAndInapInMatInside_backhoe_shuffled_UpsideDownShovelsRemoved.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#creating full size masks (used for FMDL 3.0)\n",
    "\n",
    "imagesPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may10-2019/images_fromJira/'\n",
    "labelsPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may10-2019/labels_fromJira/'\n",
    "\n",
    "masksSavePath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may10-2019/full_masks/'\n",
    "\n",
    "overlaySavePath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/fmdl-backhoe-trainingData-new_may10-2019/full_overlays/'\n",
    "\n",
    "\n",
    "for fileName in os.listdir(imagesPath):\n",
    "\n",
    "    print(\"prcessing imgId: \" + fileName + \"\\n\")\n",
    "\n",
    "    #read the image from csv row\n",
    "    img = imread(imagesPath + fileName)\n",
    "    \n",
    "    imgLabel = imread(labelsPath + fileName)\n",
    "    imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "\n",
    "    #Create a mas from cropped image\n",
    "    labelsDic = {\n",
    "        'rockInside' : np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' : np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'fmInapp'    : np.where(np.all(imgLabel == fmInapp, axis=-1)),\n",
    "    }\n",
    "\n",
    "\n",
    "    mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "    mask2 = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "    mask.dtype='uint8'\n",
    "    mask2.dtype='uint8'\n",
    "\n",
    "    mask[labelsDic['fineInside']] = 1\n",
    "    mask[labelsDic['rockInside']] = 1\n",
    "    mask[labelsDic['fmInapp']] = 1\n",
    "\n",
    "\n",
    "\n",
    "    #Remove the points that are not in the largest contour from mask\n",
    "    _,contours,_ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE, offset=(0, 0))\n",
    "\n",
    "    if contours:\n",
    "        max_cnt = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # cv2.drawContours(mask2, max_cnt, -1, 1, cv2.FILLED, 8) thos does NOT fill up the inside of contour\n",
    "        cv2.drawContours(mask2, [max_cnt], -1, 1, cv2.FILLED, 8)\n",
    "\n",
    "\n",
    "    #if no contours found, mask2 will remain as all 0s\n",
    "    cv2.imwrite(masksSavePath + fileName, mask2)\n",
    "\n",
    "\n",
    "    #get the overlay\n",
    "    maskOverlay = cv2.cvtColor(mask2*255, cv2.COLOR_GRAY2BGR)\n",
    "    maskOverlay[:,:,0] = 0\n",
    "    maskOverlay[:,:,2] = 0\n",
    "\n",
    "    opacity = 0.2\n",
    "    cv2.addWeighted(maskOverlay, opacity, img, 1 - opacity, 0, img)\n",
    "    \n",
    "    cv2.imwrite(overlaySavePath + fileName, img)\n",
    "\n",
    "\n",
    "    '''        \n",
    "    plt.imshow(mask)\n",
    "    plt.title('mask1')\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(mask2)\n",
    "    plt.title('mask2 final')\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.title('overlayed img')\n",
    "    plt.show()\n",
    "    break\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# random crop the FULL masks create above. You need FULL images and Masks here not cropped. \n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "offsetsToApply = [50,75, 100, 125, 150, 175]\n",
    "\n",
    "dirToSaveImages = '/home/hooman/backhoeOpticalScene/roiDelineators/try4-csvFrom-ssdTry3-withInapp-reducedNumberOfempyBuckets-BatchSize4/randomCroppedImages/'\n",
    "\n",
    "dirToSaveMasks = '/home/hooman/backhoeOpticalScene/roiDelineators/try4-csvFrom-ssdTry3-withInapp-reducedNumberOfempyBuckets-BatchSize4/randomCroppedMasks/'\n",
    "\n",
    "\n",
    "dirToReadImages = '/home/hooman/backhoeOpticalScene/roiDelineators/try4-csvFrom-ssdTry3-withInapp-reducedNumberOfempyBuckets-BatchSize4/images/'\n",
    "\n",
    "dirToReadMasks = '/home/hooman/backhoeOpticalScene/roiDelineators/try4-csvFrom-ssdTry3-withInapp-reducedNumberOfempyBuckets-BatchSize4/full-masks_withInapp/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for row in gt_rows[1:len(gt_rows)-1]:\n",
    "    \n",
    "    vals = row.split(',')\n",
    "\n",
    "    if os.path.exists(dirToReadImages + vals[0]) and os.path.exists(dirToReadMasks + vals[0]):\n",
    "        \n",
    "        try:\n",
    "            imgPil = Image.open(dirToReadImages + vals[0])\n",
    "            img = np.array(imgPil) \n",
    "            imgPil.close()\n",
    "\n",
    "            labelPil = Image.open(dirToReadMasks + vals[0])\n",
    "            label = np.array(labelPil)\n",
    "            labelPil.close()\n",
    "\n",
    "\n",
    "\n",
    "            xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "            if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "                (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "\n",
    "                imgWidth = img.shape[1]\n",
    "                imgHeight = img.shape[0]\n",
    "\n",
    "\n",
    "                imgAct = img[ymin:ymax, xmin:xmax,]\n",
    "                labelAct = label[ymin:ymax, xmin:xmax]\n",
    "\n",
    "                if imgAct.shape[0] > 0 and imgAct.shape[1] > 0 and labelAct.shape[0] > 0 and labelAct.shape[1] > 0: \n",
    "                    cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '_RCAct.png'), imgAct)\n",
    "                    cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '_RCAct.png'), labelAct)\n",
    "\n",
    "\n",
    "\n",
    "                for offset in offsetsToApply:\n",
    "\n",
    "                    img1 =     img[ymin + offset:ymax + offset, xmin:xmax]\n",
    "                    label1 = label[ymin + offset:ymax + offset, xmin:xmax]\n",
    "\n",
    "                    if img1.shape[0] > 0 and img1.shape[1] > 0 and label1.shape[0] > 0 and label1.shape[1] > 0: \n",
    "                        cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_1.png', img1)\n",
    "                        cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_1.png', label1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    img2 =     img[ymin:ymax, xmin + offset:xmax + offset]\n",
    "                    label2 = label[ymin:ymax, xmin + offset:xmax + offset]\n",
    "\n",
    "                    if img2.shape[0] > 0 and img2.shape[1] > 0 and label2.shape[0] > 0 and label2.shape[1] > 0: \n",
    "                        cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_2.png', img2)\n",
    "                        cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_2.png', label2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    if (ymin - offset) > 0:\n",
    "                        img3 =     img[ymin - offset:ymax - offset, xmin:xmax]\n",
    "                        label3 = label[ymin - offset:ymax - offset, xmin:xmax]\n",
    "\n",
    "                        if img3.shape[0] > 0 and img3.shape[1] > 0 and label3.shape[0] > 0 and label3.shape[1] > 0: \n",
    "                            cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_3.png', img3)\n",
    "                            cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_3.png', label3)\n",
    "\n",
    "\n",
    "\n",
    "                    if (xmin - offset) > 0:\n",
    "                        img4 =     img[ymin:ymax, xmin - offset:xmax - offset]\n",
    "                        label4 = label[ymin:ymax, xmin - offset:xmax - offset]\n",
    "\n",
    "                        if img4.shape[0] > 0 and img4.shape[1] > 0 and label4.shape[0] > 0 and label4.shape[1] > 0: \n",
    "\n",
    "                            cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_4.png', img4)\n",
    "                            cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_4.png', label4)\n",
    "        \n",
    "        except:\n",
    "            print(\"coud not open file: \" + vals[0] + \"\\n\")\n",
    "\n",
    "    else:\n",
    "        print(\"one of the provided directories doesn't exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font color='red'> Sandbox Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Showing Images side-by-side for mahdi\n",
    "predsDir1 = '/home/hooman/justHead_testSet_fromTensent/examples/labels_above40-40/'\n",
    "predsDir2 = '/home/hooman/justHead_testSet_fromTensent/examples/preds_all/'\n",
    "predsDir3 = '/home/hooman/justHead_testSet_fromTensent/examples/preds_onlyAbove40-40/'\n",
    "\n",
    "dirToSaveResults = '/home/hooman/justHead_testSet_fromTensent/examples/side/'\n",
    "\n",
    "for imgId in os.listdir('/home/hooman/justHead_testSet_fromTensent/examples/good1/'):\n",
    "\n",
    "    pred1 = imread(predsDir1 + imgId)\n",
    "    pred2 = imread(predsDir2 + imgId)\n",
    "    pred3 = imread(predsDir3 + imgId)\n",
    "\n",
    "    totalW = pred1.shape[1] + pred2.shape[1] + pred2.shape[1] + 20\n",
    "    combImg = np.zeros((pred1.shape[0],totalW, 3), np.uint8)\n",
    "\n",
    "    combImg[:, 0:pred1.shape[1], :] = pred1\n",
    "    offset1 = pred1.shape[1] + 10\n",
    "    combImg[:, offset1:pred2.shape[1]+offset1, :] = pred2\n",
    "    offset2 = pred2.shape[1]+offset1 + 10\n",
    "    combImg[:, offset2:pred3.shape[1]+offset2, :] = pred3\n",
    "    \n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    textloc1 = int(pred1.shape[1] / 2) - 70\n",
    "    textloc2 = int((offset1 + pred2.shape[1]+offset1)/2)- 50\n",
    "    textloc3 = int((offset2 + pred3.shape[1]+offset2)/2)- 90\n",
    "    \n",
    "    cv2.putText(combImg,'groundTruth',(textloc1,7), font, 1,(0,255,0), 2, 0)\n",
    "    cv2.putText(combImg,'allPreds',(textloc2,7), font, 1,(0,255,0), 2, 0)\n",
    "    cv2.putText(combImg,'predsAbove40-40',(textloc3,7), font, 1,(0,255,0), 2, 0)\n",
    "\n",
    "    cv2.imwrite(dirToSaveResults + imgId, combImg)\n",
    "    #cv2.imwrite(dirToSaveResults + imgId, combImg)\n",
    "    imsave(dirToSaveResults + imgId, combImg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
