{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#read and display images\n",
    "import skimage\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage import img_as_ubyte\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#get file names\n",
    "import os\n",
    "\n",
    "#calculate mode\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#you must include the / at the end\n",
    "\n",
    "'''\n",
    "imgBoundariesPath = '/home/hooman/dataPreparation/hsTestSet/imgBoundaries/'\n",
    "labelBoundariesPath = '/home/hooman/dataPreparation/hsTestSet/labelBoundaries/'\n",
    "gtMaskPath = '/home/hooman/dataPreparation/hsTestSet/bucketRectangleMasks/'\n",
    "'''\n",
    "\n",
    "imagesPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/hydraulics/images_fromJira/'\n",
    "\n",
    "labelsPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/hydraulics/labels_fromJira/'\n",
    "\n",
    "\n",
    "#resultsLoc = \"/home/hooman/resultsFromExistingNetwork/mahdisNetworkResult/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Correct Color maps from document\n",
    "\n",
    "###**** FOR THE LABELS YOU MUST CONVERT: \n",
    "#imgLabel = imread(croppedLabelsPath + fileName)\n",
    "#imgLabelRev = cv2.cvtColor(imgLabel, cv2.COLOR_RGB2BGR)\n",
    "###***********************\n",
    "\n",
    "\"\"\" \n",
    "*** Dust and Shadow can be outside or inside. They are trying to convert all shadows and dusts to inside only\n",
    "    but this has not been done in my dataset yet.\n",
    "    \n",
    "*** Inap is anything inside the bucket that is inappropriate for FM and for WM.\n",
    "\n",
    "*** Rock == Boulders\n",
    "*** FineInside == Good For Fragmentation\n",
    "    \n",
    "* Hydralics have no cable and no sheave (the pully puling the cables up).\n",
    "* Bucyris has two cables and two sheaves. \n",
    "* B&H has a single cable and a single sheaves\n",
    "\n",
    "\n",
    "\n",
    "rockInside  = (0, 0, 255, 100)     #blue     \"rock_inside\"      = \"0000FF\"\n",
    "fineInside  = (0, 255, 0, 100)     #green    \"fine_inside\"      = \"00FF00\"\n",
    "emptyInside = (255, 255, 0, 100)   #yellow   \"empty\"            = \"FFFF00\"\n",
    "wmInside    = (255, 100, 100, 100) #L-Pink   \"wm_landmarks\"     = \"FF6464\"\n",
    "inapInside  = (150, 100, 50,100)   #L-Brown  \"inapp_For_FM\"     = \"966432\"\n",
    "\n",
    "\n",
    "teeth       = (255,   0, 255, 100) #pink     \"teeth\"            = \"FF00FF\"\n",
    "case        = (255, 0, 0, 100)     #red      \"case\"             = \"FF0000\"\n",
    "truck       = (255, 255, 200, 100) #cream    \"truck\"            = \"FFFFC8\"\n",
    "sheave      = (255, 128, 0, 100)   #Orage    \"Sheave\"           = \"FF8000\"\n",
    "cable       = (0 , 0, 0, 100)      #black    \"Cable\"            = \"000000\"\n",
    "\n",
    "rockOutside = (128, 0, 255, 100)   #purple    \"rock_outside\"    = \"8000FF\"\n",
    "fineOutside = (0, 255, 255, 100)   #cyan      \"fine_outside\"     = \"00FFFF\"\n",
    "\n",
    "void        = (180, 50, 50, 100)   #Brown    \"void anything not in this labels\"  = \"B43232\"\n",
    "shadow      = (120, 120, 120, 100) #gray     \"shadow inside or outside\"          = \"787878\"\n",
    "dust        = (80, 80, 80, 100)    #D-Gray   \"dust inside or outside\"            = \"505050\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "'''\n",
    "#for Backhoe\n",
    "emptyInside = (255, 255, 0)   #yellow   \"empty\"            = \"FFFF00\"\n",
    "case        = (255, 0, 0)     #red      \"case\"             = \"FF0000\"\n",
    "teeth       = (255,   0, 255) #pink     \"teeth\"            = \"FF00FF\"\n",
    "bucketOutside = (0, 80, 50)\n",
    "\n",
    "\n",
    "cable       = (0 , 0, 0)      #black    \"Cable\"            = \"000000\"\n",
    "shadow      = (150, 150, 150) #gray     \"shadow inside or outside\"          = \"787878\"\n",
    "backGround = (0, 255, 255)   #cyan      \"fine_outside\"     = \"00FFFF\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rockInside  = (0, 0, 255)     #blue     \"rock_inside\"      = \"0000FF\"\n",
    "fineInside  = (0, 255, 0)     #green    \"fine_inside\"      = \"00FF00\"\n",
    "fmInapp = (128, 0, 255)   #purple    \"rock_outside\"    = \"8000FF\"\n",
    "\n",
    "wmInapp = (150, 100,50)\n",
    "wm = (255,100,100)\n",
    "\n",
    "\n",
    "wmInside    = (255, 100, 100) #L-Pink   \"wm_landmarks\"     = \"FF6464\"\n",
    "inapInside  = (150, 100, 50)   #L-Brown  \"inapp_For_FM\"     = \"966432\"\n",
    "\n",
    "sheave      = (255, 128, 0)   #Orage    \"Sheave\"           = \"FF8000\"\n",
    "truck       = (255, 255, 200) #cream    \"truck\"            = \"FFFFC8\"\n",
    "\n",
    "dust = (80,80,80)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#To use the labels below with original labels (not the ones you have saved) use:\n",
    "#imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "# to use these values with labels saved with opencv you must convert to BGR\n",
    "#imgLabelRev = cv2.cvtColor(imgLabel, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "########################\n",
    "# I used this labeles for the manually relabeled ones (by Farhad and Max)\n",
    "# for next retrain round: 150, 100,  50 for fmInapp instead of 128, 0, 255\n",
    "# There is inapp in this color too .128,   0, 255\n",
    "\n",
    "rockInside  = (0, 0, 255)     #blue     \"rock_inside\"      = \"0000FF\"\n",
    "fineInside  = (0, 255, 0)     #green    \"fine_inside\"      = \"00FF00\"\n",
    "emptyInside = (255, 255, 0)   #yellow   \"empty\"            = \"FFFF00\"\n",
    "wmInside    = (255, 100, 100) #L-Pink   \"wm_landmarks\"     = \"FF6464\"\n",
    "inapInside  = (150, 100,  50)   #L-Brown  \"inapp_For_FM\"     = \"966432\"\n",
    "\n",
    "\n",
    "teeth       = (255,   0, 255) #pink     \"teeth\"            = \"FF00FF\"\n",
    "case        = (255, 0, 0)     #red      \"case\"             = \"FF0000\"\n",
    "truck       = (255, 255, 200) #cream    \"truck\"            = \"FFFFC8\"\n",
    "sheave      = (255, 128, 0)   #Orage    \"Sheave\"           = \"FF8000\"\n",
    "cable       = (0 , 0, 0)      #black    \"Cable\"            = \"000000\"\n",
    "\n",
    "rockOutside = (128, 0, 255)   #purple    \"rock_outside\"    = \"8000FF\"\n",
    "fineOutside = (0, 255, 255)   #cyan      \"fine_outside\"     = \"00FFFF\"\n",
    "\n",
    "void        = (180, 50, 50)   #Brown    \"void anything not in this labels\"  = \"B43232\"\n",
    "shadow      = (120, 120, 120) #gray     \"shadow inside or outside\"          = \"787878\"\n",
    "dust        = (80, 80, 80)    #D-Gray   \"dust inside or outside\"            = \"505050\"\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################################################################################################\n",
    "#######################################  FMDL 3.1 STUFF  #########################################################\n",
    "##################################################################################################################\n",
    "\n",
    "# (FOR HYDRAULICS) Use this for images fromJira (the one below for manually relabeled) (V3 training)\n",
    "#After the conversion of .pdn (s) to .png\n",
    "# This pixel values work for the ones from JIRA (not the ones farhad relabeled) which are in:\n",
    "#imagesPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/images/'\n",
    "#labelsPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/labels/'\n",
    "\n",
    "rockInside  = (100, 0, 0)     #blue     \"rock_inside\"                      = \"640000\"\n",
    "fineInside  = (100, 0, 50)     #green    \"fine_inside\"                     = \"640032\"\n",
    "emptyInside = (0, 100, 100)   #yellow   \"empty\"                            = \"FFFF00\"\n",
    "wmInside    = (39, 39, 100) #L-Pink   \"wm_landmarks\"                       = \"272764\"\n",
    "\n",
    "wmInapp = (20, 39, 59)                              #                      = \"14273b\"\n",
    "\n",
    "inapInside  = (47, 47, 47)   #L-Brown  \"inapp_For_FM\"                      = \"2f2f2f\"\n",
    "\n",
    "fineInside2 = (0, 100, 0)   # for some images the green is this\n",
    "\n",
    "\n",
    "teeth       = (100,   0, 100) #pink     \"teeth\"                             = \"640064\"\n",
    "case        = (255, 0, 0)     #red      \"case\"                              = \"FF0000\"\n",
    "truck       = (255, 255, 200) #cream    \"truck\"                             = \"FFFFC8\"\n",
    "sheave      = (255, 128, 0)   #Orage    \"Sheave\"                            = \"FF8000\"\n",
    "cable       = (0 , 0, 0)      #black    \"Cable\"                             = \"000000\"\n",
    "\n",
    "rockOutside = (128, 0, 255)   #purple    \"rock_outside\"                     = \"8000FF\"\n",
    "fineOutside = (0, 255, 255)   #cyan      \"fine_outside\"                     = \"00FFFF\"\n",
    "\n",
    "void        = (180, 50, 50)   #Brown    \"void anything not in this labels\"  = \"B43232\"\n",
    "shadow      = (120, 120, 120) #gray     \"shadow inside or outside\"          = \"787878\"\n",
    "dust        = (80, 80, 80)    #D-Gray   \"dust inside or outside\"            = \"505050\"\n",
    "'''\n",
    "'''\n",
    "\n",
    "'''\n",
    "########################\n",
    "# (FOR HYDRAULICS) I used this labeles for the manually relabeled ones (by Farhad and Max) V3 training)\n",
    "# for next retrain round: 150, 100,  50 for fmInapp instead of 128, 0, 255\n",
    "# There is inapp in this color too .128,   0, 255\n",
    "\n",
    "rockInside  = (0, 0, 255)     #blue     \"rock_inside\"      = \"0000FF\"\n",
    "fineInside  = (0, 255, 0)     #green    \"fine_inside\"      = \"00FF00\"\n",
    "emptyInside = (255, 255, 0)   #yellow   \"empty\"            = \"FFFF00\"\n",
    "wmInside    = (255, 100, 100) #L-Pink   \"wm_landmarks\"     = \"FF6464\"\n",
    "inapInside  = (150, 100,  50)   #L-Brown  \"inapp_For_FM\"     = \"966432\"\n",
    "\n",
    "\n",
    "teeth       = (255,   0, 255) #pink     \"teeth\"            = \"FF00FF\"\n",
    "case        = (255, 0, 0)     #red      \"case\"             = \"FF0000\"\n",
    "truck       = (255, 255, 200) #cream    \"truck\"            = \"FFFFC8\"\n",
    "sheave      = (255, 128, 0)   #Orage    \"Sheave\"           = \"FF8000\"\n",
    "cable       = (0 , 0, 0)      #black    \"Cable\"            = \"000000\"\n",
    "\n",
    "rockOutside = (128, 0, 255)   #purple    \"rock_outside\"    = \"8000FF\"\n",
    "fineOutside = (0, 255, 255)   #cyan      \"fine_outside\"     = \"00FFFF\"\n",
    "\n",
    "void        = (180, 50, 50)   #Brown    \"void anything not in this labels\"  = \"B43232\"\n",
    "shadow      = (120, 120, 120) #gray     \"shadow inside or outside\"          = \"787878\"\n",
    "dust        = (80, 80, 80)    #D-Gray   \"dust inside or outside\"            = \"505050\"\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "# (FOR CABLE)\n",
    "truck       = (255, 255, 200) #cream    \"truck\"            = \"FFFFC8\"\n",
    "case        = (255, 0, 0)     #red      \"case\"             = \"FF0000\"\n",
    "cable       = (0 , 0, 0)      #black    \"Cable\"            = \"000000\"\n",
    "\n",
    "sheave      = (255, 128, 0)   #Orage    \"Sheave\"           = \"FF8000\"\n",
    "teeth       = (255,   0, 255) #pink     \"teeth\"            = \"FF00FF\"\n",
    "fmInapp     = (128, 0, 255)   #purple   \"fine_inside\"      = \"8000FF\"\n",
    "fineInside  = (0, 255, 0)   #green   \"fine_inside\"      = \"00FF00\"\n",
    "emptyInside = (255, 255, 0)   #yellow   \"empty\"            = \"FFFF00\"\n",
    "wmInside    = (255, 100, 100) #L-Pink   \"wm_landmarks\"     = \"FF6464\"\n",
    "dust        = (80, 80, 80, 100)    #D-Gray   \"dust inside or outside\"            = \"505050\"\n",
    "rockInside  = (0, 0, 255, 100)     #blue     \"rock_inside\"      = \"0000FF\"\n",
    "wmInapp  = (150, 100, 50,100)   #L-Brown  \"inapp_For_WM\"     = \"966432\"\n",
    "shadow      = (120, 120, 120) #gray     \"shadow inside or outside\"          = \"787878\"\n",
    "background = (0, 255, 255)   #cyan      \"fine_outside\"     = \"00FFFF\"\n",
    "\n",
    "void        = (180, 50, 50)   #Brown    \"void anything not in this labels\"  = \"B43232\"\n",
    "'''\n",
    "\n",
    "'''\n",
    "# (FOR Backhoe)\n",
    "emptyInside = (255, 255, 0)   #yellow   \"empty\"            = \"FFFF00\"\n",
    "case        = (255, 0, 0)     #red      \"case\"             = \"FF0000\"\n",
    "teeth       = (255,   0, 255) #pink     \"teeth\"            = \"FF00FF\"\n",
    "bucketOutside = (0, 80, 50)     # = \"005032\"\n",
    "\n",
    "cable       = (0 , 0, 0)      #black    \"Cable\"            = \"000000\"\n",
    "shadow      = (120, 120, 120) #gray     \"shadow inside or outside\"          = \"787878\"\n",
    "backGround = (0, 255, 255)   #cyan      \"fine_outside\"     = \"00FFFF\"\n",
    "\n",
    "rockInside  = (0, 0, 255)     #blue     \"rock_inside\"      = \"0000FF\"\n",
    "fineInside  = (0, 255, 0)     #green    \"fine_inside\"      = \"00FF00\"\n",
    "fmInapp = (128, 0, 255)   #purple    \"rock_outside\"    = \"8000FF\"\n",
    "\n",
    "wmInapp = (150, 100,50)\n",
    "wm = (255,100,100)\n",
    "\n",
    "wmInside    = (255, 100, 100) #L-Pink   \"wm_landmarks\"     = \"FF6464\"\n",
    "inapInside  = (150, 100, 50)   #L-Brown  \"inapp_For_FM\"     = \"966432\"\n",
    "\n",
    "sheave      = (255, 128, 0)   #Orage    \"Sheave\"           = \"FF8000\"\n",
    "truck       = (255, 255, 200) #cream    \"truck\"            = \"FFFFC8\"\n",
    "\n",
    "dust = (80,80,80)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def sortLabelsDic(labelsDic, imgLabel, img=[]):\n",
    "\n",
    " #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "            \n",
    "    '''\n",
    "    if len(img) >0 :\n",
    "        print(sortedLabelColsDic)\n",
    "        print(\"\\n\")\n",
    "        print(sortedLabelRowsDic)\n",
    "        print(\"\\n\")\n",
    "    ''' \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ############## Bucket Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    \n",
    "    lowColValsTeeth = []\n",
    "    highColValsTeeth = []\n",
    "    for itemKey in sortedLabelColsDic.keys():\n",
    "        if itemKey == 'teethCols':\n",
    "            labV = sortedLabelColsDic[itemKey]\n",
    "            for v in labV:\n",
    "                lowColValsTeeth.append(v[0])\n",
    "                highColValsTeeth.append(v[len(v)-1])\n",
    "        \n",
    "        labV = sortedLabelColsDic[itemKey]\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    \n",
    "    lowRowValsTeeth = []\n",
    "    highRowValsTeeth = []\n",
    "    for itemKey in sortedLabelRowsDic.keys():\n",
    "        if itemKey == 'teethRows':\n",
    "            labV = sortedLabelRowsDic[itemKey]\n",
    "            for v in labV:\n",
    "                lowRowValsTeeth.append(v[0])\n",
    "                highRowValsTeeth.append(v[len(v)-1])\n",
    "\n",
    "        labV = sortedLabelRowsDic[itemKey]\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "\n",
    "    \n",
    "\n",
    "    #get the bucket boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    yminsTeeth = np.sort(np.array(lowRowValsTeeth))\n",
    "    ymaxsTeeth = np.sort(np.array(highRowValsTeeth))\n",
    "    \n",
    "    '''\n",
    "    print('lowColValsTeeth:')\n",
    "    print(lowColValsTeeth)\n",
    "    print('highColValsTeeth:')\n",
    "    print(highColValsTeeth)\n",
    "    \n",
    "    print('imageShape')\n",
    "    print(imgLabel.shape)\n",
    "    '''\n",
    "    \n",
    "    return xmins, xmaxs, ymins, ymaxs, yminsTeeth, ymaxsTeeth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getBucketBoundariesTooth2ToothV2(imgLabel, img=[]):\n",
    "\n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        \n",
    "                \n",
    "        '''\n",
    "        \n",
    "        #for Cable\n",
    "        'sheave'     :np.where(np.all(imgLabel == sheave, axis=-1)),\n",
    "        'teeth'     :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'fmInapp'     :np.where(np.all(imgLabel == fmInapp, axis=-1)),\n",
    "        'fineInside'     :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'emptyInside'     :np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'     :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'dust'     :np.where(np.all(imgLabel == dust, axis=-1)),\n",
    "        'rockInside'     :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'wmInapp'     :np.where(np.all(imgLabel == wmInapp, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1))\n",
    "        '''\n",
    "        \n",
    "        #for Hydraulics\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        'wmInapp':np.where(np.all(imgLabel == wmInapp, axis=-1)),\n",
    "        'fineInside2' : np.where(np.all(imgLabel == fineInside2, axis=-1))\n",
    "    }\n",
    "    \n",
    "    if len(img) >0 :\n",
    "        plt.imshow(imgLabel)\n",
    "        plt.show()\n",
    "        print(labelsDic)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "    xmins, xmaxs, ymins, ymaxs, yminsTeeth, ymaxsTeeth = sortLabelsDic(labelsDic, imgLabel, img)\n",
    "    \n",
    "          \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0:\n",
    "          \n",
    "        if len(yminsTeeth) > 0 and len(ymaxsTeeth) > 0 and (ymaxsTeeth[len(ymaxsTeeth)-1] - yminsTeeth[0]) > (0.5 * imgLabel.shape[1]):\n",
    "            boundariesDict['bucketInit'] = [xmins[0], xmaxs[len(xmaxs)-1], yminsTeeth[0], ymaxsTeeth[len(ymaxsTeeth)-1]]\n",
    "        \n",
    "        else:\n",
    "            boundariesDict['bucketInit'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1]]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    if 'bucketInit' in boundariesDict:\n",
    "        #(xmin, xmax, ymin, ymax) = boundariesDict['bucketInit']\n",
    "        #cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(255,0,0),3)\n",
    "        \n",
    "        bucketInitHeight = boundariesDict['bucketInit'][1] - boundariesDict['bucketInit'][0]\n",
    "        quart = int(boundariesDict['bucketInit'][0] + bucketInitHeight * 0.4)\n",
    "        \n",
    "        labelsDic2 = {\n",
    "            'fineInside_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == fineInside, axis=-1)),\n",
    "            'fineInside2_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == fineInside2, axis=-1)),\n",
    "            'inapInside_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == inapInside, axis=-1)),\n",
    "            'emptyInside_q':np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == emptyInside, axis=-1)),\n",
    "            'wmInside_q'   :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == wmInside, axis=-1)),\n",
    "            'teeth_q'      :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == teeth, axis=-1)),\n",
    "            'shadow_q'     :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == shadow, axis=-1)),\n",
    "            'wmInapp_q':np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == wmInapp, axis=-1)),\n",
    "            \n",
    "            'rockInside_q' : np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == rockInside, axis=-1)),\n",
    "            #'dust_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == dust, axis=-1)),\n",
    "            #'case_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == case, axis=-1)),\n",
    "        }\n",
    "        \n",
    "        \n",
    "        \n",
    "        xmins2, xmaxs2, ymins2, ymaxs2, yminsTeeth2, ymaxsTeeth2 = sortLabelsDic(labelsDic2, imgLabel, img)\n",
    "        \n",
    "        if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins2) > 0 and len(ymaxs2) > 0:\n",
    "\n",
    "            if len(yminsTeeth2) > 0 and len(ymaxsTeeth2) > 0 and (ymaxsTeeth2[len(ymaxsTeeth2)-1] - yminsTeeth2[0]) > (0.5 * imgLabel.shape[1]):\n",
    "                boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], yminsTeeth2[0], ymaxsTeeth2[len(ymaxsTeeth2)-1]]\n",
    "\n",
    "            else:\n",
    "                boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins2[0], ymaxs2[len(ymaxs2)-1]]\n",
    "        \n",
    "                \n",
    "\n",
    "        ##############################################\n",
    "        ######### Draw Boundaries if Verbose #########\n",
    "        ##############################################\n",
    "        if len(img) > 0:\n",
    "            print(boundariesDict)\n",
    "\n",
    "\n",
    "            #draw bucket boundaries\n",
    "            if 'bucket' in boundariesDict:\n",
    "                (xmin, xmax, ymin, ymax) = boundariesDict['bucket']\n",
    "                cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,255,255),3)\n",
    "\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getMatInsideBoundaries(imgLabel, img=[]):\n",
    "    '''\n",
    "    HS: \n",
    "    ---This method returs a list of boundaries: 1 matInside boundary (if present), which is combination of fineInside, rockInside and inappropritate.\n",
    "    '''\n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        #For Cable  FMDL3.1\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'fmInapp' :np.where(np.all(imgLabel == fmInapp, axis=-1)),\n",
    "\n",
    "        'dust' :np.where(np.all(imgLabel == dust, axis=-1)),\n",
    "        '''\n",
    "        \n",
    "        #For Hydraulics  FMDL3.1\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        \n",
    "        #with the new labels this is the new fmAppropriate mat\n",
    "        'fineInside2' :np.where(np.all(imgLabel == fineInside2, axis=-1))\n",
    "\n",
    "       \n",
    "    }\n",
    "    \n",
    "    if len(img) >0 :\n",
    "        plt.imshow(imgLabel)\n",
    "        plt.show()\n",
    "        print(labelsDic)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "    if len(img) >0 :\n",
    "        print(sortedLabelColsDic)\n",
    "        print(\"\\n\")\n",
    "        print(sortedLabelRowsDic)\n",
    "        print(\"\\n\")\n",
    "         \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ############## matInside Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    for labV in sortedLabelColsDic.values():\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    for labV in sortedLabelRowsDic.values():\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0 : \n",
    "        boundariesDict['matInside'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1]]\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "                \n",
    "\n",
    "    ##############################################\n",
    "    ######### Draw Boundaries if Verbose #########\n",
    "    ##############################################\n",
    "    if len(img) > 0:\n",
    "        print(boundariesDict)\n",
    "        \n",
    "        \n",
    "        #draw boundaries\n",
    "        if 'matInside' in boundariesDict:\n",
    "            (xmin, xmax, ymin, ymax) = boundariesDict['matInside']\n",
    "            cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,0,255),3)\n",
    "        \n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getBucketBoundariesTooth2Tooth(imgLabel, img=[]):\n",
    "\n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        'wmInapp':np.where(np.all(imgLabel == wmInapp, axis=-1)),\n",
    "        'fineInside2' : np.where(np.all(imgLabel == fineInside2, axis=-1)),\n",
    "        \n",
    "        #for Bucyrus\n",
    "        #'sheave'     :np.where(np.all(imgLabel == sheave, axis=-1)),\n",
    "        #'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "    }\n",
    "    \n",
    "    if len(img) >0 :\n",
    "        plt.imshow(imgLabel)\n",
    "        plt.show()\n",
    "        print(labelsDic)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "    if len(img) >0 :\n",
    "        print(sortedLabelColsDic)\n",
    "        print(\"\\n\")\n",
    "        print(sortedLabelRowsDic)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ############## Bucket Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    \n",
    "    lowColValsTeeth = []\n",
    "    highColValsTeeth = []\n",
    "    for itemKey in sortedLabelColsDic.keys():\n",
    "        if itemKey == 'teethCols':\n",
    "            labV = sortedLabelColsDic[itemKey]\n",
    "            for v in labV:\n",
    "                lowColValsTeeth.append(v[0])\n",
    "                highColValsTeeth.append(v[len(v)-1])\n",
    "        \n",
    "        labV = sortedLabelColsDic[itemKey]\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    \n",
    "    lowRowValsTeeth = []\n",
    "    highRowValsTeeth = []\n",
    "    for itemKey in sortedLabelRowsDic.keys():\n",
    "        if itemKey == 'teethRows':\n",
    "            labV = sortedLabelRowsDic[itemKey]\n",
    "            for v in labV:\n",
    "                lowRowValsTeeth.append(v[0])\n",
    "                highRowValsTeeth.append(v[len(v)-1])\n",
    "\n",
    "        labV = sortedLabelRowsDic[itemKey]\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "\n",
    "    \n",
    "\n",
    "    #get the bucket boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    yminsTeeth = np.sort(np.array(lowRowValsTeeth))\n",
    "    ymaxsTeeth = np.sort(np.array(highRowValsTeeth))\n",
    "    \n",
    "    print('lowColValsTeeth:')\n",
    "    print(lowColValsTeeth)\n",
    "    print('highColValsTeeth:')\n",
    "    print(highColValsTeeth)\n",
    "    \n",
    "    print('imageShape')\n",
    "    print(imgLabel.shape)\n",
    "    \n",
    "          \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0:\n",
    "          \n",
    "        if len(yminsTeeth) > 0 and len(ymaxsTeeth) > 0 and (ymaxsTeeth[len(ymaxsTeeth)-1] - yminsTeeth[0]) > (0.5 * imgLabel.shape[1]):\n",
    "            boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], yminsTeeth[0], ymaxsTeeth[len(ymaxsTeeth)-1]]\n",
    "        \n",
    "        else:\n",
    "            boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1]]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "                \n",
    "\n",
    "    ##############################################\n",
    "    ######### Draw Boundaries if Verbose #########\n",
    "    ##############################################\n",
    "    if len(img) > 0:\n",
    "        print(boundariesDict)\n",
    "        \n",
    "        \n",
    "        #draw bucket boundaries\n",
    "        if 'bucket' in boundariesDict:\n",
    "            (xmin, xmax, ymin, ymax) = boundariesDict['bucket']\n",
    "            cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,0,255),3)\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getBucketBoundaries(imgLabel, img=[]):\n",
    "\n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        \n",
    "        #for Bucyrus\n",
    "        #'sheave'     :np.where(np.all(imgLabel == sheave, axis=-1)),\n",
    "        #'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "    }\n",
    "    \n",
    "    if len(img) >0 :\n",
    "        plt.imshow(imgLabel)\n",
    "        plt.show()\n",
    "        print(labelsDic)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "    if len(img) >0 :\n",
    "        print(sortedLabelColsDic)\n",
    "        print(\"\\n\")\n",
    "        print(sortedLabelRowsDic)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ############## Bucket Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    for labV in sortedLabelColsDic.values():\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    for labV in sortedLabelRowsDic.values():\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "\n",
    "    \n",
    "\n",
    "    #get the bucket boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0 : \n",
    "        boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1]]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "                \n",
    "\n",
    "    ##############################################\n",
    "    ######### Draw Boundaries if Verbose #########\n",
    "    ##############################################\n",
    "    if len(img) > 0:\n",
    "        print(boundariesDict)\n",
    "        \n",
    "        \n",
    "        #draw bucket boundaries\n",
    "        (xmin, xmax, ymin, ymax) = boundariesDict['bucket']\n",
    "        cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,0,255),3)\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getAllBoundaries(imgLabel, img=[]):\n",
    "    '''\n",
    "    HS: \n",
    "    ---This method returs a list of boundaries: 1 bucket boundary, 1 fineInside boundary (if present) and several     rockInside boundaries (if present). \n",
    "    '''\n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        \n",
    "        #for Bucyrus\n",
    "        #'sheave'     :np.where(np.all(imgLabel == sheave, axis=-1)),\n",
    "        #'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "    }\n",
    "    \n",
    "    if len(img) >0 :\n",
    "        plt.imshow(imgLabel)\n",
    "        plt.show()\n",
    "        print(labelsDic)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "    if len(img) >0 :\n",
    "        print(sortedLabelColsDic)\n",
    "        print(\"\\n\")\n",
    "        print(sortedLabelRowsDic)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    ##############################################\n",
    "    ############# FineInside Boundary ############\n",
    "    ##############################################'\n",
    "    if 'fineInsideCols' in sortedLabelColsDic and 'fineInsideRows' in sortedLabelRowsDic:\n",
    "        boundariesDict['fineInside'] = [\n",
    "            int(sortedLabelColsDic[\"fineInsideCols\"][0][0]),\n",
    "            int(sortedLabelColsDic[\"fineInsideCols\"][0][len(sortedLabelRowsDic[\"fineInsideRows\"][0])-1]),\n",
    "            int(sortedLabelRowsDic[\"fineInsideRows\"][0][0]),\n",
    "            int(sortedLabelRowsDic[\"fineInsideRows\"][0][len(sortedLabelColsDic[\"fineInsideCols\"][0])-1]),\n",
    "        ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ############# teeth Boundary ############\n",
    "    ##############################################\n",
    "    if 'teethCols' in sortedLabelColsDic and 'teethRows' in sortedLabelRowsDic:\n",
    "        boundariesDict['teeth'] = [\n",
    "            int(sortedLabelColsDic[\"teethCols\"][0][0]),\n",
    "            int(sortedLabelColsDic[\"teethCols\"][0][len(sortedLabelRowsDic[\"teethRows\"][0])-1]),\n",
    "            int(sortedLabelRowsDic[\"teethRows\"][0][0]),\n",
    "            int(sortedLabelRowsDic[\"teethRows\"][0][len(sortedLabelColsDic[\"teethCols\"][0])-1]),\n",
    "        ]   \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ############## Bucket Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    for labV in sortedLabelColsDic.values():\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    for labV in sortedLabelRowsDic.values():\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "\n",
    "    \n",
    "\n",
    "    #get the bucket boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0 : \n",
    "        boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1]]\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    ##############################################\n",
    "    ############# RockInside Boundary ############\n",
    "    ##############################################\n",
    "    if 'rockInsideCols' in sortedLabelColsDic and 'rockInsideRows' in sortedLabelRowsDic:\n",
    "        # Getting the rock maks used to find rock boundaries        \n",
    "        rockMask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "        rockMask[labelsDic['rockInside']] = 1\n",
    "\n",
    "        # This converts any np.array to opencv image.\n",
    "        cv_rockMask = img_as_ubyte(rockMask)\n",
    "\n",
    "        contours, _ = cv2.findContours(cv_rockMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Getting bounding boxes from contours\n",
    "        rockBoundaries = []\n",
    "        for cnt in contours:\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            (xmin, xmax, ymin, ymax) = (y, (y+h), x, (x+w))\n",
    "\n",
    "            # only consider large boundaries.\n",
    "            if h>3 and w >3:\n",
    "                rockBoundaries.append([xmin, xmax, ymin, ymax])\n",
    "\n",
    "        boundariesDict['rockInside'] = rockBoundaries\n",
    "\n",
    "\n",
    "    \n",
    "                \n",
    "\n",
    "    ##############################################\n",
    "    ######### Draw Boundaries if Verbose #########\n",
    "    ##############################################\n",
    "    if len(img) > 0:\n",
    "        print(boundariesDict)\n",
    "        \n",
    "        \n",
    "        #draw bucket boundaries\n",
    "        (xmin, xmax, ymin, ymax) = boundariesDict['bucket']\n",
    "        cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,0,255),3)\n",
    "        \n",
    "        \n",
    "        #draw rockInside boundaries\n",
    "        for rockBb in boundariesDict['rockInside']:\n",
    "            cv2.rectangle(img,(rockBb[2], rockBb[0]),(rockBb[3], rockBb[1]),(255,0,0),3)\n",
    "\n",
    "        \n",
    "        #draw fineInside boundaries\n",
    "        (xmin, xmax, ymin, ymax) = boundariesDict['fineInside']\n",
    "        cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,255,0),3)\n",
    "        \n",
    "        \n",
    "        #draw teeth boundaries\n",
    "        (xmin, xmax, ymin, ymax) = boundariesDict['teeth']\n",
    "        cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(255,255,0),3)\n",
    "        \n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def writeRowsToCsv(rows, csvFullPath):\n",
    "    # open the file\n",
    "    csv_file = open(csvFullPath, \"w\") \n",
    "    \n",
    "    # define column names\n",
    "    columnTitles = \"filename,pathname,xmins,xmax,ymins,ymax,class\\n\"\n",
    "    csv_file.write(columnTitles)\n",
    "\n",
    "    # write rows\n",
    "    for row in rows:\n",
    "        csv_file.write(row)\n",
    "\n",
    "    csv_file.close()\n",
    "    \n",
    "    print(\"wrote \" + str(len(rows)) + \" rows to csv file\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def writeRowDicToCsv(rowsDic, csvFullPath):\n",
    "    # open the file\n",
    "    #use w for mode to override existing\n",
    "    csv_file = open(csvFullPath, \"a\") \n",
    "    \n",
    "    # define column names\n",
    "    columnTitles = \"filename,pathname,xmins,xmax,ymins,ymax,class\\n\"\n",
    "    csv_file.write(columnTitles)\n",
    "\n",
    "    # write rows\n",
    "    for imId in rowsDic:\n",
    "        if imId != 'fileName':\n",
    "            row = rowsDic[imId] + '\\n'\n",
    "            csv_file.write(row)\n",
    "\n",
    "    csv_file.close()\n",
    "    \n",
    "    print(\"wrote \" + str(len(rowsDic)) + \" rows to csv file\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def readCsvRows(fullCsvPath):\n",
    "    # open the file\n",
    "    csv_file = open(fullCsvPath, \"r\") \n",
    "    data = csv_file.read()\n",
    "    csv_file.close()\n",
    "    \n",
    "    rows = data.split('\\n')\n",
    "    \n",
    "    print(\"read \" + str(len(rows)) + \" rows\")\n",
    "    \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getRowsDictFromCsv(fullCsvPath):\n",
    "    csv_file = open(fullCsvPath, \"r\") \n",
    "    data = csv_file.read()\n",
    "    csv_file.close()\n",
    "\n",
    "    rows = data.split('\\n')\n",
    "\n",
    "    rowsDict = {}\n",
    "\n",
    "    for row in rows[1 : len(rows)-1]:\n",
    "        vals = row.split(',')\n",
    "\n",
    "        if vals[0] not in rowsDict:\n",
    "            rowsDict[vals[0]] = []\n",
    "\n",
    "        rowsDict[vals[0]].append(vals[2:7])\n",
    "        \n",
    "    print(\"read \" + str(len(rowsDict)) + \" examples\")\n",
    "    return rowsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getCertainClassRowsDictFromCsv(fullCsvPath, classesToLookFor):\n",
    "    csv_file = open(fullCsvPath, \"r\") \n",
    "    data = csv_file.read()\n",
    "    csv_file.close()\n",
    "\n",
    "    rows = data.split('\\n')\n",
    "\n",
    "    rowsDict = {}\n",
    "\n",
    "    for row in rows[1 : len(rows)-1]:\n",
    "        vals = row.split(',')\n",
    "        \n",
    "        if vals[6] in classesToLookFor:\n",
    "\n",
    "            if vals[0] not in rowsDict:\n",
    "                rowsDict[vals[0]] = row\n",
    "            else:\n",
    "                print(\"error. duplicateRow. This shouldn't happen\")\n",
    "        \n",
    "    print(\"read \" + str(len(rowsDict)) + \" examples\")\n",
    "    return rowsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def visualizeRowDict(rowDict, writeToDisk=False, outputDirPath=\"\", saveLabelToo=False):\n",
    "    for imgId in rowsDict:\n",
    "\n",
    "        img = imread(imagesPath + imgId)\n",
    "        if saveLabelToo==True:\n",
    "            label = imread(labelsPath + imgId)\n",
    "\n",
    "        for box in rowsDict[imgId]:\n",
    "            \n",
    "            if(box[0] != \"\"):\n",
    "\n",
    "                if box[4] == 'bucket':\n",
    "                    (xmin, xmax, ymin, ymax) = box[0:4]\n",
    "                    int(round(float(xmin)))\n",
    "                    cv2.rectangle(img,(int(round(float(xmin))), int(round(float(ymin)))),(int(round(float(xmax))), int(round(float(ymax)))),(0,0,255),3)\n",
    "                    \n",
    "                    \n",
    "                if box[4] == 'matInside':\n",
    "                    (xmin, xmax, ymin, ymax) = box[0:4]\n",
    "                    cv2.rectangle(img,(int(round(float(xmin))), int(round(float(ymin)))),(int(round(float(xmax))), int(round(float(ymax)))),(0,255,0),3)\n",
    "\n",
    "\n",
    "                if box[4] == 'fineInside':\n",
    "                    (xmin, xmax, ymin, ymax) = box[0:4]\n",
    "                    cv2.rectangle(img,(int(round(float(xmin))), int(round(float(ymin)))),(int(round(float(xmax))), int(round(float(ymax)))),(0,255,0),3)\n",
    "\n",
    "\n",
    "                if box[4] == 'rockInside':\n",
    "                    (xmin, xmax, ymin, ymax) = box[0:4]\n",
    "                    cv2.rectangle(img,(int(round(float(xmin))), int(round(float(ymin)))),(int(round(float(xmax))), int(round(float(ymax)))),(255,0,0),3)\n",
    "\n",
    "\n",
    "        if writeToDisk==True and outputDirPath != \"\":\n",
    "            cv2.imwrite(outputDirPath + imgId, img)\n",
    "            \n",
    "            if saveLabelToo==True:\n",
    "                cv2.imwrite(outputDirPath + \"_label_\" + imgId, label)\n",
    "        else:\n",
    "            print(imgId)\n",
    "            if saveLabelToo==True:\n",
    "                plt.imshow(label)\n",
    "                plt.show()\n",
    "\n",
    "            plt.imshow(img)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def visualizeRow(row):\n",
    "    vals = row.split(',')\n",
    "    \n",
    "    img = imread(imagesPath + vals[0])\n",
    "    label = imread(labelsPath + vals[0])\n",
    "    \n",
    "    xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "    if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "        (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "        \n",
    "        \n",
    "        if vals[6] == 'matInside':\n",
    "            cv2.rectangle(img,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(0,255,0),3)\n",
    "            cv2.rectangle(label,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(0,255,0),3)\n",
    "            \n",
    "        if vals[6] == 'matInside':\n",
    "            cv2.rectangle(img,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(0,0,255),3)\n",
    "            cv2.rectangle(label,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(0,0,255),3)\n",
    "            \n",
    "        else:\n",
    "            #read in notebook\n",
    "            cv2.rectangle(img,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(255,0,0),3)\n",
    "            cv2.rectangle(label,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(255,0,0),3)\n",
    "            \n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(label)\n",
    "    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def writeRowToDisk(row, writeLabelsToo=False):\n",
    "    vals = row.split(',')\n",
    "    \n",
    "    img = imread(imagesPath + vals[0])\n",
    "    \n",
    "    xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "    cv2.rectangle(img,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(255,0,0),3)\n",
    "    \n",
    "    cv2.imwrite(imgBoundariesPath + vals[0], img)\n",
    "    \n",
    "    if writeLabelsToo:\n",
    "        label = imread(labelsPath + vals[0])\n",
    "        cv2.rectangle(label,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(255,0,0),3)\n",
    "        cv2.imwrite(labelBoundariesPath + vals[0], label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def visualizeImg(imgId):\n",
    "    img = imread(imagesPath + imgId)\n",
    "    label = imread(labelsPath + imgId)\n",
    "    \n",
    "    foundBucketBoundary, xmin, xmax, ymin, ymax = getBucketBoundaries(label)\n",
    "    \n",
    "    if(foundBucketBoundary):\n",
    "        cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(255,0,0),3)\n",
    "        cv2.rectangle(label,(ymin, xmin),(ymax, xmax),(255,0,0),3)\n",
    "\n",
    "        plt.imshow(img)\n",
    "        plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(label)\n",
    "        plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(\"could not find bucket boundary\\n\")\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(label)\n",
    "        plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getBbxMask(row, writeToDisk=False, mask_direct_path=None, verbose=False):\n",
    "    vals = row.split(',')\n",
    "    \n",
    "    img = imread(imagesPath + vals[0])\n",
    "    mask = np.zeros((img.shape[0], img.shape[1]), bool)\n",
    "    \n",
    "    xmin, xmax, ymin, ymax = vals[2:6]\n",
    "    if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "        (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "        mask[ymin:ymax, xmin:xmax] = 1\n",
    "    \n",
    "    if writeToDisk == True and mask_direct_path != None:\n",
    "        mask.dtype='uint8'\n",
    "        cv2.imwrite(mask_direct_path + vals[0], mask)\n",
    "        \n",
    "    if verbose:\n",
    "        if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "            cv2.rectangle(img,(xmin, ymin),(xmax, ymax),(255,0,0),3)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def calcPerformance(pred_rows, gt_rows, predictedBbMasks_path, gtBbMaks_path, verbose=False, predictedRowDict=None):\n",
    "    total_tn = 0\n",
    "    total_tp = 0\n",
    "    total_fn = 0\n",
    "    total_fp = 0\n",
    "    \n",
    "    rowCount = 0\n",
    "\n",
    "    if predictedRowDict == None:\n",
    "        print(\"using pred_rows\")\n",
    "        for pred_row, gt_row in zip(pred_rows, gt_rows):\n",
    "            pred_vals = pred_row.split(',')\n",
    "            gt_vals = gt_row.split(',')\n",
    "\n",
    "            if gt_vals[0] == pred_vals[0]:\n",
    "                pred_mask = imread(predictedBbMasks_path + pred_vals[0])\n",
    "                gt_mask = imread(gtBbMaks_path + gt_vals[0])\n",
    "\n",
    "                pos_preds = np.where(pred_mask == 1)\n",
    "                neg_preds = np.where(pred_mask == 0)\n",
    "\n",
    "                pos_overlap = pred_mask * gt_mask\n",
    "                neg_overlap = np.logical_not(pred_mask) * np.logical_not(gt_mask)\n",
    "\n",
    "                tp = np.count_nonzero(pos_overlap)\n",
    "                tn = np.count_nonzero(neg_overlap)\n",
    "                fp = len(pos_preds[0]) - tp\n",
    "                fn = len(neg_preds[0]) - tn\n",
    "\n",
    "                total_fp += fp\n",
    "                total_fn += fn\n",
    "                total_tp += tp\n",
    "                total_tn += tn\n",
    "                \n",
    "                rowCount += 1\n",
    "\n",
    "            else:\n",
    "                print(\"ERROR image id's don't match between gt csv file and predictions csv file\")\n",
    "\n",
    "    else:\n",
    "        print(\"using predictedRowDict\")\n",
    "        for gt_row in gt_rows:\n",
    "            gt_vals = gt_row.split(',')\n",
    "\n",
    "            if gt_vals[0] in predictedRowDict:\n",
    "                pred_vals = predictedRowDict[gt_vals[0]]\n",
    "                pred_mask = imread(predictedBbMasks_path + gt_vals[0])\n",
    "                gt_mask = imread(gtBbMaks_path + gt_vals[0])\n",
    "\n",
    "                pos_preds = np.where(pred_mask == 1)\n",
    "                neg_preds = np.where(pred_mask == 0)\n",
    "\n",
    "                pos_overlap = pred_mask * gt_mask\n",
    "                neg_overlap = np.logical_not(pred_mask) * np.logical_not(gt_mask)\n",
    "\n",
    "                tp = np.count_nonzero(pos_overlap)\n",
    "                tn = np.count_nonzero(neg_overlap)\n",
    "                fp = len(pos_preds[0]) - tp\n",
    "                fn = len(neg_preds[0]) - tn\n",
    "\n",
    "                total_fp += fp\n",
    "                total_fn += fn\n",
    "                total_tp += tp\n",
    "                total_tn += tn\n",
    "                \n",
    "                rowCount += 1\n",
    "                \n",
    "        \n",
    "    print(\"Processed \" + str(rowCount) + \" rows:\" )\n",
    "                \n",
    "\n",
    "                \n",
    "    if verbose:\n",
    "        plt.imshow(pred_mask)\n",
    "        plt.title(\"pred\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(gt_mask)\n",
    "        plt.title(\"gt\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(pos_overlap)\n",
    "        plt.title(\"pos_overlap\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(neg_overlap)\n",
    "        plt.title(\"neg_overlap\")\n",
    "        plt.show()\n",
    "\n",
    "        print(\"tp: \" + str(tp) + \" ,    fp: \" + str(fp) + \" ,    tn: \" + str(tn) + \" ,    fn: \" + str(fn) + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    sensitivity = float(total_tp) / (total_tp + total_fn)\n",
    "    specificity = float(total_tn) / (total_tn + total_fp)\n",
    "    precision = float(total_tp) / (total_tp + total_fp)\n",
    "    f_score = 2 * precision * sensitivity / (precision + sensitivity)\n",
    "\n",
    "    print(\"-Sensitivity: \" + str(sensitivity) +\n",
    "          \" ,    -Specificity: \" + str(specificity) +\n",
    "          \" ,    -Precision: \" + str(precision) +\n",
    "          \" ,    -F_score: \" + str(f_score)\n",
    "         )\n",
    "    \n",
    "    return sensitivity, specificity, precision, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def calcPerformance_insideBucket_multiClass(unet_pathToSavedResults, unet_pathTo1ChanLabels, verbose = False):\n",
    "\n",
    "    total_tn = 0\n",
    "    total_tp = 0\n",
    "    total_fn = 0\n",
    "    total_fp = 0\n",
    "\n",
    "    rowCount = 0\n",
    "\n",
    "\n",
    "    for imgId in os.listdir(unet_pathTo1ChanLabels):\n",
    "\n",
    "        label = imread(unet_pathTo1ChanLabels + imgId)\n",
    "        pred = imread(unet_pathToSavedResults + imgId)\n",
    "\n",
    "        labelMask = np.zeros((label.shape[0], label.shape[1]), bool)\n",
    "        predMask = np.zeros((pred.shape[0], pred.shape[1]), bool)\n",
    "\n",
    "\n",
    "\n",
    "        labelPixels = np.where(label == 2)\n",
    "        predPixels = np.where(pred == 2)\n",
    "\n",
    "        labelMask[labelPixels] = 1\n",
    "        predMask[predPixels] = 1\n",
    "\n",
    "\n",
    "\n",
    "        pos_preds = np.where(predMask == 1)\n",
    "        neg_preds = np.where(predMask == 0)\n",
    "\n",
    "        pos_overlap = predMask * labelMask\n",
    "        neg_overlap = np.logical_not(predMask) * np.logical_not(labelMask)\n",
    "\n",
    "\n",
    "        if verbose==True:\n",
    "            imshow(label)\n",
    "            plt.title('label')\n",
    "            plt.show()\n",
    "\n",
    "            imshow(labelMask)\n",
    "            plt.title('labelMask')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            imshow(pred)\n",
    "            plt.title('pred')\n",
    "            plt.show()\n",
    "\n",
    "            imshow(predMask)\n",
    "            plt.title('pred')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        tp = np.count_nonzero(pos_overlap)\n",
    "        tn = np.count_nonzero(neg_overlap)\n",
    "        fp = len(pos_preds[0]) - tp\n",
    "        fn = len(neg_preds[0]) - tn\n",
    "\n",
    "        total_fp += fp\n",
    "        total_fn += fn\n",
    "        total_tp += tp\n",
    "        total_tn += tn\n",
    "\n",
    "        rowCount += 1\n",
    "\n",
    "\n",
    "\n",
    "    sensitivity = float(total_tp) / (total_tp + total_fn)\n",
    "    specificity = float(total_tn) / (total_tn + total_fp)\n",
    "    precision = float(total_tp) / (total_tp + total_fp)\n",
    "    f_score = 2 * precision * sensitivity / (precision + sensitivity)\n",
    "\n",
    "    print(\"-Sensitivity: \" + str(sensitivity) +\n",
    "          \" ,    -Specificity: \" + str(specificity) +\n",
    "          \" ,    -Precision: \" + str(precision) +\n",
    "          \" ,    -F_score: \" + str(f_score)\n",
    "         )\n",
    "\n",
    "\n",
    "    return sensitivity, specificity, precision, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def cropImgFromRow(row, showResult = True , saveResult=False, cropImgPath = \"\", cropLabelPath = \"\"):\n",
    "    vals = row.split(',')\n",
    "\n",
    "    img = imread(imagesPath + vals[0])\n",
    "    label = imread(labelsPath + vals[0])\n",
    "\n",
    "    xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "    if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "        (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "\n",
    "        img = img[ymin:ymax, xmin:xmax,]\n",
    "        label = label[ymin:ymax, xmin:xmax]\n",
    "        \n",
    "        \n",
    "        \n",
    "    if saveResult==True:\n",
    "        cv2.imwrite(cropImgPath + vals[0], img)\n",
    "        cv2.imwrite(cropLabelPath + vals[0], label)\n",
    "\n",
    "        \n",
    "    if showResult==True:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(label)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def cropImgFromRowV2(vals, imgName, margin, showResult = True , saveResult=False, cropImgPath = \"\", cropLabelPath = \"\"):\n",
    "\n",
    "    bestVal = vals[0]\n",
    "    for val in vals:\n",
    "        if val[4] == 'matInside':\n",
    "            bestVal = val\n",
    "    \n",
    "    img = imread(imagesPath + imgName)\n",
    "    label = imread(labelsPath + imgName)\n",
    "\n",
    "    xmin, xmax, ymin, ymax = bestVal[0:4]\n",
    "\n",
    "    if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "        (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "\n",
    "        \n",
    "        \n",
    "        if (ymin-margin) > 0:\n",
    "            yminAdj = (ymin-margin)\n",
    "        else:\n",
    "            yminAdj = ymin\n",
    "\n",
    "\n",
    "        if (xmin-margin) > 0:\n",
    "            xminAdj = (xmin-margin)\n",
    "        else:\n",
    "            xminAdj = xmin\n",
    "\n",
    "\n",
    "\n",
    "        if (ymax + margin) < img.shape[0]:\n",
    "            ymaxAdj = (ymax + margin)\n",
    "        else:\n",
    "            ymaxAdj = ymax\n",
    "\n",
    "\n",
    "\n",
    "        if (xmax + margin) < img.shape[1]:\n",
    "            xmaxAdj = (xmax + margin)\n",
    "        else:\n",
    "            xmaxAdj = xmax\n",
    "\n",
    "\n",
    "        img = img[yminAdj:ymaxAdj, xminAdj:xmaxAdj,]\n",
    "        label = label[yminAdj:ymaxAdj, xminAdj:xmaxAdj]\n",
    "\n",
    "        \n",
    "\n",
    "    if saveResult==True:\n",
    "        cv2.imwrite(cropImgPath + imgName, img)\n",
    "        cv2.imwrite(cropLabelPath + imgName, label)\n",
    "\n",
    "\n",
    "    if showResult==True:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(label)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def randomCropImgFromRow(row, showResult = True , saveResult=False, cropImgPath = \"\", cropLabelPath = \"\", offsetsToApply = []):\n",
    "    vals = row.split(',')\n",
    "\n",
    "    img = imread(imagesPath + vals[0])\n",
    "    label = imread(labelsPath + vals[0])\n",
    "\n",
    "    xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "    if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "        (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "\n",
    "        imgWidth = img.shape[1]\n",
    "        imgHeight = img.shape[0]\n",
    "        \n",
    "        if showResult==True:\n",
    "            plt.imshow(img)\n",
    "            plt.title('imgOrig')\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            \n",
    "        imgAct = img[ymin:ymax, xmin:xmax,]\n",
    "        labelAct = label[ymin:ymax, xmin:xmax]\n",
    "\n",
    "        if saveResult==True:\n",
    "            cv2.imwrite(cropImgPath + vals[0].replace('.png', '_RCAct.png'), imgAct)\n",
    "            cv2.imwrite(cropLabelPath + vals[0].replace('.png', '_RCAct.png'), labelAct)\n",
    "\n",
    "        if showResult==True:\n",
    "            plt.imshow(imgAct)\n",
    "            plt.title('imgAct')\n",
    "            plt.show()\n",
    "            \n",
    "\n",
    "            \n",
    "        for offset in offsetsToApply:\n",
    "            \n",
    "            img1 =     img[ymin + offset:ymax + offset, xmin:xmax]\n",
    "            label1 = label[ymin + offset:ymax + offset, xmin:xmax]\n",
    "            \n",
    "            if saveResult==True:\n",
    "                cv2.imwrite(cropImgPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_1.png', img1)\n",
    "                cv2.imwrite(cropLabelPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_1.png', label1)\n",
    "            \n",
    "            if showResult==True:\n",
    "                plt.imshow(img1)\n",
    "                plt.title('img1')\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            img2 =     img[ymin:ymax, xmin + offset:xmax + offset]\n",
    "            label2 = label[ymin:ymax, xmin + offset:xmax + offset]\n",
    "\n",
    "            if saveResult==True:\n",
    "                cv2.imwrite(cropImgPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_2.png', img2)\n",
    "                cv2.imwrite(cropLabelPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_2.png', label2)\n",
    "            \n",
    "            if showResult==True:\n",
    "                plt.imshow(img2)\n",
    "                plt.title('img2')\n",
    "                plt.show()\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "            if (ymin - offset) >= 0:\n",
    "                img3 =     img[ymin - offset:ymax - offset, xmin:xmax]\n",
    "                label3 = label[ymin - offset:ymax - offset, xmin:xmax]\n",
    "\n",
    "                if saveResult==True:\n",
    "                    cv2.imwrite(cropImgPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_3.png', img3)\n",
    "                    cv2.imwrite(cropLabelPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_3.png', label3)\n",
    "\n",
    "                if showResult==True:\n",
    "                    plt.imshow(img3)\n",
    "                    plt.title('img3')\n",
    "                    plt.show()\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "            if (xmin - offset) >= 0:\n",
    "                img4 =     img[ymin:ymax, xmin - offset:xmax - offset]\n",
    "                label4 = label[ymin:ymax, xmin - offset:xmax - offset]\n",
    "\n",
    "                if saveResult==True:\n",
    "                    cv2.imwrite(cropImgPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_4.png', img4)\n",
    "                    cv2.imwrite(cropLabelPath + vals[0].replace('.png', '') + '_RC' + str(offset) + '_4.png', label4)\n",
    "\n",
    "                if showResult==True:\n",
    "                    plt.imshow(img4)\n",
    "                    plt.title('img4')\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated data processing for boundingBox training set generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def seperateTrainingImages_hydraulics(\n",
    "    imgLabel, \n",
    "    img,\n",
    "    imgName,\n",
    "    dir2PutRejectedImages='/home/hooman/Desktop/deleteThis/negExamples/',\n",
    "    dir2PutAcceptedImages='/home/hooman/Desktop/deleteThis/goodExamples/',\n",
    "    dir2PutBadMatInsideImages='/home/hooman/Desktop/deleteThis/badExamples/',\n",
    "    verbose=True\n",
    "    ):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    rockInside  = (100, 0, 0)     #blue     \"rock_inside\"                      = \"640000\"\n",
    "    fineInside  = (100, 0, 50)     #green    \"fine_inside\"                     = \"640032\"\n",
    "    emptyInside = (0, 100, 100)   #yellow   \"empty\"                            = \"FFFF00\"\n",
    "    wmInside    = (39, 39, 100) #L-Pink   \"wm_landmarks\"                       = \"272764\"\n",
    "\n",
    "    fineInside2 = (20, 39, 59)                              #                      = \"14273b\"\n",
    "\n",
    "    inapInside  = (47, 47, 47)   #L-Brown  \"inapp_For_FM\"                      = \"2f2f2f\"\n",
    "\n",
    "    wmInapp = (0, 100, 0)   # for some images the green is this\n",
    "\n",
    "\n",
    "    teeth       = (100,   0, 100) #pink     \"teeth\"                             = \"640064\"\n",
    "    case        = (255, 0, 0)     #red      \"case\"                              = \"FF0000\"\n",
    "    truck       = (255, 255, 200) #cream    \"truck\"                             = \"FFFFC8\"\n",
    "    sheave      = (255, 128, 0)   #Orage    \"Sheave\"                            = \"FF8000\"\n",
    "    cable       = (0 , 0, 0)      #black    \"Cable\"                             = \"000000\"\n",
    "\n",
    "    rockOutside = (128, 0, 255)   #purple    \"rock_outside\"                     = \"8000FF\"\n",
    "    fineOutside = (0, 255, 255)   #cyan      \"fine_outside\"                     = \"00FFFF\"\n",
    "\n",
    "    void        = (180, 50, 50)   #Brown    \"void anything not in this labels\"  = \"B43232\"\n",
    "    shadow      = (120, 120, 120) #gray     \"shadow inside or outside\"          = \"787878\"\n",
    "    dust        = (80, 80, 80)    #D-Gray   \"dust inside or outside\"            = \"505050\"\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    minAcceptableBucketArea = 10000\n",
    "    minAcceptableBucketHeight = 100\n",
    "    minMatInsideArea2BucketAreaRatio = 0.65\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    boundariesDict = {}\n",
    "    status = 'undefined'\n",
    "    \n",
    "\n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {        \n",
    "        #for Hydraulics only\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        'wmInapp':np.where(np.all(imgLabel == wmInapp, axis=-1)),\n",
    "        'fineInside2' : np.where(np.all(imgLabel == fineInside2, axis=-1))\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    if verbose:\n",
    "        plt.imshow(imgLabel)\n",
    "        plt.title('imgLabel')\n",
    "        plt.show()\n",
    "        plt.imshow(img)\n",
    "        plt.title('img')\n",
    "        plt.show()\n",
    "\n",
    "        print('\\nlabelsDic:')\n",
    "        print(labelsDic)\n",
    "     \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    #######################################################\n",
    "    ########## Finding initial bucket boundary ############\n",
    "    #######################################################\n",
    "    xmins, xmaxs, ymins, ymaxs, yminsTeeth, ymaxsTeeth = sortLabelsDic(labelsDic, imgLabel, img)\n",
    "    \n",
    "          \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0:\n",
    "          \n",
    "        if len(yminsTeeth) > 0 and len(ymaxsTeeth) > 0 and (ymaxsTeeth[len(ymaxsTeeth)-1] - yminsTeeth[0]) > (0.5 * imgLabel.shape[1]):\n",
    "            boundariesDict['bucketInit'] = [xmins[0], xmaxs[len(xmaxs)-1], yminsTeeth[0], ymaxsTeeth[len(ymaxsTeeth)-1]]\n",
    "        \n",
    "        else:\n",
    "            boundariesDict['bucketInit'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1]]\n",
    "\n",
    "\n",
    "            \n",
    "                 \n",
    "    if 'bucketInit' in boundariesDict:\n",
    "        \n",
    "        (xminInit, xmaxInit, yminInit, ymaxInit) = boundariesDict['bucketInit']\n",
    "       \n",
    "        foundBucketArea = (ymaxInit - yminInit)*(xmaxInit - xminInit)\n",
    "        foundBucketHeight = xmaxInit - xminInit\n",
    "        \n",
    "        if verbose:            \n",
    "            cv2.rectangle(img,(yminInit, xminInit),(ymaxInit, xmaxInit),(255,0,0),3)\n",
    "            plt.imshow(img)\n",
    "            plt.title('initialBucket')\n",
    "            plt.show()\n",
    "            print('foundBucketArea:')\n",
    "            print(foundBucketArea)          \n",
    "            print('foundBucketHeight')\n",
    "            print(foundBucketHeight)\n",
    "  \n",
    "        \n",
    "        \n",
    "        #######################################################\n",
    "        ##########******Reject1 Bucket sizes*****#########\n",
    "        #If initial bucket we found is too small, reject this image\n",
    "        #######################################################\n",
    "        if foundBucketArea < minAcceptableBucketArea:    \n",
    "            cv2.rectangle(img,(yminInit, xminInit),(ymaxInit, xmaxInit),(255,0,0),3)\n",
    "            status = 'rejected-bucketArea2small'\n",
    "            \n",
    "            cv2.imwrite(dir2PutRejectedImages + imgName, img)\n",
    "            \n",
    "            boundariesDict['finalStatus'] = status\n",
    "            return boundariesDict\n",
    "        \n",
    "        if foundBucketHeight < minAcceptableBucketHeight:\n",
    "            cv2.rectangle(img,(yminInit, xminInit),(ymaxInit, xmaxInit),(255,0,0),3)\n",
    "            status = 'rejected-bucketHeight2small'\n",
    "            \n",
    "            cv2.imwrite(dir2PutRejectedImages + imgName, img)\n",
    "            \n",
    "            boundariesDict['finalStatus'] = status\n",
    "            return boundariesDict\n",
    "        #######################################################\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "        #######################################################\n",
    "        ########## Finding final bucket boundary ##############\n",
    "        #######################################################    \n",
    "        bucketInitHeight = boundariesDict['bucketInit'][1] - boundariesDict['bucketInit'][0]\n",
    "        quart = int(boundariesDict['bucketInit'][0] + bucketInitHeight * 0.4)\n",
    "        \n",
    "        labelsDic2 = {\n",
    "            'fineInside_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == fineInside, axis=-1)),\n",
    "            'fineInside2_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == fineInside2, axis=-1)),\n",
    "            'inapInside_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == inapInside, axis=-1)),\n",
    "            'emptyInside_q':np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == emptyInside, axis=-1)),\n",
    "            'wmInside_q'   :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == wmInside, axis=-1)),\n",
    "            'teeth_q'      :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == teeth, axis=-1)),\n",
    "            'shadow_q'     :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == shadow, axis=-1)),\n",
    "            'wmInapp_q':np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == wmInapp, axis=-1)),\n",
    "            \n",
    "            'rockInside_q' : np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == rockInside, axis=-1)),\n",
    "            #'dust_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == dust, axis=-1)),\n",
    "            #'case_q' :np.where(np.all(imgLabel[boundariesDict['bucketInit'][0]:quart,:,:] == case, axis=-1)),\n",
    "        }\n",
    "        \n",
    "        \n",
    "        xmins2, xmaxs2, ymins2, ymaxs2, yminsTeeth2, ymaxsTeeth2 = sortLabelsDic(labelsDic2, imgLabel, img)\n",
    "        \n",
    "        if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins2) > 0 and len(ymaxs2) > 0:\n",
    "\n",
    "            if len(yminsTeeth2) > 0 and len(ymaxsTeeth2) > 0 and (ymaxsTeeth2[len(ymaxsTeeth2)-1] - yminsTeeth2[0]) > (0.5 * imgLabel.shape[1]):\n",
    "                boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], yminsTeeth2[0], ymaxsTeeth2[len(ymaxsTeeth2)-1]]\n",
    "\n",
    "            else:\n",
    "                boundariesDict['bucket'] = [xmins[0], xmaxs[len(xmaxs)-1], ymins2[0], ymaxs2[len(ymaxs2)-1]]\n",
    "        \n",
    "                \n",
    "\n",
    "\n",
    "        if 'bucket' in boundariesDict:\n",
    "            (xmin, xmax, ymin, ymax) = boundariesDict['bucket']\n",
    "            cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,255,255),3)\n",
    "\n",
    "            if verbose:\n",
    "                plt.imshow(img)\n",
    "                plt.title('finalBucket')\n",
    "                plt.show()\n",
    "\n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "##################################################################################################################\n",
    "            \n",
    "            ##############################################\n",
    "            ######### Processing MatInside ###############\n",
    "            ##############################################\n",
    "            labelsDicMatInside = {\n",
    "                #For Hydraulics  FMDL3.1\n",
    "                'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "                'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "                'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "\n",
    "                #with the new labels this is the new fmAppropriate mat\n",
    "                'fineInside2' :np.where(np.all(imgLabel == fineInside2, axis=-1)),\n",
    "            }\n",
    "            \n",
    "        \n",
    "            if verbose:\n",
    "                print('\\n\\n\\nlabelsDicMatInside:')\n",
    "                print(labelsDicMatInside)\n",
    "\n",
    "                \n",
    "\n",
    "            #get the boundary for each label\n",
    "            sortedLabelColsDicMatInside = {}\n",
    "            sortedLabelRowsDicMatInside = {}\n",
    "            for k in labelsDicMatInside.keys():\n",
    "                if len(labelsDicMatInside[k][0]) > 0:\n",
    "                    sortedLabelColsDicMatInside[k+'Cols'] = np.sort(labelsDicMatInside[k][0]),\n",
    "                    sortedLabelRowsDicMatInside[k+'Rows'] = np.sort(labelsDicMatInside[k][1]),\n",
    "\n",
    "\n",
    "\n",
    "            #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "            lowColValsMatInside = []\n",
    "            highColValsMatInside = []\n",
    "            for labV in sortedLabelColsDicMatInside.values():\n",
    "                for v in labV:\n",
    "                    lowColValsMatInside.append(v[0])\n",
    "                    highColValsMatInside.append(v[len(v)-1])\n",
    "\n",
    "            lowRowValsMatInside = []\n",
    "            highRowValsMatInside = []\n",
    "            for labV in sortedLabelRowsDicMatInside.values():\n",
    "                for v in labV:\n",
    "                    lowRowValsMatInside.append(v[0])\n",
    "                    highRowValsMatInside.append(v[len(v)-1])\n",
    "\n",
    "\n",
    "\n",
    "            #get the boundary\n",
    "            xminsMatInside = np.sort(np.array(lowColValsMatInside))\n",
    "            xmaxsMatInside = np.sort(np.array(highColValsMatInside))\n",
    "            yminsMatInside = np.sort(np.array(lowRowValsMatInside))\n",
    "            ymaxsMatInside = np.sort(np.array(highRowValsMatInside))\n",
    "            \n",
    "            \n",
    "            \n",
    "                    \n",
    "            ##########################################################################\n",
    "            ############## decide to keep or reject matInside Boundary ###############\n",
    "            ##########################################################################\n",
    "\n",
    "            if len(xminsMatInside) > 0 and len(xmaxsMatInside) > 0 and len(yminsMatInside) > 0 and len(ymaxsMatInside) > 0 : \n",
    "            \n",
    "                boundariesDict['matInside'] = [xminsMatInside[0], xmaxsMatInside[len(xmaxsMatInside)-1], yminsMatInside[0], ymaxsMatInside[len(ymaxsMatInside)-1]]\n",
    "\n",
    "\n",
    "                (xminFinalMatInside, xmaxFinalMatInside, yminFinalMatInside, ymaxFinalMatInside) = boundariesDict['matInside']\n",
    "\n",
    "                cv2.rectangle(img,(yminFinalMatInside, xminFinalMatInside),(ymaxFinalMatInside, xmaxFinalMatInside),(255,255, 0),3)\n",
    "\n",
    "                foundFinalMatInsideArea = (ymaxFinalMatInside - yminFinalMatInside)*(xmaxFinalMatInside - xminFinalMatInside)\n",
    "                \n",
    "                matInside2BucketAreaRatio = foundFinalMatInsideArea / foundBucketArea\n",
    "\n",
    "\n",
    "                if verbose:\n",
    "                    print('\\nmatInside2BucketAreaRatio:')\n",
    "                    print(matInside2BucketAreaRatio)\n",
    "                    \n",
    "                    plt.imshow(img)\n",
    "                    plt.title('finalMatInside')\n",
    "                    plt.show()\n",
    "\n",
    "                    \n",
    "                                        \n",
    "                    \n",
    "                #################################################################\n",
    "                ##########******Reject2 not enough good material*****############\n",
    "                #If no fine, or rock material that are good in the bucket, reject\n",
    "                #################################################################\n",
    "                if len(labelsDicMatInside['rockInside'][0]) == 0 and len(labelsDicMatInside['fineInside'][0]) == 0 and len(labelsDicMatInside['fineInside2'][0]) == 0:\n",
    "\n",
    "                    status = 'rejected-SomeButNotEnoughAppropriateMaterial'\n",
    "\n",
    "                    cv2.imwrite(dir2PutBadMatInsideImages + imgName, img)\n",
    "\n",
    "                    boundariesDict['finalStatus'] = status\n",
    "\n",
    "                    return boundariesDict\n",
    "                #################################################################                    \n",
    "                    \n",
    "                    \n",
    "                ###############################################################################\n",
    "                ##########******Reject3 not enough good material*****##########################\n",
    "                #If area of matInside is much less than bucket area (mostly empty bucket), reject\n",
    "                ###############################################################################                \n",
    "                if matInside2BucketAreaRatio < minMatInsideArea2BucketAreaRatio:    \n",
    "                    status = 'rejected-matInsideArea2small'\n",
    "\n",
    "                    cv2.imwrite(dir2PutBadMatInsideImages + imgName, img)\n",
    "\n",
    "                    boundariesDict['finalStatus'] = status\n",
    "                    return boundariesDict\n",
    "                #################################################################\n",
    "                \n",
    "                \n",
    "                status = 'accepted-BothBucketAndMatInside'\n",
    "            else:\n",
    "                #Found bucket but no MatInside    \n",
    "                status = 'accepted-onlyBucketNoMatInsideContent'\n",
    "                \n",
    "                \n",
    "            cv2.imwrite(dir2PutAcceptedImages + imgName, img)    \n",
    "            boundariesDict['finalStatus'] = status\n",
    "            \n",
    "            return boundariesDict\n",
    "                \n",
    "        else:\n",
    "            # Found no bucket\n",
    "            boundariesDict['finalStatus'] = 'rejected_foundNoBucket'\n",
    "            cv2.imwrite(dir2PutRejectedImages + imgName, img)\n",
    "            return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Automatically generating training data from directory of images\n",
    "imagesPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/hydraulics/images_fromJira/'\n",
    "labelsPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/hydraulics/labels_fromJira/'\n",
    "\n",
    "dir2PutRejectedImages='/home/hooman/Desktop/deleteThis/negExamples/'\n",
    "dir2PutAcceptedImages='/home/hooman/Desktop/deleteThis/goodExamples/'\n",
    "dir2PutBadMatInsideImages='/home/hooman/Desktop/deleteThis/badExamples/'\n",
    "verbose=False\n",
    "\n",
    "\n",
    "rows = []\n",
    "for fileName in os.listdir(imagesPath):\n",
    "    \n",
    "    filePath = labelsPath + fileName\n",
    "    \n",
    "    imgLabel = imread(filePath)\n",
    "    \n",
    "    #I added this for try3  ssd-multiclass-tries 1 and 2 didnt have this.\n",
    "    imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "    img = imread(imagesPath + fileName)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"processing file:\\n\" + filePath + '\\n')\n",
    "    \n",
    "    boundariesDict = seperateTrainingImages_hydraulics(imgLabel, img, fileName, dir2PutRejectedImages, dir2PutAcceptedImages, dir2PutBadMatInsideImages, verbose)\n",
    "\n",
    "    print('\\nboundariesDict:')\n",
    "    print(boundariesDict)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if boundariesDict and ('bucket' in boundariesDict):\n",
    "        # write up the rows\n",
    "        (xmin, xmax, ymin, ymax) = boundariesDict['bucket']\n",
    "        row = fileName + \",\" + filePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"bucket\" + \"\\n\"\n",
    "    \n",
    "        rows.append(row)\n",
    "\n",
    "        \n",
    "        if('matInside' in boundariesDict):\n",
    "            if len(boundariesDict['matInside']) == 4:\n",
    "                (xmin, xmax, ymin, ymax) = boundariesDict['matInside']\n",
    "                row = fileName + \",\" + filePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"matInside\" + \"\\n\"\n",
    "            else:\n",
    "                print(\"ERROR: Found more than one matInside Boundaries. This should NOT happen\\n\")\n",
    "\n",
    "            rows.append(row)  \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "print(\"processed \"+ str(len(rows)) + \" rows\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#(single image of above for tests) (do not delete)\n",
    "rows = []\n",
    "\n",
    "\n",
    "#fileName = 'KAJF0576_20110311071930_avi_15591.png'\n",
    "#fileName = '1004_ESP_S05_001_35973.png'\n",
    "#fileName = '1_20161115-222501_0001n0_3297.png'\n",
    "#fileName = '1_20170118-023300_0001n0_9611.png'\n",
    "#fileName = '1_20161117-022000_0001n0_12000.png' \n",
    "#fileName = '1_20171114-111400_0001n0_18741.png'\n",
    "#fileName = '1_20180122-051000_0001n0_29579.png'\n",
    "#fileName = '1_20161116-025500_0001n0_13817.png'\n",
    "#fileName = '1_20170118-111000_0001n0_17029.png'\n",
    "\n",
    "#fileName = '1004_ESP_S04_009_69091.png'\n",
    "#fileName = '1004_ESP_S04_009_67813.png'\n",
    "\n",
    "fileName = '1004_ESP_S04_009_66324.png'\n",
    "\n",
    "    \n",
    "    \n",
    "filePath = labelsPath + fileName\n",
    "\n",
    "imgLabel = imread(filePath)\n",
    "img = imread(imagesPath + fileName)\n",
    "\n",
    "#I added this for try3  ssd-multiclass-tries 1 and 2 didnt have this.\n",
    "imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "\n",
    "print(\"processing file:\\n\" + filePath + '\\n\\n\\n')\n",
    "\n",
    "\n",
    "boundariesDict = seperateTrainingImages_hydraulics(imgLabel, img, fileName)\n",
    "\n",
    "\n",
    "print('\\n\\n\\nboundariesDict:')\n",
    "print(boundariesDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeRowsToCsv(rows, \"/home/hooman/Desktop/deleteThis/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows[0:38]:\n",
    "    visualizeRow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding boundaries and writing them to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Finding matInside and bucket boundaries. For ssdMulti-try3\n",
    "rows = []\n",
    "for fileName in os.listdir(imagesPath):\n",
    "    \n",
    "    filePath = labelsPath + fileName\n",
    "    \n",
    "    imgLabel = imread(filePath)\n",
    "    \n",
    "    #I added this for try3  ssd-multiclass-tries 1 and 2 didnt have this.\n",
    "    imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "    \n",
    "    print(\"processing file: \" + filePath)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #bucketBoundariesDict = getBucketBoundaries(imgLabel)\n",
    "    bucketBoundariesDict = getBucketBoundariesTooth2ToothV2(imgLabel)\n",
    "    matInsideBoundariesDict = getMatInsideBoundaries(imgLabel)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if bucketBoundariesDict and ('bucket' in bucketBoundariesDict):\n",
    "        # write up the rows\n",
    "        (xmin, xmax, ymin, ymax) = bucketBoundariesDict['bucket']\n",
    "        row = fileName + \",\" + filePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"bucket\" + \"\\n\"\n",
    "    \n",
    "        rows.append(row)\n",
    "    \n",
    "    else:\n",
    "        print(\"ERROR: Found no bucket boundary.\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    if('matInside' in matInsideBoundariesDict):\n",
    "        if len(matInsideBoundariesDict['matInside']) == 4:\n",
    "            (xmin, xmax, ymin, ymax) = matInsideBoundariesDict['matInside']\n",
    "            row = fileName + \",\" + filePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"matInside\" + \"\\n\"\n",
    "        else:\n",
    "            print(\"ERROR: Found more than one matInside Boundaries. This should NOT happen\\n\")\n",
    "        \n",
    "        rows.append(row)        \n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "print(\"processes \"+ str(len(rows)) + \" rows\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeRowsToCsv(rows, \"/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/cable/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_cable__try1/validationSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for row in rows[200:300]:\n",
    "    visualizeRow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#(single image of above for tests) Debugging boundaris for boxDetector 2nd round (do not delete)\n",
    "rows = []\n",
    "\n",
    "#fileName = '1_20180703-100000_1001n0_23970.png'\n",
    "fileName = '1003_PTF_S14_A_001_2187.png'\n",
    "   \n",
    "    \n",
    "    \n",
    "filePath = labelsPath + fileName\n",
    "\n",
    "imgLabel = imread(filePath)\n",
    "img = imread(imagesPath + fileName)\n",
    "\n",
    "#I added this for try3  ssd-multiclass-tries 1 and 2 didnt have this.\n",
    "imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "print(\"processing file: \" + filePath)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bucketBoundariesDict = getBucketBoundariesTooth2ToothV2(imgLabel, img)\n",
    "#matInsideBoundariesDict = getMatInsideBoundaries(imgLabel, img)\n",
    "\n",
    "\n",
    "\n",
    "if('bucket' in bucketBoundariesDict):\n",
    "    # write up the rows\n",
    "    (xmin, xmax, ymin, ymax) = bucketBoundariesDict['bucket']\n",
    "    row = fileName + \",\" + filePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"bucket\" + \"\\n\"\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: Found no bucket boundary.\\n\")\n",
    "\n",
    "\n",
    "\n",
    "if('matInside' in matInsideBoundariesDict):\n",
    "    if len(matInsideBoundariesDict['matInside']) == 4:\n",
    "        (xmin, xmax, ymin, ymax) = matInsideBoundariesDict['matInside']\n",
    "        row = fileName + \",\" + filePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"matInside\" + \"\\n\"\n",
    "    else:\n",
    "        print(\"ERROR: Found more than one matInside Boundaries. This should NOT happen\\n\")\n",
    "\n",
    "    rows.append(row)        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing existing csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowsDict = getRowsDictFromCsv(\"/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/backhoe/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_backhoe__try1/validationSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizeRowDict(rowsDict, True, '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/backhoe/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_backhoe__try1/validationSet/', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropping images to contain only ROI (V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowDict = getRowsDictFromCsv('/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameNetworkAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/unetBoxes_finalTrainingSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgName in os.listdir(imagesPath):\n",
    "    cropImgFromRowV2(rowDict[imgName],imgName, 100, False , True,'/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameNetworkAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/finalTrainingSet_images_croped/','/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameNetworkAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/finalTrainingSet_masks_croped/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Cropping images for U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_rows = readCsvRows('/home/hooman/backhoeOpticalScene/roiDelineators/try1-csvFrom-ssdTry2/fromSSdTry2_fineAndRockAndInapInMatInside_backhoe_shuffled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# random crop images and masks\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "offsetsToApply = [50,75, 100, 125, 150, 175]\n",
    "dirToSaveImages = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/randomCroppedImages/'\n",
    "dirToSaveMasks = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/randomCroppedMasks/'\n",
    "\n",
    "\n",
    "dirToReadImages = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/allImages/'\n",
    "dirToReadMasks = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/fullMaks/'\n",
    "\n",
    "\n",
    "for row in gt_rows[1:len(gt_rows)-1]:\n",
    "    \n",
    "    vals = row.split(',')\n",
    "\n",
    "    if os.path.exists(dirToReadImages + vals[0]) and os.path.exists(dirToReadMasks + vals[0]):\n",
    "        \n",
    "        #This causes a \"Too many open files error\"\n",
    "        #img = imread(dirToReadImages + vals[0])\n",
    "        #label = imread(dirToReadMasks + vals[0])\n",
    "        \n",
    "        imgPil = Image.open(dirToReadImages + vals[0])\n",
    "        img = np.array(imgPil) \n",
    "        imgPil.close()\n",
    "\n",
    "        labelPil = Image.open(dirToReadMasks + vals[0])\n",
    "        label = np.array(labelPil)\n",
    "        labelPil.close()\n",
    "        \n",
    "        \n",
    "\n",
    "        xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "        if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "            (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "\n",
    "            imgWidth = img.shape[1]\n",
    "            imgHeight = img.shape[0]\n",
    "\n",
    "\n",
    "            imgAct = img[ymin:ymax, xmin:xmax,]\n",
    "            labelAct = label[ymin:ymax, xmin:xmax]\n",
    "\n",
    "            if imgAct.shape[0] > 0 and imgAct.shape[1] > 0 and labelAct.shape[0] > 0 and labelAct.shape[1] > 0: \n",
    "                cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '_RCAct.png'), imgAct)\n",
    "                cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '_RCAct.png'), labelAct)\n",
    "\n",
    "\n",
    "\n",
    "            for offset in offsetsToApply:\n",
    "\n",
    "                img1 =     img[ymin + offset:ymax + offset, xmin:xmax]\n",
    "                label1 = label[ymin + offset:ymax + offset, xmin:xmax]\n",
    "                \n",
    "                if img1.shape[0] > 0 and img1.shape[1] > 0 and label1.shape[0] > 0 and label1.shape[1] > 0: \n",
    "                    cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_1.png', img1)\n",
    "                    cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_1.png', label1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                img2 =     img[ymin:ymax, xmin + offset:xmax + offset]\n",
    "                label2 = label[ymin:ymax, xmin + offset:xmax + offset]\n",
    "         \n",
    "                if img2.shape[0] > 0 and img2.shape[1] > 0 and label2.shape[0] > 0 and label2.shape[1] > 0: \n",
    "                    cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_2.png', img2)\n",
    "                    cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_2.png', label2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                if (ymin - offset) > 0:\n",
    "                    img3 =     img[ymin - offset:ymax - offset, xmin:xmax]\n",
    "                    label3 = label[ymin - offset:ymax - offset, xmin:xmax]\n",
    "                    \n",
    "                    if img3.shape[0] > 0 and img3.shape[1] > 0 and label3.shape[0] > 0 and label3.shape[1] > 0: \n",
    "                        cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_3.png', img3)\n",
    "                        cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_3.png', label3)\n",
    "\n",
    "\n",
    "\n",
    "                if (xmin - offset) > 0:\n",
    "                    img4 =     img[ymin:ymax, xmin - offset:xmax - offset]\n",
    "                    label4 = label[ymin:ymax, xmin - offset:xmax - offset]\n",
    "                    \n",
    "                    if img4.shape[0] > 0 and img4.shape[1] > 0 and label4.shape[0] > 0 and label4.shape[1] > 0: \n",
    "\n",
    "                        cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_4.png', img4)\n",
    "                        cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_4.png', label4)\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"one of the provided directories doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#random cropping images and labels\n",
    "\n",
    "offsetsToApply = [50,75, 100, 125, 150, 175]\n",
    "dirToSaveImages = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCroppedImages/'\n",
    "dirToSaveLabels = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCroppedLabels/'\n",
    "\n",
    "for row in gt_rows[1:len(gt_rows)-1]:\n",
    "    randomCropImgFromRow(row, False , True, dirToSaveImages, dirToSaveLabels, offsetsToApply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating semantic segmentation Masks for U-Net from Cropped images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# creating masks for u-net CORRECT (using BGR for labels) more efficent to use with augmentations quickly\n",
    "\n",
    "\n",
    "croppedImagesPath = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCropped_images/'\n",
    "croppedLabelsPath = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCropped_labels/'\n",
    "croppedMasksPath  = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCropped_masks/'\n",
    "\n",
    "\n",
    "n = 0\n",
    "for fileName in os.listdir(croppedLabelsPath):\n",
    "    \n",
    "    try:\n",
    "        img = imread(croppedImagesPath + fileName)\n",
    "        imgLabel = imread(croppedLabelsPath + fileName)\n",
    "        #imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGB2BGR)  This is wrong too\n",
    "        imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "\n",
    "        labelsDic = {\n",
    "            'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "            'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "            'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        #    'emptyInside' :np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        }\n",
    "\n",
    "\n",
    "        #print(labelsDic)\n",
    "\n",
    "        mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "        mask[labelsDic['fineInside']] = 1\n",
    "        mask[labelsDic['rockInside']] = 1\n",
    "        mask[labelsDic['inapInside']] = 1\n",
    "        #mask[labelsDic['emptyInside']] = 1\n",
    "\n",
    "\n",
    "        mask.dtype='uint8'\n",
    "        cv2.imwrite(croppedMasksPath + fileName, mask)\n",
    "\n",
    "        n += 1\n",
    "    except:\n",
    "        print(\"couldnt open file: \" + fileName)\n",
    "\n",
    "print(\"created  \" + str(n) + \"  binary masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# creating masks for u-net CORRECT (using BGR for labels) with overlay\n",
    "\n",
    "'''\n",
    "croppedImagesPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/images/'\n",
    "croppedLabelsPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/labels/'\n",
    "croppedMasksPath  = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/masks/'\n",
    "croppedOverlayedPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/overlayed/'\n",
    "'''\n",
    "\n",
    "'''\n",
    "croppedImagesPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/finalTrainingSet_images/'\n",
    "croppedLabelsPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/labels_fromJira/'\n",
    "\n",
    "croppedMasksPath  = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/images_frmJira__fullSizeImages_masks/'\n",
    "croppedOverlayedPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/images_frmJira__fullSizeImages_overlays/'\n",
    "'''\n",
    "\n",
    "croppedImagesPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/images_manuallyLabeled/'\n",
    "\n",
    "croppedLabelsPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/labeles_manuallyLabeled/'\n",
    "\n",
    "croppedMasksPath  = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/manuallyLabeled_masks/'\n",
    "\n",
    "croppedOverlayedPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/manuallyLabeled_overlays/'\n",
    "\n",
    "\n",
    "\n",
    "n = 0\n",
    "for fileName in os.listdir(croppedImagesPath):\n",
    "    img = imread(croppedImagesPath + fileName)\n",
    "    imgLabel = imread(croppedLabelsPath + fileName)\n",
    "    #imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGB2BGR)  This is wrong too\n",
    "    imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "\n",
    "    labelsDic = {\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        \n",
    "        #for V3 with the new labels this is the new fmAppropriate mat\n",
    "        'fineInside2' :np.where(np.all(imgLabel == fineInside2, axis=-1)),\n",
    "        \n",
    "        #V2 for Hydraulics U-Net I had the inapInside labels but not for BucyrucAndPnH  for V3 no inapp.\n",
    "        #'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        \n",
    "    #    'emptyInside' :np.where(np.all(imgLabel == emptyInside, axis=-1)), bad idea\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "    #print(labelsDic)\n",
    "    #print(img.shape)\n",
    "\n",
    "    mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "    mask[labelsDic['fineInside']] = 1\n",
    "    mask[labelsDic['fineInside2']] = 1\n",
    "    mask[labelsDic['rockInside']] = 1\n",
    "    #mask[labelsDic['inapInside']] = 1\n",
    "    #mask[labelsDic['emptyInside']] = 1\n",
    "\n",
    "\n",
    "\n",
    "    mask.dtype='uint8'\n",
    "    maskOverlay = cv2.cvtColor(mask*255, cv2.COLOR_GRAY2BGR)\n",
    "    maskOverlay[:,:,0] = 0\n",
    "    maskOverlay[:,:,2] = 0\n",
    "\n",
    "\n",
    "    opacity = 0.2\n",
    "    cv2.addWeighted(maskOverlay, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "\n",
    "\n",
    "    mask.dtype='uint8'\n",
    "    cv2.imwrite(croppedMasksPath + fileName, mask)\n",
    "    cv2.imwrite(croppedOverlayedPath + fileName, img)\n",
    "\n",
    "    n += 1\n",
    "\n",
    "print(\"created  \" + str(n) + \"  binary masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# debugging UNET data generation\n",
    "\n",
    "# creating masks for u-net CORRECT (using BGR for labels) with overlay\n",
    "\n",
    "'''\n",
    "croppedImagesPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/images/'\n",
    "croppedLabelsPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/labels/'\n",
    "croppedMasksPath  = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/masks/'\n",
    "croppedOverlayedPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/overlayed/'\n",
    "'''\n",
    "\n",
    "croppedImagesPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/images_fromJira/'\n",
    "croppedLabelsPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/labels_fromJira/'\n",
    "\n",
    "croppedMasksPath  = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/images_frmJira__fullSizeImages_masks/'\n",
    "croppedOverlayedPath = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/images_frmJira__fullSizeImages_overlays/'\n",
    "\n",
    "\n",
    "\n",
    "fileName = '1_20161115-073100_0001n0_11017.png'\n",
    "\n",
    "\n",
    "\n",
    "img = imread(croppedImagesPath + fileName)\n",
    "imgLabel = imread(croppedLabelsPath + fileName)\n",
    "#imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGB2BGR)  This is wrong too\n",
    "imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "\n",
    "labelsDic = {\n",
    "    'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "    'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "\n",
    "    #for V3 with the new labels this is the new fmAppropriate mat\n",
    "    'fineInside2' :np.where(np.all(imgLabel == fineInside2, axis=-1)),\n",
    "\n",
    "    #V2 for Hydraulics U-Net I had the inapInside labels but not for BucyrucAndPnH  for V3 no inapp.\n",
    "    #'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "\n",
    "#    'emptyInside' :np.where(np.all(imgLabel == emptyInside, axis=-1)), bad idea\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "#print(labelsDic)\n",
    "#print(img.shape)\n",
    "\n",
    "mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "mask[labelsDic['fineInside']] = 1\n",
    "mask[labelsDic['fineInside2']] = 1\n",
    "mask[labelsDic['rockInside']] = 1\n",
    "#mask[labelsDic['inapInside']] = 1\n",
    "#mask[labelsDic['emptyInside']] = 1\n",
    "\n",
    "\n",
    "\n",
    "mask.dtype='uint8'\n",
    "maskOverlay = cv2.cvtColor(mask*255, cv2.COLOR_GRAY2BGR)\n",
    "maskOverlay[:,:,0] = 0\n",
    "maskOverlay[:,:,2] = 0\n",
    "\n",
    "\n",
    "opacity = 0.2\n",
    "cv2.addWeighted(maskOverlay, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "\n",
    "\n",
    "mask.dtype='uint8'\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "#cv2.imwrite(croppedMasksPath + fileName, mask)\n",
    "#cv2.imwrite(croppedOverlayedPath + fileName, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating padded images for U-Net\n",
    " 1. Some images are (480, 640, 3)   some are (480, 720, 3) so first we resize them all to (480, 640, 3)\n",
    " \n",
    " 2. Now that all images are 40W*480H, we downsample them by 4 to get 160W*120H. \n",
    "\n",
    " 3. Next, the VES U-Net pads these with 0 making them 162W*130H. But doing that in Keras leads to output being 160*128. So I pad the inputs with 0 to be 160W*128H to begin with.\n",
    " \n",
    " 4. The label input has 6 channels (size 128*160) 5 of them are below:\n",
    "\n",
    "    \"value\": [[\"WM_landmarks\"], [\"Fine_Inside\", \"Rock_inside\"], [\"Teeth\"], [\"Empty\", \"Shadow\", \"Dust\"], [\"Case\"]]\n",
    "\n",
    "    The 6th is background, which is everything that is not these. So in the image, the pixels have above labels are 0 and everything else is a 1. \n",
    "    \n",
    "    \n",
    "    ***Dust and shadow are supposed to be just inside, but there are examples of them outside. I am going to deviate from above in that I won't group [\"Empty\", \"Shadow\", \"Dust\"] just [\"Empty\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Creating the (128, 160, 1) labels \n",
    "generatedMaskPath = '/home/hooman/dataPreparation/hsTestSet/masks0PaddedForUNet/'\n",
    "\n",
    "for fileName in os.listdir(labelsPath):\n",
    "    \n",
    "    label = imread(labelsPath + fileName) \n",
    "    \n",
    "    \n",
    "    \n",
    "    #resize the label map.\n",
    "    imgLabelResized = cv2.resize(label, (640, 480)) \n",
    "\n",
    "    # you can downsample with numpy too. I use opencv to be consistant.    imgDs = img[::4, ::4, :]\n",
    "    imgLabelDs = cv2.resize(imgLabelResized, (0,0), fx=0.25, fy=0.25) \n",
    "\n",
    "    imgLabel = cv2.copyMakeBorder(imgLabelDs,4,4,0,0,cv2.BORDER_CONSTANT,value=(0,0,0,0))\n",
    "    \n",
    "    \n",
    "\n",
    "    mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), int)\n",
    "\n",
    "\n",
    "    labelsDic = {\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'case'       :np.where(np.all(imgLabel == case, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        'dust'       :np.where(np.all(imgLabel == dust, axis=-1)),\n",
    "    }\n",
    "\n",
    "    #channel 1\n",
    "    if 'wmInside' in labelsDic:\n",
    "        mask[labelsDic['wmInside']] = 1\n",
    "\n",
    "\n",
    "    #channel 2\n",
    "    if 'rockInside' in labelsDic:\n",
    "        mask[labelsDic['rockInside']] = 2\n",
    "\n",
    "    if 'fineInside' in labelsDic:\n",
    "        mask[labelsDic['fineInside']] = 2\n",
    "\n",
    "\n",
    "    #channel 3\n",
    "    if 'teeth' in labelsDic:\n",
    "        mask[labelsDic['teeth']] = 3\n",
    "\n",
    "\n",
    "    #channel 4\n",
    "    if 'emptyInside' in labelsDic:\n",
    "        mask[labelsDic['emptyInside']] = 4\n",
    "\n",
    "    if 'shadow' in labelsDic:\n",
    "        mask[labelsDic['shadow']] = 4\n",
    "\n",
    "    if 'dust' in labelsDic:\n",
    "        mask[labelsDic['dust']] = 4\n",
    "\n",
    "\n",
    "    #channel 5\n",
    "    if 'case' in labelsDic:\n",
    "        mask[labelsDic['case']] = 5\n",
    "\n",
    "        \n",
    "    cv2.imwrite(generatedMaskPath + fileName, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Correct Creating the (128, 160, 6) labels \n",
    "generatedMaskPath = '/home/hooman/dataPreparation/hsTrainingSet/masks6Chan/'\n",
    "\n",
    "for fileName in os.listdir(labelsPath):\n",
    "    \n",
    "    label = imread(labelsPath + fileName) \n",
    "    \n",
    "    \n",
    "    \n",
    "    #resize the label map.\n",
    "    imgLabelResized = cv2.resize(label, (640, 480)) \n",
    "\n",
    "    # you can downsample with numpy too. I use opencv to be consistant.    imgDs = img[::4, ::4, :]\n",
    "    imgLabelDs = cv2.resize(imgLabelResized, (0,0), fx=0.25, fy=0.25) \n",
    "\n",
    "    imgLabel = cv2.copyMakeBorder(imgLabelDs,4,4,0,0,cv2.BORDER_CONSTANT,value=(0,0,0,0))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1], 6), bool)\n",
    "\n",
    "    backGroundMask = np.ones((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "\n",
    "    \n",
    "    \n",
    "    labelsDic = {\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'case'       :np.where(np.all(imgLabel == case, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        'dust'       :np.where(np.all(imgLabel == dust, axis=-1)),\n",
    "    }\n",
    "\n",
    "    \n",
    "    \n",
    "    #channel 1\n",
    "    if 'wmInside' in labelsDic:\n",
    "        mask[labelsDic['wmInside'][0], labelsDic['wmInside'][1], 1] = 1\n",
    "        backGroundMask[labelsDic['wmInside']] = 0\n",
    "\n",
    "\n",
    "    #channel 2\n",
    "    if 'rockInside' in labelsDic:\n",
    "        mask[labelsDic['rockInside'][0], labelsDic['rockInside'][1], 2] = 1\n",
    "        backGroundMask[labelsDic['rockInside']] = 0\n",
    "\n",
    "    if 'fineInside' in labelsDic:\n",
    "        mask[labelsDic['fineInside'][0], labelsDic['fineInside'][1], 2] = 1\n",
    "        backGroundMask[labelsDic['fineInside']] = 0\n",
    "\n",
    "\n",
    "    #channel 3\n",
    "    if 'teeth' in labelsDic:\n",
    "        mask[labelsDic['teeth'][0], labelsDic['teeth'][1], 3] = 1\n",
    "        backGroundMask[labelsDic['teeth']] = 0\n",
    "\n",
    "\n",
    "    #channel 4\n",
    "    if 'emptyInside' in labelsDic:\n",
    "        mask[labelsDic['emptyInside'][0], labelsDic['emptyInside'][1], 4] = 1\n",
    "        backGroundMask[labelsDic['emptyInside']] = 0\n",
    "\n",
    "    if 'shadow' in labelsDic:\n",
    "        mask[labelsDic['shadow'][0], labelsDic['shadow'][1], 4] = 1\n",
    "        backGroundMask[labelsDic['shadow']] = 0\n",
    "\n",
    "    if 'dust' in labelsDic:\n",
    "        mask[labelsDic['dust'][0], labelsDic['dust'][1], 4] = 1\n",
    "        backGroundMask[labelsDic['dust']] = 0\n",
    "\n",
    "\n",
    "    #channel 5\n",
    "    if 'case' in labelsDic:\n",
    "        mask[labelsDic['case'][0], labelsDic['case'][1], 5] = 1\n",
    "        backGroundMask[labelsDic['case']] = 0\n",
    "\n",
    "\n",
    "    #channel 0\n",
    "    mask[:,:, 0] = backGroundMask\n",
    "    \n",
    "    \n",
    "    np.save(generatedMaskPath + fileName.replace(\".png\",\"\"), mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlaying Segmentation results for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Overlaying predicted segmentation resutls\n",
    "unet_pathToSavedResults = '/home/hooman/UNet/hsUnet_try13/predicted1chanImages/'\n",
    "testImagesPath = '/home/hooman/dataPreparation/hsTestSet/cropped/croppedImages/'\n",
    "\n",
    "# set this to '' to not save results but desplay the images instead\n",
    "pathToSaveOverlayResults = '/home/hooman/UNet/hsUnet_try13/croppedImagesPredictionsOverlayed/'\n",
    "\n",
    "\n",
    "for imgId in os.listdir(testImagesPath):\n",
    "\n",
    "    img = imread(testImagesPath + imgId)\n",
    "\n",
    "    pred = imread(unet_pathToSavedResults + imgId)\n",
    "    predRes = cv2.resize(pred, (img.shape[1], img.shape[0])) \n",
    "\n",
    "    predCol = cv2.cvtColor(predRes*255, cv2.COLOR_GRAY2BGR)\n",
    "    predCol[:,:,0] = 0\n",
    "    predCol[:,:,2] = 0\n",
    "\n",
    "    \n",
    "    opacity = 0.1\n",
    "    overIm = cv2.addWeighted(predCol, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "    \n",
    "    if pathToSaveOverlayResults != '':\n",
    "        cv2.imwrite(pathToSaveOverlayResults + imgId, overIm)\n",
    "    else:\n",
    "        imshow(overIm)\n",
    "        plt.title('overLayedImage')\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    imgRes = cv2.resize(img, (128, 128)) \n",
    "    imshow(img)\n",
    "    plt.title('img')\n",
    "    plt.show()\n",
    "\n",
    "    imshow(imgRes)\n",
    "    plt.title('imgRes')\n",
    "    plt.show()\n",
    "\n",
    "    imshow(pred)\n",
    "    plt.title('pred')\n",
    "    plt.show()\n",
    "\n",
    "    imshow(predRes)\n",
    "    plt.title('predRes')\n",
    "    plt.show()\n",
    "\n",
    "    imshow(predCol)\n",
    "    plt.title('predCol')\n",
    "    plt.show()\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Overlaying Ground Truth Masks multiple images\n",
    "pathToMasks =  '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCropped_masks/'\n",
    "pathToImages = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCropped_images/'\n",
    "pathToSaveOverlayResults = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCropped_overlay/'\n",
    "\n",
    "\n",
    "for imgId in os.listdir(pathToImages):\n",
    "\n",
    "    img = imread(pathToImages + imgId)\n",
    "    mask = imread(pathToMasks + imgId)\n",
    "\n",
    "    mask.dtype='uint8'\n",
    "    maskOverlay = cv2.cvtColor(mask*255, cv2.COLOR_GRAY2BGR)\n",
    "    maskOverlay[:,:,0] = 0\n",
    "    maskOverlay[:,:,2] = 0\n",
    "\n",
    "\n",
    "    opacity = 0.2\n",
    "    cv2.addWeighted(maskOverlay, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "    \n",
    "\n",
    "    mask.dtype='uint8'\n",
    "    \n",
    "    \n",
    "    cv2.imwrite(pathToSaveOverlayResults + imgId, img)\n",
    "    \n",
    "    #imshow(img)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Overlaying Ground Truth Masks single image\n",
    "\n",
    "pathToMasks = '/home/hooman/dataPreparation/hsTrainingSet/cropped/wrong_croppedMasks/'\n",
    "pathToImages = '/home/hooman/dataPreparation/hsTrainingSet/cropped/croppedImages/'\n",
    "\n",
    "imgId = '1_20161116-155500_0001n0_20737.png'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img = imread(pathToImages + imgId)\n",
    "mask = imread(pathToMasks + imgId)\n",
    "\n",
    "mask.dtype='uint8'\n",
    "maskOverlay = cv2.cvtColor(mask*255, cv2.COLOR_GRAY2BGR)\n",
    "maskOverlay[:,:,0] = 0\n",
    "maskOverlay[:,:,2] = 0\n",
    "\n",
    "\n",
    "opacity = 0.2\n",
    "cv2.addWeighted(maskOverlay, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "\n",
    "\n",
    "mask.dtype='uint8'\n",
    "\n",
    "imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting ROI Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#function checking if two lines intersec\n",
    "\n",
    "def pointsCross(A,B,C):\n",
    "    return (C[1]-A[1]) * (B[0]-A[0]) > (B[1]-A[1]) * (C[0]-A[0])\n",
    "\n",
    "# Return true if line segments AB and CD intersect\n",
    "def linesIntersect(line1, line2):\n",
    "    A = np.array(line1[0])\n",
    "    B = np.array(line1[1])\n",
    "\n",
    "    C = np.array(line2[0])\n",
    "    D = np.array(line2[1])\n",
    "    \n",
    "    return pointsCross(A,C,D) != pointsCross(B,C,D) and pointsCross(A,B,C) != pointsCross(A,B,D)\n",
    "\n",
    "def unitTest():\n",
    "    line1 = ( (0, 10), (10,0) )\n",
    "    line2 = ( (15, 12), (10,10) ) \n",
    "    \n",
    "    line3 = ((89, 256), (112, 479))\n",
    "    line4 = ((104, 439), (134, 430))\n",
    "\n",
    "    assert linesIntersect(line1,line2) == False\n",
    "    assert linesIntersect(line3,line4) == True\n",
    "    \n",
    "unitTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Converting ROI points from ratio to abs and drawing them on image\n",
    "\n",
    "im = cv2.imread('/home/hooman/Downloads/RE__Invalid_FM_ROI/download.jpg')\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "jq = [\n",
    "    (0.1390625,0.5333333333333333),\n",
    "    (0.175,0.9979166666666667),\n",
    "    (0.1625,0.9145833333333333),\n",
    "    (0.209375,0.8958333333333334),\n",
    "    (0.1765625,0.825),\n",
    "    (0.26875,0.7854166666666667),\n",
    "    (0.2421875,0.7020833333333333),\n",
    "    (0.33125,0.6833333333333333),\n",
    "    (0.26875,0.71875),\n",
    "    (0.35,0.7375),\n",
    "    (0.4703125,0.6125),\n",
    "    (0.5265625,0.6145833333333334),\n",
    "    (0.5390625,0.7145833333333333),\n",
    "    (0.503125,0.7208333333333333),\n",
    "    (0.690625,0.825),\n",
    "    (0.6453125,0.8916666666666667),\n",
    "    (0.8328125,0.8604166666666667),\n",
    "    (0.809375,0.5541666666666667),\n",
    "    (0.728125,0.5520833333333334),\n",
    "    (0.6953125,0.47291666666666665),\n",
    "    (0.340625,0.38333333333333336)\n",
    "]\n",
    "\n",
    "\n",
    "jqConv = []\n",
    "for el in jq:\n",
    "    jqConv.append( ((int(el[0]*im.shape[1])),int(el[1]*im.shape[0])) )\n",
    "\n",
    "\n",
    "print(im.shape)\n",
    "print(jqConv)\n",
    "\n",
    "'''\n",
    "for i in range(len(jqConv)-1):\n",
    "    cv2.line(im, jqConv[i], jqConv[i+1], (255,0,0),2)\n",
    "    \n",
    "cv2.line(im, jqConv[len(jqConv)-1], jqConv[0], (255,0,0),2)\n",
    "\n",
    "cv2.imwrite('/home/hooman/Downloads/RE__Invalid_FM_ROI/res.png', im)\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def areSelfIntersecting(boundary_points):\n",
    "    \n",
    "    lines = []\n",
    "\n",
    "    for i in range(len(boundary_points)-1):\n",
    "        newLine = (boundary_points[i], boundary_points[i+1])\n",
    "\n",
    "        for oldLine in lines[:-1]:\n",
    "            if linesIntersect(oldLine, newLine):\n",
    "                return True\n",
    "\n",
    "        lines.append( newLine )\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#don't draw the edge that intersects boundary\n",
    "\n",
    "im = cv2.imread('/home/hooman/Downloads/RE__Invalid_FM_ROI/download.jpg')\n",
    "\n",
    "\n",
    "lines = []\n",
    "for i in range(len(jqConv)):\n",
    "    if i < len(jqConv)-1:\n",
    "        newLine = (jqConv[i], jqConv[i+1])\n",
    "    else:\n",
    "        newLine = (jqConv[len(jqConv)-1], jqConv[0])\n",
    "    \n",
    "    isOk = True\n",
    "    for oldLine in lines[:-1]:\n",
    "        if linesIntersect(oldLine, newLine):\n",
    "            print(i)\n",
    "            isOk = False\n",
    "            \n",
    "    if isOk:\n",
    "        cv2.line(im, newLine[0], newLine[1], (255,0,0),2)\n",
    "        lines.append( newLine )\n",
    "\n",
    "\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areSelfIntersecting(jqConv[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copying, Deleting, renaming, resizing, or changing data formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Resize and downsample all images to (128, 160, 3)\n",
    "resizedImagesPath = '/home/hooman/dataPreparation/hsTestSet/images0PaddedForUNet/'\n",
    "\n",
    "for fileName in os.listdir(imagesPath):\n",
    "\n",
    "    img = imread(imagesPath + fileName) \n",
    "    \n",
    "    imgResized = cv2.resize(img, (640, 480)) \n",
    "\n",
    "    # you can downsample with numpy too. I use opencv to be consistant.    imgDs = img[::4, ::4, :]\n",
    "    imgDs = cv2.resize(imgResized, (0,0), fx=0.25, fy=0.25) \n",
    "\n",
    "    imgPadded = cv2.copyMakeBorder(imgDs,4,4,0,0,cv2.BORDER_CONSTANT,value=(0,0,0))\n",
    "    \n",
    "    cv2.imwrite(resizedImagesPath + fileName, imgPadded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# deleting files that are not in one dir from another\n",
    "fileToKeepDict = {}\n",
    "\n",
    "for fileName in os.listdir('/home/hooman/FM_PROJECT/dataPreparation/newFmdlTestData_latestFrmMahdi/3chansBucandPnH/'):\n",
    "    fileToKeepDict[fileName] = 1\n",
    "\n",
    "\n",
    "    \n",
    "for fileName in os.listdir('/home/hooman/FM_PROJECT/fmdl_algo/tests/BucyrusAndPnH-shovels/testImagesToPass/'):\n",
    "    if fileName not in fileToKeepDict:\n",
    "        print(fileName)\n",
    "        os.remove('/home/hooman/FM_PROJECT/fmdl_algo/tests/BucyrusAndPnH-shovels/testImagesToPass/' + fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# deleting images that cannot be opened (usaully after augmentation)\n",
    "dirToDeleteFrom = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/randomCroppedImages/'\n",
    "\n",
    "for fileName in os.listdir(dirToDeleteFrom):\n",
    "    try:\n",
    "        img = imread(dirToDeleteFrom + fileName)\n",
    "    except:\n",
    "        os.remove(dirToDeleteFrom + fileName)\n",
    "        os.remove('/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/randomCroppedMasks/' + fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# copying files from one dir to another\n",
    "\n",
    "import shutil\n",
    "\n",
    "for imgId in os.listdir('/home/hooman/WM_PROJECT/dataPreparation/hsTrainingData/optical/hydraulics/jiraIssues_BOTH-teethAndWm_OpticalHydraulic/image_brokenDownByShovelType/Chador/imagesWithBadLabels'):\n",
    "    shutil.copy('/home/hooman/WM_PROJECT/dataPreparation/hsTrainingData/optical/hydraulics/jiraIssues_BOTH-teethAndWm_OpticalHydraulic/images_all/' + imgId, '/home/hooman/WM_PROJECT/dataPreparation/hsTrainingData/optical/hydraulics/jiraIssues_BOTH-teethAndWm_OpticalHydraulic/testSet_notIncludedIntrainingSets_imagesWithBadLabels_fromBrokenDownByImageType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Exclusing testSet images from trainingSet for BucketTracking\n",
    "# copying files from one dir to another\n",
    "\n",
    "dirWithListOfimages = \"/media/hooman/hsSsdPartUbuntu/FM_PROJECT/FMDL_3.1/cable/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_cable__try1/goodMatInsides_forBBLabelingOfYolo/\"\n",
    "\n",
    "dir2RemoveFrom = \"/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/cable/fmdl-cable-trainingData/images/\"\n",
    "\n",
    "\n",
    "import shutil\n",
    "\n",
    "movedLabels = []\n",
    "\n",
    "for imgId in os.listdir(dirWithListOfimages):\n",
    "    \n",
    "    movedLabels.append(imgId)\n",
    "\n",
    "    imgName = imgId.replace('.jpg', '.xml')\n",
    "    \n",
    "    \n",
    "    if os.path.isfile(dir2RemoveFrom + imgId):\n",
    "    #if os.path.isfile(dir2RemoveFrom + imgName):\n",
    "    \n",
    "        #shutil.move(dir2RemoveFrom + imgName, '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/cable/validationsSet_hsPicked_labels')\n",
    "        \n",
    "        shutil.copy(dir2RemoveFrom + imgId, '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/FMDL_3.1/cable/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_cable__try1/temp')\n",
    "    \n",
    "        #os.remove(dir2RemoveFrom + imgId)\n",
    "        #os.remove(dir2RemoveFrom + imgName)\n",
    "        print(dir2RemoveFrom + imgName)\n",
    "        \n",
    "    \n",
    "print(\"\")\n",
    "print(\"Moved labels and deleted images for  \" + str(len(movedLabels))  + \"  examples\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Correcting image Ids by content matching singleImage\n",
    "#HSNOTE: this does not work with abs error must be squared.\n",
    "\n",
    "pathToCorrectNames = '/home/hooman/dataPreparation/testingMahdisNetworkOnMyLatestTestSetForComparison/input-orig/'\n",
    "pathToWrongNames   = '/home/hooman/dataPreparation/testingMahdisNetworkOnMyLatestTestSetForComparison/outputOfSaveH5/'\n",
    "pathToWrongPreds = '/home/hooman/dataPreparation/testingMahdisNetworkOnMyLatestTestSetForComparison/ouputOfNetworkJustOutput/'\n",
    "\n",
    "\n",
    "for srcId in os.listdir(pathToWrongNames):\n",
    "\n",
    "    minScore = 100000000\n",
    "    minId = ''\n",
    "    \n",
    "    for targId in os.listdir(pathToCorrectNames):\n",
    "        srcIm = imread(pathToWrongNames + srcId)\n",
    "\n",
    "        temp= imread(pathToCorrectNames + targId)\n",
    "        targIm = cv2.resize(temp, (srcIm.shape[1], srcIm.shape[0])) \n",
    "\n",
    "        dif = np.square((srcIm - targIm))\n",
    "        score = np.sum(dif)\n",
    "\n",
    "        if score < minScore:\n",
    "            minScore = score\n",
    "            minId = targId\n",
    "            \n",
    "\n",
    "    print(\"src: \" + srcId + \"  matched with: \" + minId)\n",
    "    os.rename(pathToWrongNames + srcId, pathToWrongNames + minId)\n",
    "    os.rename(pathToWrongPreds + srcId, pathToWrongPreds + minId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Correcting image Ids by content matching allChannels\n",
    "\n",
    "\n",
    "pathToCorrectNames = '/home/hooman/dataPreparation/testingMahdisNetworkOnMyLatestTestSetForComparison/input-orig/'\n",
    "pathToWrongNames   = '/home/hooman/dataPreparation/testingMahdisNetworkOnMyLatestTestSetForComparison/outputOfSaveH5/'\n",
    "\n",
    "pathToCorrectNamesIn = '/home/hooman/dataPreparation/testingMahdisNetworkOnMyLatestTestSetForComparison/ouputOfNetworkAllChannels/' \n",
    "\n",
    "namesDic = {}\n",
    "for srcId in os.listdir(pathToWrongNames):\n",
    "\n",
    "    minScore = 100000000\n",
    "    minId = ''\n",
    "    \n",
    "    for targId in os.listdir(pathToCorrectNames):\n",
    "        srcIm = imread(pathToWrongNames + srcId)\n",
    "\n",
    "        temp= imread(pathToCorrectNames + targId)\n",
    "        targIm = cv2.resize(temp, (srcIm.shape[1], srcIm.shape[0])) \n",
    "\n",
    "        dif = np.square((srcIm - targIm))\n",
    "        score = np.sum(dif)\n",
    "\n",
    "        if score < minScore:\n",
    "            minScore = score\n",
    "            minId = targId\n",
    "            \n",
    "    print(srcId + \"___\" + minId)\n",
    "    namesDic[srcId] = minId\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import glob\n",
    "\n",
    "for srcId in namesDic.keys():\n",
    "\n",
    "    #print(\"src: \" + srcId + \"  matched with: \" + minId)\n",
    "    \n",
    "    nameAr = srcId.split('_')\n",
    "    nameAr = nameAr[0:2]\n",
    "\n",
    "    shortName = \"\"\n",
    "    for i in range(len(nameAr)):\n",
    "        shortName = shortName + nameAr[i] + '_'\n",
    "\n",
    "    chanFiles = glob.glob1(pathToCorrectNamesIn, shortName + '*')\n",
    "    \n",
    "    for fil in chanFiles:\n",
    "        chan = fil.split('_')[2]\n",
    "        #print(chan)\n",
    "        \n",
    "        if chan[0:2] == \"ch\":\n",
    "            newname = chan + \"_\" + namesDic[srcId]\n",
    "            print(\"renamed CH: \" + fil + \" to: \" + newname + \"\\n\")\n",
    "            os.rename(pathToCorrectNamesIn + fil, pathToCorrectNamesIn + newname)\n",
    "        else:\n",
    "            newname = namesDic[srcId]\n",
    "            print(\"renamed: \" + fil + \" to: \" + newname + \"\\n\")\n",
    "            os.rename(pathToCorrectNamesIn + fil, pathToCorrectNamesIn + namesDic[srcId])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# converting single channel images to 3 channels\n",
    "for imId in os.listdir('/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/cable/temp/'):\n",
    "\n",
    "    img = imread('/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/cable/temp/'+ imId)\n",
    "    if len(img.shape) < 3:\n",
    "        img3Chan = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "        cv2.imwrite('/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/cable/hsTestSetOfHardImages/' + imId, img3Chan)\n",
    "        \n",
    "    else:\n",
    "        print(img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Converting jpg image to png, and removing the jpegs\n",
    "img_dest_dir = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/allImages/'\n",
    "\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "imageFileNameDic = {}\n",
    "\n",
    "for file in os.listdir(img_dest_dir):\n",
    "    fileName = file.replace(\".jpg\", \"\")\n",
    "    #fileName = file.replace(\".png\", \"\")\n",
    "    if fileName in imageFileNameDic:\n",
    "        imageFileNameDic[fileName] += 1\n",
    "    else:\n",
    "        imageFileNameDic[fileName] = 0\n",
    "\n",
    "        \n",
    "        \n",
    "for name in imageFileNameDic.keys():\n",
    "    print(name)\n",
    "    im = Image.open(img_dest_dir + '/' + name + '.jpg')\n",
    "    im.save(img_dest_dir + '/' + name + '.png')\n",
    "    os.remove(img_dest_dir + '/' + name + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# converting single channel images to 3 channels\n",
    "for imId in os.listdir('/media/hooman/New Volume/FM_PROJECT_STORAGE/QC-Tests/backhoe/Telfer_EX010_2/Frame/'):\n",
    "\n",
    "    img = imread('/media/hooman/New Volume/FM_PROJECT_STORAGE/QC-Tests/backhoe/Telfer_EX010_2/Frame/'+ imId)\n",
    "    img3Chan = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    cv2.imwrite('/media/hooman/New Volume/FM_PROJECT_STORAGE/QC-Tests/backhoe/Telfer_EX010_2/3chan/' + imId, img3Chan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# compressing png images with jpeg\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "saveDir = '/home/hooman/FM_PROJECT/dataPreparation/fmdlTestData-optical-hydraulic/compressedJpeg80/'\n",
    "\n",
    "for imId in os.listdir('/home/hooman/FM_PROJECT/dataPreparation/fmdlTestData-optical-hydraulic/Frame/'):\n",
    "    img = Image.open('/home/hooman/FM_PROJECT/dataPreparation/fmdlTestData-optical-hydraulic/Frame/'+ imId)\n",
    "    \n",
    "    fileName = imId.replace(\".png\", \"\")\n",
    "    \n",
    "    img.save(saveDir + '/' + fileName + '.jpg', quality=80,optimize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting legecy fm/wm and fontend stuff to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# converting .GMP to .FMDL\n",
    "import os\n",
    "import glob\n",
    "import base64\n",
    "\n",
    "\n",
    "parentInputPath = \"/home/hooman/Downloads/MOTIONMETRICS/FM/5F016EA0-5D72-10B4-9364-5B61122A98D3/\"\n",
    "\n",
    "outputPath = \"/home/hooman/Downloads/MOTIONMETRICS/FM/temp/\"\n",
    "\n",
    "#for dires in os.listdir(parentInputPath):\n",
    " #   inputPath = parentInputPath + '/' + dires + '/'\n",
    "    \n",
    "    #files = glob.glob(inputPath+'*.gmp')\n",
    "\n",
    "for filename in os.listdir(parentInputPath):\n",
    "\n",
    "    print(filename)\n",
    "\n",
    "    f = open(parentInputPath + filename,'r')\n",
    "\n",
    "    text = f.read()\n",
    "\n",
    "    outFileName = text[text.find(\"filename\")+11:text.find(\"data\") -3]\n",
    "    print(outFileName)\n",
    "\n",
    "    if (text.find(\"FMDL\") > 0) & (text.find(\"FMDL\") < text.find(\"data\")):\n",
    "\n",
    "        img_txt = text[text.find(\"data\")+7:-4];\n",
    "        print(img_txt)\n",
    "\n",
    "        with open(outputPath+outFileName,\"wb\") as ff:\n",
    "\n",
    "            ff.write(base64.b64decode(img_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# YAML to WMDL\n",
    "\n",
    "import glob\n",
    "from base64 import decodestring\n",
    "import base64\n",
    "\n",
    "\n",
    "import zlib\n",
    "import yaml\n",
    "filename = \"C:/Software/Dev/DLWM-20171026-105/resources/CNRL/SH1006/DLWM_reference.yaml\"\n",
    "with open(filename, 'r') as stream:\n",
    "    yamlfile = yaml.load(stream)\n",
    "    \n",
    "stream = open(filename, 'r')\n",
    "\n",
    "import cv2\n",
    "fs_read = cv2.FileStorage(\"D:/temp/test.yml\", cv2.FILE_STORAGE_READ)\n",
    "import yaml\n",
    "filename = \"D:/temp/test.yml\"\n",
    "with open(filename, 'r') as stream:\n",
    "    yamlfile = yaml.load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#WMDL to YAML\n",
    "import glob\n",
    "from base64 import decodestring\n",
    "import base64\n",
    "\n",
    "inputPath = \"C:/Software/Dev/DLWM-20180201/resources/Test/SH7106/CV/input/\"\n",
    "outputPath = \"C:/Software/Dev/DLWM-20180201/resources/Test/SH7106/CV/yaml/\"\n",
    "files = glob.glob(inputPath+'*.wmdl')\n",
    "import zlib  \n",
    "import os\n",
    "for filename in files:\n",
    "    wmdl = open(filename,'rb').read()\n",
    "    wmyaml = zlib.decompress(wmdl)\n",
    "    with open(outputPath+os.path.basename(filename)[:-5]+\".yaml\",\"wb\") as f:\n",
    "        f.write(wmyaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#WMDL GMP            \n",
    "import glob\n",
    "from base64 import decodestring\n",
    "import base64\n",
    "\n",
    "inputPath = \"N:/randd/temp/WMDL_Logs/WMDL_CVE_S20/\"\n",
    "outputPath = \"C:/Software/Dev/DLWM-20180201/resources/CV/SH20/input_2/\"\n",
    "files = glob.glob(inputPath+'*.gmp')\n",
    "for filename in files:\n",
    "    f = open(filename,'r')\n",
    "    text = f.read()\n",
    "    print(text[text.find(\"filename\")+11:text.find(\"data\")])\n",
    "    if (text.find(\"WMDL\") > 0) & (text.find(\"WMDL\") < text.find(\"data\")):\n",
    "        img_txt = text[text.find(\"data\")+7:-4];\n",
    "        with open(outputPath+text[text.find(\"filename\")+11:text.find(\".wmdl\")+5],\"wb\") as f:\n",
    "            f.write(base64.b64decode(img_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# MTDL GMP\n",
    "import glob\n",
    "import base64\n",
    "\n",
    "inputPath = \"N:/temp/MTDL-Sishen/PH03_4100/\"\n",
    "outputPath = \"N:/randd/MachineLearning/Temp/Sishen/PH03_4100/\"\n",
    "files = glob.glob(inputPath+'*.gmp')\n",
    "for filename in files:\n",
    "    f = open(filename,'r')\n",
    "    text = f.read()\n",
    "    if (text.find(\"MTDL-LEGACY\") > 0) & (text.find(\"MTDL-LEGACY\") < text.find(\"data\")):\n",
    "        img_txt = text[text.find(\"data\")+7:-4];\n",
    "        with open(outputPath+text[text.find(\"filename\")+13:text.find(\".jpg\")+4],\"wb\") as f:\n",
    "            f.write(base64.b64decode(img_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up CSVs with bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# shuffling a csv  (adds an empty line somewhere, and moves the header)\n",
    "\n",
    "csvRows = readCsvRows('/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/backhoe/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_backhoe__try1/finalTrainingSet.csv')\n",
    "\n",
    "\n",
    "\n",
    "# shuffle the rows\n",
    "from random import shuffle\n",
    "shuffle(csvRows)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#write the shuffled rows to csv\n",
    "csv_file = open('/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/backhoe/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_backhoe__try1/finalTrainingSet_SHUFFLED.csv', \"w\") \n",
    "\n",
    "\n",
    "# write rows\n",
    "for row in csvRows:\n",
    "    csv_file.write(row + '\\n')\n",
    "\n",
    "csv_file.close()\n",
    "\n",
    "print(\"wrote \" + str(len(csvRows)) + \" rows to csv file\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#read rows from the file you wanna append to\n",
    "existingRowsDic = getCertainClassRowsDictFromCsv('/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try5/trainSet_multiClass_bucket_fineRock_try5_manuallyCleaned.csv', ['matInside'])\n",
    "\n",
    "\n",
    "\n",
    "#read rows from the file you wanna get the new rows from\n",
    "rowsDicToAddFrom = getCertainClassRowsDictFromCsv('/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/unusedCsvFiles/trainSet_multiClass_bucket_fineRockInapp_try3_uncleaned.csv', ['matInside'])\n",
    "\n",
    "\n",
    "\n",
    "#Append the missing rows\n",
    "n = 0\n",
    "rowsDicToAddTo = {}\n",
    "for imId in os.listdir('/home/hooman/dataPreparation/hsTrainingSet/imsToAddMatInsideFor/'):\n",
    "    n += 1\n",
    "    print(imId)\n",
    "    if imId not in existingRowsDic:\n",
    "        if imId in rowsDicToAddFrom:\n",
    "            rowsDicToAddTo[imId] = rowsDicToAddFrom[imId]\n",
    "        else:\n",
    "            print(\"error didn't find:  \" + imId + \"\\n\")\n",
    "    else:\n",
    "        print(\"already there\\n\")\n",
    "\n",
    "print(\"processed \" + str(n) + \" rows\")\n",
    "\n",
    "writeRowDicToCsv(rowsDicToAddTo, '/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try4/trainSet_multiClass_bucket_fineRock_try4_manuallyCleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# delete images from csv\n",
    "imIdsToDelete = os.listdir('/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/cable/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_cable__try1/examplesToRemove/')\n",
    "\n",
    "csvToWorkWith = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/cable/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_cable__try1/firstTry_final.csv'\n",
    "\n",
    "\n",
    "existingRows = readCsvRows(csvToWorkWith)\n",
    "\n",
    "n1 = 0\n",
    "for row in existingRows:\n",
    "    vals = row.split(',')\n",
    "\n",
    "    if vals[0] not in imIdsToDelete:\n",
    "        existingRows.remove(row)\n",
    "        n1 += 1\n",
    "        \n",
    "print(\"in the first run deleted \" + str(n1) +' rows\\n')\n",
    "\n",
    "n2 = 0\n",
    "for row in existingRows:\n",
    "    vals = row.split(',')\n",
    "\n",
    "    if vals[0] not in imIdsToDelete:\n",
    "        existingRows.remove(row)\n",
    "        n2 += 1\n",
    "        \n",
    "print(\"in the second run deleted \" + str(n2) +' rows\\n')\n",
    "print(\"deleted \" + str(n1+n2) + \" rows in total\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# open the file\n",
    "csv_file = open(csvToWorkWith, \"w\") \n",
    "\n",
    "# define column names\n",
    "columnTitles = \"filename,pathname,xmins,xmax,ymins,ymax,class\\n\"\n",
    "csv_file.write(columnTitles)\n",
    "\n",
    "# write rows\n",
    "for r in existingRows:\n",
    "    row = r + '\\n'\n",
    "    csv_file.write(row)\n",
    "\n",
    "csv_file.close()\n",
    "\n",
    "print(\"wrote \" + str(len(existingRows)) + \" rows to csv file\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# add no bucket rows to existing csv and shuffle its rows\n",
    "\n",
    "csvRows = readCsvRows('/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try5/trainSet_multiClass_bucket_fineRock_try5_manuallyCleaned.csv')\n",
    "\n",
    "#getRid of the empty row at the end\n",
    "csvRows = csvRows[0:len(csvRows)-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# add the no bucket rows for the images in dir\n",
    "for imId in os.listdir('/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try6/noShovelImagesToAdd/'):\n",
    "    newRow = str(str(imId) + ',' + str(imagesPath) + str(imId) + ',' + '' + ',' + '' + ',' + '' + ',' + '' + ',' + '')\n",
    "    print(newRow)\n",
    "    \n",
    "    csvRows.append(newRow)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# shuffle the rows\n",
    "from random import shuffle\n",
    "shuffle(csvRows)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#write the shuffled rows to csv\n",
    "csv_file = open('/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try5/trainSet_multiClass_bucket_fineRock_try5_manuallyCleaned_new.csv', \"w\") \n",
    "\n",
    "\n",
    "# write rows\n",
    "for row in csvRows:\n",
    "    csv_file.write(row + '\\n')\n",
    "\n",
    "csv_file.close()\n",
    "\n",
    "print(\"wrote \" + str(len(csvRows)) + \" rows to csv file\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# remove matInsideBoundary rows from CSV\n",
    "\n",
    "rowsDic = getCertainClassRowsDictFromCsv('/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/trainSet_bucketAndMatInsideBoundaries_allImages_BucAndPnH_cleaned.csv', ['bucket'])\n",
    "\n",
    "writeRowDicToCsv(rowsDic, '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/trainSet_justBucketBoundaries_allImages_BucAndPnH_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Converting existing network CSVs to out csv format\n",
    "\n",
    "The CSVs produced by the existing networks provide the topLeft cornor's x value, yvalu, a width, and a height. This must be converted to the format used by us which provides top left and bottom right cornors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existNetRows = readCsvRows(\"/home/hooman/resultsFromExistingNetwork/testSetFregmentationResults/output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "existNetRowsDict = {}\n",
    "for row in existNetRows[0:60]:\n",
    "    vals = row.split(',')\n",
    "    existNetRowsDict[vals[0]] = vals[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_rows = readCsvRows(\"/home/hooman/dataPreparation/testSet_noBbxImagesIncluded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#write rows\n",
    "rows = []\n",
    "for row in gt_rows[1:len(gt_rows)-1]:\n",
    "    vals = row.split(',')\n",
    "    fileName = vals[0]\n",
    "    filePath = imagesPath + fileName\n",
    "    print(\"processing file:\\n\", filePath)\n",
    "    \n",
    "    if fileName in existNetRowsDict:\n",
    "        topx, topy, width, height = existNetRowsDict[fileName]\n",
    "\n",
    "        (topx, topy, width, height) = (int(round(float(topx))), int(round(float(topy))), int(round(float(width))), int(round(float(height)))) \n",
    "\n",
    "        xmin = topx\n",
    "        xmax = topx + width\n",
    "        ymin = topy\n",
    "        ymax = topy + height\n",
    "        \n",
    "        row = fileName + \",\" + filePath + \",\" + str(xmin) +\",\"+ str(xmax) + \",\" + str(ymin) + \",\" + str(ymax) + \",\" + \"bucket\" + \"\\n\"\n",
    "        \n",
    "    else:\n",
    "        row = fileName + \",\" + filePath + \",\" + \"\" +\",\"+ \"\" + \",\" + \"\" + \",\" + \"\" + \",\" + \"bucket\" + \"\\n\"\n",
    "        print(\"Found no bucket boundary\\n\")\n",
    "        \n",
    "    rows.append(row)\n",
    "    \n",
    "print(\"processes \"+ str(len(rows)) + \" rows\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeRowsToCsv(rows, \"/home/hooman/resultsFromExistingNetwork/testSetFregmentationResults/testSetOutputConverted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting .pdn files to .png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#converting .pdn (dot net) to pnd\n",
    "\n",
    "import pypdn\n",
    "\n",
    "pdnsDir = \"/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/pdnLabels/\"\n",
    "finalDir = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/regen/'\n",
    "\n",
    "#fileName = '1_20161115-222501_0001n0_16697.pdn'\n",
    "for fileName in os.listdir(pdnsDir):\n",
    "\n",
    "    #read the layer info\n",
    "    layeredImage = pypdn.read(pdnsDir + fileName)\n",
    "    #print(layeredImage)\n",
    "\n",
    "\n",
    "    #make the background invisible\n",
    "    layer = layeredImage.layers[0]\n",
    "    layer.visible = False\n",
    "\n",
    "\n",
    "    #Combine the layers into a numpy image\n",
    "    flatImage = layeredImage.flatten(asByte=True)\n",
    "\n",
    "    #plt.figure()\n",
    "    #plt.imshow(flatImage)\n",
    "    #plt.show()\n",
    "\n",
    "    newFileName = fileName.replace('.pdn', '.png')\n",
    "    cv2.imwrite(finalDir + newFileName, flatImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FM-Cloud presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Showing Images side-by-side\n",
    "\n",
    "\n",
    "#predsDir1 = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/try0-AnuarConfigs/image_hard_pickedByHs_predicted_Anuars_model/'\n",
    "\n",
    "predsDir1 = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/try5-NewTrainingProcedure--higherBatchSize/preds_onBackgroundImages/'\n",
    "\n",
    "\n",
    "predsDir2 = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/try11_sameAs5_afterDataCorrections/preds_onBackground/'\n",
    "\n",
    "dirToSaveResults = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/try11_sameAs5_afterDataCorrections/combined_try5Vs11_backgroundImages/'\n",
    "\n",
    "for imgId in os.listdir(predsDir1):\n",
    "    #hsPred = imread(hsPredsDir + imgId)\n",
    "    #temp = imread(vesPredsDir + imgId)\n",
    "    #vesPred = img3Chan = cv2.cvtColor(temp, cv2.COLOR_GRAY2BGR) \n",
    "    \n",
    "    pred1 = imread(predsDir1 + imgId)\n",
    "    pred2 = imread(predsDir2 + imgId)\n",
    "\n",
    "    combImg = np.zeros((pred1.shape[0],1400, 3), np.uint8)\n",
    "\n",
    "    combImg[:, 0:pred1.shape[1], :] = pred1\n",
    "    combImg[:, 700:pred2.shape[1]+700, :] = pred2\n",
    "    \n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(combImg,'try5',(30,70), font, 2,(255,255,255), 2, 0)\n",
    "    cv2.putText(combImg,'try11',(730,70), font, 2,(255,255,255), 2, 0)\n",
    "    \n",
    "    #plt.imshow(combImg)\n",
    "    #plt.show()\n",
    "    #break\n",
    "    \n",
    "    cv2.imwrite(dirToSaveResults + imgId, combImg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Showing Images side-by-side 1280\n",
    "\n",
    "\n",
    "#predsDir1 = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/try0-AnuarConfigs/image_hard_pickedByHs_predicted_Anuars_model/'\n",
    "\n",
    "predsDir1 = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/try5-NewTrainingProcedure--higherBatchSize/preds_onBackgroundImages/'\n",
    "\n",
    "\n",
    "predsDir2 = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/try11_sameAs5_afterDataCorrections/preds_onBackground/'\n",
    "\n",
    "dirToSaveResults = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/try11_sameAs5_afterDataCorrections/combined_try5Vs11_backgroundImages/'\n",
    "\n",
    "for imgId in os.listdir(predsDir1):\n",
    "    #hsPred = imread(hsPredsDir + imgId)\n",
    "    #temp = imread(vesPredsDir + imgId)\n",
    "    #vesPred = img3Chan = cv2.cvtColor(temp, cv2.COLOR_GRAY2BGR) \n",
    "    \n",
    "    pred1 = imread(predsDir1 + imgId)\n",
    "    pred2 = imread(predsDir2 + imgId)\n",
    "\n",
    "    combImg = np.zeros((pred1.shape[0],2560, 3), np.uint8)\n",
    "\n",
    "    combImg[:, 0:pred1.shape[1], :] = pred1\n",
    "    combImg[:, 1280:pred2.shape[1]+1280, :] = pred2\n",
    "    \n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(combImg,'try5',(30,70), font, 2,(255,255,255), 2, 0)\n",
    "    cv2.putText(combImg,'try11',(730,70), font, 2,(255,255,255), 2, 0)\n",
    "    \n",
    "    #plt.imshow(combImg)\n",
    "    #plt.show()\n",
    "    #break\n",
    "    \n",
    "    cv2.imwrite(dirToSaveResults + imgId, combImg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Putting the optical flow and U-Net outputs sidebyside.  \n",
    "\n",
    "#FMDL_2018.04.30_11.38.09.png\n",
    "\n",
    "temp = imread('/home/hooman/dataPreparation/fmdlTestData-optical-hydraulic/Frame/' + 'FMDL_2018.04.30_11.38.09.png')\n",
    "\n",
    "frame = cv2.cvtColor(temp, cv2.COLOR_GRAY2BGR) \n",
    "\n",
    "plt.imshow(frame)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "of = imread('/home/hooman/dataPreparation/fmdlTestData-optical-hydraulic/OpticalFlowMagnitude/' + 'FMDL_2018.04.30_11.38.09.png')\n",
    "\n",
    "plt.imshow(of)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "no = imread('/home/hooman/dataPreparation/fmdlTestData-optical-hydraulic/NetOut/' + 'FMDL_2018.04.30_11.38.09.png')\n",
    "\n",
    "plt.imshow(no)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "temp2 = imread('/home/hooman/dataPreparation/fmdlTestData-optical-hydraulic/VES_finalOutput/fragmentation_results/all/' + 'FMDL_2018.04.30_11.38.09.png')\n",
    "\n",
    "fo = cv2.cvtColor(temp2, cv2.COLOR_GRAY2BGR) \n",
    "\n",
    "plt.imshow(fo)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(np.amax(of))\n",
    "\n",
    "\n",
    "combImg = np.zeros((frame.shape[0],2800, 3), np.uint8)\n",
    "\n",
    "combImg[:, 0:frame.shape[1], :] = frame\n",
    "combImg[:, 700:frame.shape[1]+700, :] = cv2.resize(cv2.cvtColor(of, cv2.COLOR_GRAY2BGR), (frame.shape[1], frame.shape[0])) \n",
    "combImg[:, 1400:frame.shape[1]+1400, :] = cv2.resize(cv2.cvtColor(no, cv2.COLOR_GRAY2BGR), (frame.shape[1], frame.shape[0])) \n",
    "combImg[:, 2100:fo.shape[1]+2100, :] = fo\n",
    "\n",
    "\n",
    "plt.imshow(combImg)\n",
    "plt.show()\n",
    "cv2.imwrite('/home/hooman/' + 'combined_FMDL_2018.04.30_11.38.09.png', combImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading data from H5 \n",
    "### look at the visalizing_h5 notebook in  \n",
    "/home/hooman/randd/MachineLearning/TeamMembers/Hooman/doNotDelete_thisIsThe_onlyCopy/WM_PROJECT_hsVersion_Backup/WM_PROJECT/dataPreparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generatign FM-FrameSelection Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Generatign FM-FrameSelection Plots\n",
    "\n",
    "allFramesDir = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/frameSelection/try7_t40b10_0,150,200,125,1,outSideImageObjRemoved/allFrames_1004_ESP_S04_017/'\n",
    "\n",
    "bufferedFramesDir = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/frameSelection/try7_t40b10_0,150,200,125,1,outSideImageObjRemoved/bufferedFrames_1004_ESP_S04_017/'\n",
    "\n",
    "selectedFramesDir = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/frameSelection/try7_t40b10_0,150,200,125,1,outSideImageObjRemoved/selectedFrames_1004_ESP_S04_017/'\n",
    "\n",
    "vidName = '1004_ESP_S04_017_fmSelection.png'\n",
    "\n",
    "savePath = '/media/hooman/1tb-ssd-hs3-linu/BucketTracking-Project/hydraulic/frameSelection/try7_t40b10_0,150,200,125,1,outSideImageObjRemoved/'\n",
    "\n",
    "allFrames = []\n",
    "for imName in os.listdir(allFramesDir):\n",
    "    allFrames.append(int(imName.split('_')[-1][:-4]))\n",
    "    \n",
    "allFrames.sort()\n",
    "\n",
    "\n",
    "\n",
    "bufferedFrames = []\n",
    "for imName in os.listdir(bufferedFramesDir):\n",
    "    bufferedFrames.append(int(imName.split('_')[-1][:-4]))\n",
    "    \n",
    "bufferedFrames.sort()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "selectedFrames = []\n",
    "for imName in os.listdir(selectedFramesDir):\n",
    "    selectedFrames.append(int(imName.split('_')[-1][:-4]))\n",
    "    \n",
    "selectedFrames.sort()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30,5))\n",
    "ax = plt.axes()\n",
    "loc = plticker.MultipleLocator(base=1800.0)\n",
    "ax.xaxis.set_major_locator(loc)\n",
    "ax.grid()\n",
    "\n",
    "plt.plot(allFrames, len(allFrames) * [0], label='received')\n",
    "plt.plot(bufferedFrames, len(bufferedFrames) * [0.2], 'bo', label='buffered')\n",
    "plt.plot(selectedFrames, len(selectedFrames) * [0.5], 'go', label='selected')\n",
    "plt.ylabel('buffered=Blue,  Selected=Green')\n",
    "plt.xlabel('frameNumber(1 minute tick)')\n",
    "\n",
    "\n",
    "plt.savefig(savePath + vidName)\n",
    "plt.legend('best')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "\n",
    "hsDic = {'received': len(allFrames), 'buffered':len(bufferedFrames), 'selected':len(selectedFrames)}\n",
    "plt.bar(hsDic.keys(), hsDic.values(), color='g')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backhoe Shovels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. creating box detector training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getAllBoundaries_backhoe(imgLabel, img=[]):\n",
    "    \n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        'emptyInside' :np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'case' :np.where(np.all(imgLabel == case, axis=-1)),\n",
    "        'teeth' :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'bucketOutside':np.where(np.all(imgLabel == bucketOutside, axis=-1)),\n",
    "        'sheave': np.where(np.all(imgLabel == sheave, axis=-1)),\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "  \n",
    "    \n",
    "    ##############################################\n",
    "    ############## Bucket Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    for labV in sortedLabelColsDic.values():\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    for labV in sortedLabelRowsDic.values():\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "\n",
    "    \n",
    "\n",
    "    #get the bucket boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0 : \n",
    "\n",
    "        (bucket_xmin, bucket_xmax, bucket_ymin, bucket_ymax) = (xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1])\n",
    "        \n",
    "        \n",
    "        croppedIm = imgLabel[0:bucket_xmax, bucket_ymin:bucket_ymax]\n",
    "        \n",
    "        #plt.imshow(croppedIm)\n",
    "        #plt.show()\n",
    "        \n",
    "        labelsDic2 = {\n",
    "            'rockInside' :np.where(np.all(croppedIm == rockInside, axis=-1)),\n",
    "            \n",
    "            'fineInside' :np.where(np.all(croppedIm == fineInside, axis=-1)),\n",
    "            \n",
    "            'fmInapp' :np.where(np.all(croppedIm == fmInapp, axis=-1)),\n",
    "            'inapInside' :np.where(np.all(croppedIm == inapInside, axis=-1)),   \n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "        #get the boundary for each label\n",
    "        sortedLabelColsDic = {}\n",
    "        sortedLabelRowsDic = {}\n",
    "        for k in labelsDic2.keys():\n",
    "            if len(labelsDic2[k][0]) > 0:\n",
    "                sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic2[k][0]),\n",
    "                sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic2[k][1]),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ##############################################\n",
    "        ############## matInside Boundary ###############\n",
    "        ##############################################\n",
    "        #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "        lowColVals = []\n",
    "        highColVals = []\n",
    "        for labV in sortedLabelColsDic.values():\n",
    "            for v in labV:\n",
    "                lowColVals.append(v[0])\n",
    "                highColVals.append(v[len(v)-1])\n",
    "\n",
    "        lowRowVals = []\n",
    "        highRowVals = []\n",
    "        for labV in sortedLabelRowsDic.values():\n",
    "            for v in labV:\n",
    "                lowRowVals.append(v[0])\n",
    "                highRowVals.append(v[len(v)-1])\n",
    "\n",
    "\n",
    "\n",
    "        #get the bucket boundary\n",
    "        xmins2 = np.sort(np.array(lowColVals))\n",
    "        xmaxs2 = np.sort(np.array(highColVals))\n",
    "        ymins2 = np.sort(np.array(lowRowVals))\n",
    "        ymaxs2 = np.sort(np.array(highRowVals))\n",
    "\n",
    "        if len(xmins2) > 0 and len(xmaxs2) > 0 and len(ymins2) > 0 and len(ymaxs2) > 0 : \n",
    "            boundariesDict['matInside'] = [xmins2[0], xmaxs2[len(xmaxs2)-1], ymins2[0] + bucket_ymin, ymaxs2[len(ymaxs2)-1] + bucket_ymin]\n",
    "        \n",
    "            #if bucket_xmin > xmins[0]:\n",
    "                #bucket_xmin = xmins[0]\n",
    "        \n",
    "        boundariesDict['bucket'] = [bucket_xmin, bucket_xmax, bucket_ymin, bucket_ymax]\n",
    "        \n",
    "        \n",
    "        if len(img) > 0:\n",
    "            cv2.rectangle(img,(bucket_ymin, bucket_xmin),(bucket_ymax, bucket_xmax),(0,255,255),3)\n",
    "            \n",
    "            if 'matInside' in boundariesDict:\n",
    "                (xmin, xmax, ymin, ymax) = boundariesDict['matInside']\n",
    "                cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,0,255),3)\n",
    "\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "        \n",
    "               \n",
    "\n",
    "\n",
    "\n",
    "        return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getAllBoundaries_backhoe_V2(imgLabel, img=[]):\n",
    "    \n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        'emptyInside' :np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'case' :np.where(np.all(imgLabel == case, axis=-1)),\n",
    "        'teeth' :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'bucketOutside':np.where(np.all(imgLabel == bucketOutside, axis=-1)),\n",
    "        'sheave': np.where(np.all(imgLabel == sheave, axis=-1)),\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "  \n",
    "    \n",
    "    ##############################################\n",
    "    ############## Bucket Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    for labV in sortedLabelColsDic.values():\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    for labV in sortedLabelRowsDic.values():\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "   # print(sortedLabelColsDic)\n",
    "\n",
    "    \n",
    "\n",
    "    #get the bucket boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0 : \n",
    "\n",
    "        (bucket_xmin, bucket_xmax, bucket_ymin, bucket_ymax) = (xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1])\n",
    "        \n",
    "        \n",
    "        if 'bucketOutsideCols' in sortedLabelColsDic:\n",
    "            \n",
    "           # print(sortedLabelColsDic['bucketOutsideCols'][0])\n",
    "            sortedBackOfShovelCols = np.sort(np.array(sortedLabelColsDic['bucketOutsideCols'][0]))\n",
    "            backOfBucketMinX = sortedBackOfShovelCols[0]\n",
    "            backOfBucketMaxX = sortedBackOfShovelCols[len(sortedBackOfShovelCols)-1]\n",
    "            \n",
    "            newMaxX = int( backOfBucketMinX + (backOfBucketMaxX - backOfBucketMinX)/2 )\n",
    "            \n",
    "            croppedIm = imgLabel[0:newMaxX, bucket_ymin:bucket_ymax]\n",
    "            \n",
    "            \n",
    "        if 'teethCols' in sortedLabelColsDic:\n",
    "            \n",
    "           # print(sortedLabelColsDic['bucketOutsideCols'][0])\n",
    "            sortedTeethCols = np.sort(np.array(sortedLabelColsDic['teethCols'][0]))\n",
    "            teethMinX = sortedTeethCols[0]\n",
    "            teethMaxX = sortedTeethCols[len(sortedTeethCols)-1]\n",
    "            \n",
    "            newMaxX = int( teethMinX + (teethMaxX - teethMinX)/2 )\n",
    "            \n",
    "            croppedIm = imgLabel[0:newMaxX, bucket_ymin:bucket_ymax]\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            croppedIm = imgLabel[0:bucket_xmax, bucket_ymin:bucket_ymax]\n",
    "        \n",
    "        #plt.imshow(croppedIm)\n",
    "        #plt.show()\n",
    "        \n",
    "        labelsDic2 = {\n",
    "            'rockInside' :np.where(np.all(croppedIm == rockInside, axis=-1)),\n",
    "            \n",
    "            'fineInside' :np.where(np.all(croppedIm == fineInside, axis=-1)),\n",
    "            \n",
    "            'fmInapp' :np.where(np.all(croppedIm == fmInapp, axis=-1)),\n",
    "            'inapInside' :np.where(np.all(croppedIm == inapInside, axis=-1)), \n",
    "            'shadow' :np.where(np.all(croppedIm == shadow, axis=-1)), \n",
    "            \n",
    "        }\n",
    "        \n",
    "        \n",
    "        #print(labelsDic2)\n",
    "\n",
    "\n",
    "\n",
    "        #get the boundary for each label\n",
    "        sortedLabelColsDic = {}\n",
    "        sortedLabelRowsDic = {}\n",
    "        for k in labelsDic2.keys():\n",
    "            if len(labelsDic2[k][0]) > 0:\n",
    "                sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic2[k][0]),\n",
    "                sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic2[k][1]),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ##############################################\n",
    "        ############## matInside Boundary ###############\n",
    "        ##############################################\n",
    "        #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "        lowColVals = []\n",
    "        highColVals = []\n",
    "        for labV in sortedLabelColsDic.values():\n",
    "            for v in labV:\n",
    "                lowColVals.append(v[0])\n",
    "                highColVals.append(v[len(v)-1])\n",
    "\n",
    "        lowRowVals = []\n",
    "        highRowVals = []\n",
    "        for labV in sortedLabelRowsDic.values():\n",
    "            for v in labV:\n",
    "                lowRowVals.append(v[0])\n",
    "                highRowVals.append(v[len(v)-1])\n",
    "\n",
    "\n",
    "\n",
    "        #get the bucket boundary\n",
    "        xmins2 = np.sort(np.array(lowColVals))\n",
    "        xmaxs2 = np.sort(np.array(highColVals))\n",
    "        ymins2 = np.sort(np.array(lowRowVals))\n",
    "        ymaxs2 = np.sort(np.array(highRowVals))\n",
    "\n",
    "        if len(xmins2) > 0 and len(xmaxs2) > 0 and len(ymins2) > 0 and len(ymaxs2) > 0 : \n",
    "            boundariesDict['matInside'] = [xmins2[0], xmaxs2[len(xmaxs2)-1], ymins2[0] + bucket_ymin, ymaxs2[len(ymaxs2)-1] + bucket_ymin]\n",
    "        \n",
    "            #if bucket_xmin > xmins[0]:\n",
    "                #bucket_xmin = xmins[0]\n",
    "                \n",
    "                \n",
    "            if bucket_xmin > xmins2[0]:\n",
    "                bucket_xmin = xmins2[0]\n",
    "        \n",
    "        boundariesDict['bucket'] = [bucket_xmin, bucket_xmax, bucket_ymin, bucket_ymax]\n",
    "        \n",
    "        \n",
    "        if len(img) > 0:\n",
    "            cv2.rectangle(img,(bucket_ymin, bucket_xmin),(bucket_ymax, bucket_xmax),(0,255,255),3)\n",
    "            \n",
    "            if 'matInside' in boundariesDict:\n",
    "                (xmin, xmax, ymin, ymax) = boundariesDict['matInside']\n",
    "                cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(0,0,255),3)\n",
    "\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "        \n",
    "               \n",
    "\n",
    "\n",
    "\n",
    "        return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Finding matInside and bucket boundaries. For Backhoe\n",
    "rows = []\n",
    "\n",
    "#for fileName in os.listdir(labelsPath):\n",
    "for fileName in os.listdir('/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/backhoe/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_backhoe__try1/validationSet/'):\n",
    "    \n",
    "    imgFilePath = imagesPath + fileName\n",
    "    \n",
    "    imgLabel = imread(labelsPath + fileName)\n",
    "    \n",
    "    #I added this for try3  ssd-multiclass-tries 1 and 2 didnt have this.\n",
    "    imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "    \n",
    "    print(\"processing file: \" + fileName)\n",
    "    \n",
    "    \n",
    "    #I used this for most images in training FMDL3.1 except the some cases where the inside material is defined by back of bucket. But the V2 should work with everything\n",
    "    allBoundaries = getAllBoundaries_backhoe(imgLabel)\n",
    "    \n",
    "    #Tried this for all reprocesseds.\n",
    "    #allBoundaries = getAllBoundaries_backhoe_V2(imgLabel)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if allBoundaries:\n",
    "        if('bucket' in allBoundaries):\n",
    "            # write up the rows\n",
    "            (xmin, xmax, ymin, ymax) = allBoundaries['bucket']\n",
    "            row = fileName + \",\" + imgFilePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"bucket\" + \"\\n\"\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "        else:\n",
    "            print(\"ERROR: Found no bucket boundary.\\n\")\n",
    "\n",
    "\n",
    "\n",
    "        if('matInside' in allBoundaries):\n",
    "            if len(allBoundaries['matInside']) == 4:\n",
    "                (xmin, xmax, ymin, ymax) = allBoundaries['matInside']\n",
    "                row = fileName + \",\" + imgFilePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"matInside\" + \"\\n\"\n",
    "            else:\n",
    "                print(\"ERROR: Found more than one matInside Boundaries. This should NOT happen\\n\")\n",
    "\n",
    "            rows.append(row)        \n",
    "\n",
    "    \n",
    "        \n",
    "# shuffle the rows\n",
    "#from random import shuffle\n",
    "#shuffle(rows)       \n",
    "        \n",
    "#print(\"processes \"+ str(len(rows)) + \" rows\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeRowsToCsv(rows, \"/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/backhoe/boxDetector_V2_multiclass_Cable/try1/dataFor__boxDetector_V2_multiclass_backhoe__try1/negetiveExamplesForTraining.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# (singleImage for Debug) Finding matInside and bucket boundaries. For Backhoe\n",
    "\n",
    "#fileName = '1_20180703-100000_1001n0_23970.png'\n",
    "#fileName = '1_20180704-200300_1001n0_9159.png'\n",
    "#fileName = '1_20180703-101500_1001n0_2971.png'\n",
    "#fileName = '1_20180703-103000_1001n0_8378.png'\n",
    "#fileName = '1_20180704-084800_1001n0_694.png'\n",
    "fileName = '1_20180703-213900_1001n0_1725.png'\n",
    "    \n",
    "imgFilePath = imagesPath + fileName\n",
    "\n",
    "imgLabel = imread(labelsPath + fileName)\n",
    "img = imread(imagesPath + fileName)\n",
    "\n",
    "#I added this for try3  ssd-multiclass-tries 1 and 2 didnt have this.\n",
    "imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "print(\"processing file: \" + fileName)\n",
    "\n",
    "allBoundaries = getAllBoundaries_backhoe_V2(imgLabel, img)\n",
    "rows = [] \n",
    "\n",
    "if allBoundaries:\n",
    "    if('bucket' in allBoundaries):\n",
    "        # write up the rows\n",
    "        (xmin, xmax, ymin, ymax) = allBoundaries['bucket']\n",
    "        row = fileName + \",\" + imgFilePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"bucket\" + \"\\n\"\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    else:\n",
    "        print(\"ERROR: Found no bucket boundary.\\n\")\n",
    "\n",
    "\n",
    "    if('matInside' in allBoundaries):\n",
    "        if len(allBoundaries['matInside']) == 4:\n",
    "            (xmin, xmax, ymin, ymax) = allBoundaries['matInside']\n",
    "            \n",
    "            row = fileName + \",\" + imgFilePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"matInside\" + \"\\n\"\n",
    "        else:\n",
    "            print(\"ERROR: Found more than one matInside Boundaries. This should NOT happen\\n\")\n",
    "\n",
    "        rows.append(row)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. creating roi delineator training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#creating full size masks\n",
    "\n",
    "imagesPath = '/home/hooman/backhoeOpticalScene/roiDelineators/try4-csvFrom-ssdTry3-withInapp-reducedNumberOfempyBuckets-BatchSize4/images/'\n",
    "labelsPath = '/home/hooman/backhoeOpticalScene/roiDelineators/try4-csvFrom-ssdTry3-withInapp-reducedNumberOfempyBuckets-BatchSize4/labels/'\n",
    "\n",
    "masksSavePath = '/home/hooman/backhoeOpticalScene/roiDelineators/try4-csvFrom-ssdTry3-withInapp-reducedNumberOfempyBuckets-BatchSize4/full-masks_withInapp/'\n",
    "\n",
    "overlaySavePath = '/home/hooman/backhoeOpticalScene/roiDelineators/try4-csvFrom-ssdTry3-withInapp-reducedNumberOfempyBuckets-BatchSize4/full-overlays_withInapp/'\n",
    "\n",
    "\n",
    "for fileName in os.listdir('/home/hooman/backhoeOpticalScene/roiDelineators/try4-csvFrom-ssdTry3-withInapp-reducedNumberOfempyBuckets-BatchSize4/negImagesRemoved_croppedOverlayOfMasks/'):\n",
    "\n",
    "    print(\"prcessing imgId: \" + fileName + \"\\n\")\n",
    "\n",
    "    #read the image from csv row\n",
    "    img = imread(imagesPath + fileName)\n",
    "    \n",
    "    imgLabel = imread(labelsPath + fileName)\n",
    "    imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "\n",
    "    #Create a mas from cropped image\n",
    "    labelsDic = {\n",
    "        'rockInside' : np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' : np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'fmInapp'    : np.where(np.all(imgLabel == fmInapp, axis=-1)),\n",
    "    }\n",
    "\n",
    "\n",
    "    mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "    mask2 = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "    mask.dtype='uint8'\n",
    "    mask2.dtype='uint8'\n",
    "\n",
    "    mask[labelsDic['fineInside']] = 1\n",
    "    mask[labelsDic['rockInside']] = 1\n",
    "    mask[labelsDic['fmInapp']] = 1\n",
    "\n",
    "\n",
    "\n",
    "    #Remove the points that are not in the largest contour from mask\n",
    "    _,contours,_ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE, offset=(0, 0))\n",
    "\n",
    "    if contours:\n",
    "        max_cnt = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # cv2.drawContours(mask2, max_cnt, -1, 1, cv2.FILLED, 8) thos does NOT fill up the inside of contour\n",
    "        cv2.drawContours(mask2, [max_cnt], -1, 1, cv2.FILLED, 8)\n",
    "\n",
    "\n",
    "    #if no contours found, mask2 will remain as all 0s\n",
    "    cv2.imwrite(masksSavePath + fileName, mask2)\n",
    "\n",
    "\n",
    "    #get the overlay\n",
    "    maskOverlay = cv2.cvtColor(mask2*255, cv2.COLOR_GRAY2BGR)\n",
    "    maskOverlay[:,:,0] = 0\n",
    "    maskOverlay[:,:,2] = 0\n",
    "\n",
    "    opacity = 0.2\n",
    "    cv2.addWeighted(maskOverlay, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "    cv2.imwrite(overlaySavePath + fileName, img)\n",
    "\n",
    "\n",
    "    '''        \n",
    "    plt.imshow(mask)\n",
    "    plt.title('mask1')\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(mask2)\n",
    "    plt.title('mask2 final')\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.title('overlayed img')\n",
    "    plt.show()\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_rows = readCsvRows(\"/home/hooman/backhoeOpticalScene/boxDetectors/try3_ssdMultiClass_withInappInMatInside_upsideDownShovelsRemoved/fineAndRockAndInapInMatInside_backhoe_shuffled_UpsideDownShovelsRemoved.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# random crop the FULL masks create above. You need FULL images and Masks here not cropped. \n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "offsetsToApply = [50,75, 100, 125, 150, 175]\n",
    "\n",
    "dirToSaveImages = '/home/hooman/backhoeOpticalScene/roiDelineators/try4-csvFrom-ssdTry3-withInapp-reducedNumberOfempyBuckets-BatchSize4/randomCroppedImages/'\n",
    "\n",
    "dirToSaveMasks = '/home/hooman/backhoeOpticalScene/roiDelineators/try4-csvFrom-ssdTry3-withInapp-reducedNumberOfempyBuckets-BatchSize4/randomCroppedMasks/'\n",
    "\n",
    "\n",
    "dirToReadImages = '/home/hooman/backhoeOpticalScene/roiDelineators/try4-csvFrom-ssdTry3-withInapp-reducedNumberOfempyBuckets-BatchSize4/images/'\n",
    "\n",
    "dirToReadMasks = '/home/hooman/backhoeOpticalScene/roiDelineators/try4-csvFrom-ssdTry3-withInapp-reducedNumberOfempyBuckets-BatchSize4/full-masks_withInapp/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for row in gt_rows[1:len(gt_rows)-1]:\n",
    "    \n",
    "    vals = row.split(',')\n",
    "\n",
    "    if os.path.exists(dirToReadImages + vals[0]) and os.path.exists(dirToReadMasks + vals[0]):\n",
    "        \n",
    "        try:\n",
    "            imgPil = Image.open(dirToReadImages + vals[0])\n",
    "            img = np.array(imgPil) \n",
    "            imgPil.close()\n",
    "\n",
    "            labelPil = Image.open(dirToReadMasks + vals[0])\n",
    "            label = np.array(labelPil)\n",
    "            labelPil.close()\n",
    "\n",
    "\n",
    "\n",
    "            xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "            if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "                (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "\n",
    "                imgWidth = img.shape[1]\n",
    "                imgHeight = img.shape[0]\n",
    "\n",
    "\n",
    "                imgAct = img[ymin:ymax, xmin:xmax,]\n",
    "                labelAct = label[ymin:ymax, xmin:xmax]\n",
    "\n",
    "                if imgAct.shape[0] > 0 and imgAct.shape[1] > 0 and labelAct.shape[0] > 0 and labelAct.shape[1] > 0: \n",
    "                    cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '_RCAct.png'), imgAct)\n",
    "                    cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '_RCAct.png'), labelAct)\n",
    "\n",
    "\n",
    "\n",
    "                for offset in offsetsToApply:\n",
    "\n",
    "                    img1 =     img[ymin + offset:ymax + offset, xmin:xmax]\n",
    "                    label1 = label[ymin + offset:ymax + offset, xmin:xmax]\n",
    "\n",
    "                    if img1.shape[0] > 0 and img1.shape[1] > 0 and label1.shape[0] > 0 and label1.shape[1] > 0: \n",
    "                        cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_1.png', img1)\n",
    "                        cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_1.png', label1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    img2 =     img[ymin:ymax, xmin + offset:xmax + offset]\n",
    "                    label2 = label[ymin:ymax, xmin + offset:xmax + offset]\n",
    "\n",
    "                    if img2.shape[0] > 0 and img2.shape[1] > 0 and label2.shape[0] > 0 and label2.shape[1] > 0: \n",
    "                        cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_2.png', img2)\n",
    "                        cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_2.png', label2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    if (ymin - offset) > 0:\n",
    "                        img3 =     img[ymin - offset:ymax - offset, xmin:xmax]\n",
    "                        label3 = label[ymin - offset:ymax - offset, xmin:xmax]\n",
    "\n",
    "                        if img3.shape[0] > 0 and img3.shape[1] > 0 and label3.shape[0] > 0 and label3.shape[1] > 0: \n",
    "                            cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_3.png', img3)\n",
    "                            cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_3.png', label3)\n",
    "\n",
    "\n",
    "\n",
    "                    if (xmin - offset) > 0:\n",
    "                        img4 =     img[ymin:ymax, xmin - offset:xmax - offset]\n",
    "                        label4 = label[ymin:ymax, xmin - offset:xmax - offset]\n",
    "\n",
    "                        if img4.shape[0] > 0 and img4.shape[1] > 0 and label4.shape[0] > 0 and label4.shape[1] > 0: \n",
    "\n",
    "                            cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_4.png', img4)\n",
    "                            cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_4.png', label4)\n",
    "        \n",
    "        except:\n",
    "            print(\"coud not open file: \" + vals[0] + \"\\n\")\n",
    "\n",
    "    else:\n",
    "        print(\"one of the provided directories doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Performance for Bucket Boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 Create binary masks from predictions:\n",
    "    \n",
    "    # read the prediction results from csv\n",
    "    rows = readCsvRows(\"/home/hooman/dataPreparation/testSet_noBbxImagesIncluded.csv\")\n",
    "    \n",
    "    #produce binary masks\n",
    "    for row in rows[1:]:\n",
    "        getBbxMask(row, True, gtMaskPath)\n",
    "        \n",
    "#### Step 2 Load the predictions csv and the testSet csv using readCsvRows method (according to above)\n",
    "#### Step 3 Call the calcPerformance method providing it with the predicted and gt rows, and the paths to where the binary masks are stored.\n",
    "\n",
    "    Example: \n",
    "    _,_,_,_ = calcPerformance(pred_rows[1:len(pred_rows)-1], gt_rows[1:len(gt_rows)-1], \"/home/hooman/mobileNet_try2/result_defaultParams/predictedBbMasks/\", gtMaskPath)\n",
    "\n",
    " ####  <font color='red'>Note that: </font>  \n",
    "1. There is a slash required at the end of paths. \n",
    "2. When you provide the rows to the calcPerformance function, make sure you index in a way that the first, and last rows in the csv are igoned. This is because when you use the readCsvRows function the first row takes column headers and the last row contains an empty line.\n",
    "\n",
    "3. If your gt and prediction csv's do not match you need to create a dictionary for your predictions and suply that aswell. \n",
    "        existNetRowsDict = {}\n",
    "        for row in pred_rows[1:60]:\n",
    "            vals = row.split(',')\n",
    "            existNetRowsDict[vals[0]] = vals[1:5]\n",
    "            \n",
    "4. The call then becomes:<br>\n",
    "           _,_,_,_ = calcPerformance(pred_rows[1:len(pred_rows)-1], gt_rows[1:len(gt_rows)-1],  \"/home/hooman/resultsFromExistingNetwork/testSetFregmentationResults/predictedBinMasks/\", gtMaskPath, predictedRowDict=existNetRowsDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_rows = readCsvRows(\"/home/hooman/dataPreparation/testSet_noBbxImagesIncluded_singleClass_bucketBound_NoTeeth_NoCase.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rows = readCsvRows(\"/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try1/result_minScore09_ckpt-72237/result_minScore09_ckpt-72237.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_,_ = calcPerformance(pred_rows[1:len(pred_rows)-1], gt_rows[1:len(gt_rows)-1],  \"/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try1/result_minScore09_ckpt-72237/predictedBbMasks/\", gtMaskPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Binary Bounding Box Masks\n",
    "These are needed to quickly calcualte True/False Positives/Negetives using metrix multiplication of masks.\n",
    "You can visualize the generated binary masks using:\n",
    "\n",
    "\n",
    "\n",
    "    for row in rows[1:]:\n",
    "        m = getBbxMask(row, False, \"/home/hooman/mobileNet_try2/result_defaultParams/predictedBbMasks/\", True)\n",
    "        plt.imshow(m)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = readCsvRows(\"/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try1/result_defaultParams_ckpt-72237/result_defaultParams_ckpt-72237.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "for row in rows[1:len(rows)-1]:\n",
    "    getBbxMask(row, True, \"/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try1/result_defaultParams_ckpt-72237/predictedBbMasks/\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Augmentation using imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Get and resize train images and masks (same as in unet notebook except just one image)\n",
    "TRAIN_PATH = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameNetworkAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/finalTrainingSet_images_fullSize/'\n",
    "\n",
    "MASK_PATH  = '/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameNetworkAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/finalTrainingSet_masks_fullSize/'\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "train_ids = os.listdir(TRAIN_PATH)\n",
    "train_ids = train_ids[4:6]\n",
    "\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "\n",
    "for n, fileName in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    img = imread(TRAIN_PATH + fileName)[:,:,:IMG_CHANNELS]\n",
    "    \n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    \n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    \n",
    "    mask_ = imread(MASK_PATH + fileName )\n",
    "\n",
    "    #expand dim just converts the (h,w,) image to (h,w,1) look at above for experimentation with np.expand_dim\n",
    "    mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                  preserve_range=True), axis=-1)\n",
    "\n",
    "    #hs this in effect adds all the masks together into one mask of the same size.Since masks are bindary.\n",
    "    mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Check if the data we just loaded looks all right\n",
    "ix = 0\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# library's example of mask augmentation\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "ia.seed(1)\n",
    "\n",
    "\n",
    "image = X_train[0]\n",
    "segmap = Y_train[0]\n",
    "segmap = ia.SegmentationMapOnImage(segmap, shape=image.shape, nb_classes=1+1)\n",
    "\n",
    "# Define our augmentation pipeline.\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Dropout([0.05, 0.2]),      # drop 5% or 20% of all pixels\n",
    "    iaa.Sharpen((0.0, 1.0)),       # sharpen the image\n",
    "    iaa.Affine(rotate=(-45, 45)),  # rotate by -45 to 45 degrees (affects heatmaps)\n",
    "    iaa.ElasticTransformation(alpha=50, sigma=5)  # apply water effect (affects heatmaps)\n",
    "], random_order=True)\n",
    "\n",
    "# Augment images and heatmaps.\n",
    "images_aug = []\n",
    "segmaps_aug = []\n",
    "for _ in range(5):\n",
    "    seq_det = seq.to_deterministic()\n",
    "    images_aug.append(seq_det.augment_image(image))\n",
    "    segmaps_aug.append(seq_det.augment_segmentation_maps([segmap])[0])\n",
    "\n",
    "# We want to generate an image of original input images and heatmaps before/after augmentation.\n",
    "# It is supposed to have five columns: (1) original image, (2) augmented image,\n",
    "# (3) augmented heatmap on top of augmented image, (4) augmented heatmap on its own in jet\n",
    "# color map, (5) augmented heatmap on its own in intensity colormap,\n",
    "# We now generate the cells of these columns.\n",
    "#\n",
    "# Note that we add a [0] after each heatmap draw command. That's because the heatmaps object\n",
    "# can contain many sub-heatmaps and hence we draw command returns a list of drawn sub-heatmaps.\n",
    "# We only used one sub-heatmap, so our lists always have one entry.\n",
    "cells = []\n",
    "for image_aug, segmap_aug in zip(images_aug, segmaps_aug):\n",
    "    cells.append(image)                                      # column 1\n",
    "    cells.append(segmap.draw_on_image(image))                # column 2\n",
    "    cells.append(image_aug)                                  # column 3\n",
    "    cells.append(segmap_aug.draw_on_image(image_aug))        # column 4\n",
    "    cells.append(segmap_aug.draw(size=image_aug.shape[:2]))  # column 5\n",
    "\n",
    "# Convert cells to grid image and save.\n",
    "grid_image = ia.draw_grid(cells, cols=5)\n",
    "imageio.imwrite(\"/home/hooman/sdc1Storage/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameNetworkAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/example_segmaps.jpg\", grid_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Hs example of mask augmentation\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "ia.seed(1)\n",
    "\n",
    "\n",
    "image = X_train[1]\n",
    "segmap = Y_train[1]\n",
    "segmap = ia.SegmentationMapOnImage(segmap, shape=image.shape, nb_classes=1+1)\n",
    "\n",
    "\n",
    "\n",
    "X_train_final_augmented = []\n",
    "Y_train_final_augmented= []\n",
    "\n",
    "\n",
    "cropAug = iaa.Sequential([\n",
    "    iaa.CropAndPad(\n",
    "    percent=(-0.3, 0.3),\n",
    "    pad_mode=[\"edge\"]),\n",
    "], random_order=False)\n",
    "\n",
    "\n",
    "scaleAug = iaa.Sequential([\n",
    "    iaa.Scale((0.5, 1.0)),\n",
    "], random_order=False)\n",
    "\n",
    "\n",
    "rotateAug = iaa.Sometimes(0.5, iaa.Affine(rotate=(-10, 10)))\n",
    "\n",
    "dropOutAug = iaa.Sometimes(0.5, iaa.Dropout([0.05, 0.1]))\n",
    "\n",
    "pixelValAddAug = iaa.Sometimes(0.5, iaa.Add((-40,40)))\n",
    "\n",
    "sharpenAug = iaa.Sometimes(0.2, iaa.Sharpen(alpha=(0.05, 0.2)))\n",
    "\n",
    "contrastNormAug = iaa.Sometimes(0.2, iaa.ContrastNormalization((0.5, 1.5)))\n",
    "\n",
    "\n",
    "    \n",
    "# X translation\n",
    "augResIm = iaa.Affine(translate_px={\"x\":-5}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"x\":-5}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "augResIm = iaa.Affine(translate_px={\"x\":-10}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"x\":-10}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "   \n",
    "augResIm = iaa.Affine(translate_px={\"x\":-15}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"x\":-15}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "augResIm = iaa.Affine(translate_px={\"x\":5}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"x\":5}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "   \n",
    "    \n",
    "augResIm = iaa.Affine(translate_px={\"x\":10}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"x\":10}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "augResIm = iaa.Affine(translate_px={\"x\":15}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"x\":15}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "\n",
    "# Y translation\n",
    "augResIm = iaa.Affine(translate_px={\"y\":5}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"y\":5}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "augResIm = iaa.Affine(translate_px={\"y\":10}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"y\":10}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "augResIm = iaa.Affine(translate_px={\"y\":15}).augment_image(image)\n",
    "augResMask = iaa.Affine(translate_px={\"y\":15}).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "#horizantal flip\n",
    "augResIm = iaa.Fliplr(1).augment_image(image)\n",
    "augResMask = iaa.Fliplr(1).augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "    \n",
    "#Random crop\n",
    "cropAug_det = cropAug.to_deterministic()\n",
    "augResIm = cropAug_det.augment_image(image)\n",
    "augResMask = cropAug_det.augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "\n",
    "#Random rotate or elastically transform\n",
    "rotateAug_det = rotateAug.to_deterministic()\n",
    "augResIm = rotateAug_det.augment_image(image)\n",
    "augResMask = rotateAug_det.augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "#drop some pixels at random 50% of the time\n",
    "dropOutAug_det = dropOutAug.to_deterministic()\n",
    "augResIm = dropOutAug_det.augment_image(image)\n",
    "augResMask = dropOutAug_det.augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "# add rand nb between -40,40 to some pixels 50% of the time \n",
    "pixelValAddAug_det = pixelValAddAug.to_deterministic()\n",
    "augResIm = pixelValAddAug_det.augment_image(image)\n",
    "augResMask = pixelValAddAug_det.augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "#sharpen images 20% of the time\n",
    "sharpenAug_det = sharpenAug.to_deterministic()\n",
    "augResIm = sharpenAug_det.augment_image(image)\n",
    "augResMask = sharpenAug_det.augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "#contrastNorm images 20% of the time\n",
    "contrastNormAug_det = contrastNormAug.to_deterministic()\n",
    "augResIm = contrastNormAug_det.augment_image(image)\n",
    "augResMask = contrastNormAug_det.augment_segmentation_maps([segmap])[0]\n",
    "X_train_final_augmented.append(augResIm)\n",
    "segmaps_aug.append(augResMask.get_arr_int()[...,np.newaxis].astype(np.bool))\n",
    "\n",
    "\n",
    "cells = []\n",
    "for image_aug, segmap_aug in zip(X_train_final_augmented, segmaps_aug):\n",
    "    imshow(image_aug)\n",
    "    plt.show()\n",
    "    imshow(np.squeeze(segmap_aug))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# hs list of all augmentations I've looked at\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Dropout([0.0, 0.2]),\n",
    "    iaa.Add((-40,40)),\n",
    "    iaa.AddElementwise((-10, 10)),\n",
    "    iaa.AdditiveGaussianNoise(scale=0.1*255),\n",
    "    iaa.GaussianBlur(sigma=1.0),\n",
    "    iaa.Sharpen(alpha=0.2),\n",
    "    iaa.ElasticTransformation(alpha=50, sigma=5),\n",
    "    iaa.Scale((0.5, 1.0)),\n",
    "    iaa.CropAndPad(\n",
    "    percent=(-0.3, 0.3),\n",
    "    pad_mode=[\"constant\"],\n",
    "    pad_cval=(0, 128)),\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.ContrastNormalization((0.5, 1.5)),\n",
    "    iaa.Affine(rotate=(-10, 10)),  # rotate by -10 to 10 degrees (affects heatmaps)\n",
    "    iaa.Affine(translate_px={\"x\":-5}),\n",
    "    iaa.Affine(translate_px={\"x\":-10}),\n",
    "    iaa.Affine(translate_px={\"x\":-15}),\n",
    "    iaa.Affine(translate_px={\"x\":5}),\n",
    "    iaa.Affine(translate_px={\"x\":10}),\n",
    "    iaa.Affine(translate_px={\"x\":15}),\n",
    "    iaa.Affine(translate_px={\"y\":5}),\n",
    "    iaa.Affine(translate_px={\"y\":10}),\n",
    "    iaa.Affine(translate_px={\"y\":15}),\n",
    "], random_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating performance for only the images that the existing networks can find bucket boundaries in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_rows = readCsvRows(\"/home/hooman/dataPreparation/testSet_noBbxImagesIncluded_singleClass_bucketBound_NoTeeth_NoCase.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_rows = readCsvRows(\"/home/hooman/resultsFromExistingNetwork/testSetFregmentationResults/testSetOutputConverted_noBoundariesRemoved.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rows = readCsvRows(\"/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try1/result_minScore09_ckpt-72237/result_minScore09_ckpt-72237.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     7
    ]
   },
   "outputs": [],
   "source": [
    "#Get PredictRowDictionary\n",
    "predDict = {}\n",
    "for row in pred_rows[1:255]:\n",
    "    vals = row.split(',')\n",
    "    predDict[vals[0]] = vals[2:6]\n",
    "    \n",
    "existNetRowsFromPredDict = {}\n",
    "for row in ex_rows[1:61]:\n",
    "    vals = row.split(',')\n",
    "    existNetRowsFromPredDict[vals[0]] = predDict[vals[0]]\n",
    "    \n",
    "print(\"preDict has: \" + str(len(predDict)) + \" rows\")\n",
    "print(\"existNetRowsFromPredDict has: \" + str(len(existNetRowsFromPredDict)) + \" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_,_ = calcPerformance(pred_rows[1:len(pred_rows)-1], gt_rows[1:len(gt_rows)-1], \"/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try1/result_minScore09_ckpt-72237/predictedBbMasks/\", gtMaskPath, predictedRowDict=existNetRowsFromPredDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_,_ = calcPerformance(pred_rows[1:len(pred_rows)-1], gt_rows[1:len(gt_rows)-1],  \"/home/hooman/ssdMobileNet_multiClass_bucket_rockInside_FineInside_NoTeeth_NoCase/try1/result_defaultParams_ckpt-72237/predictedBbMasks/\", gtMaskPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Performance for inside Bucket Delineations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# loading and displaying saved single channel U-Net resutls\n",
    "unet_pathToSavedResults = '/home/hooman/UNet/vesUnet_try1/predicted6chanImages/'\n",
    "unet_pathTo1ChanLabels = '/home/hooman/dataPreparation/hsTestSet/masks0PaddedForUNet/'\n",
    "unet_pathToTestImages = '/home/hooman/dataPreparation/hsTestSet/images0PaddedForUNet/'\n",
    "\n",
    "for imgId in os.listdir(unet_pathToTestImages):\n",
    "    \n",
    "    img = imread(unet_pathToTestImages + imgId)\n",
    "    label = imread(unet_pathTo1ChanLabels + imgId)\n",
    "    pred = imread(unet_pathToSavedResults + imgId)\n",
    "    \n",
    "    \n",
    "    imshow(img)\n",
    "    plt.title('image')\n",
    "    plt.show()\n",
    "        \n",
    "    imshow(label)\n",
    "    plt.title('label')\n",
    "    plt.show()\n",
    "    \n",
    "    imshow(pred)\n",
    "    plt.title('pred')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_,_ = calcPerformance_insideBucket_multiClass('/home/hooman/UNet/hsUnet_try2/predicted6chanImages_cropped/', '/home/hooman/dataPreparation/hsTestSet/cropped/croppedMasks_resized128-160/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# calculating performance for hsUNet style singleClass\n",
    "unet_pathToSavedResults = '/home/hooman/UNet/hsUnet_try14/predicted1chanImages/'\n",
    "unet_pathTo1ChanLabelsMasks = '/home/hooman/dataPreparation/hsTestSet/cropped/28by28Masks/croppedMask_withInapp_mistakesRemoved/'\n",
    "verbose = False\n",
    "\n",
    "\n",
    "total_tn = 0\n",
    "total_tp = 0\n",
    "total_fn = 0\n",
    "total_fp = 0\n",
    "\n",
    "rowCount = 0\n",
    "\n",
    "\n",
    "for imgId in os.listdir(unet_pathTo1ChanLabelsMasks):\n",
    "    \n",
    "    label = imread(unet_pathTo1ChanLabelsMasks + imgId)\n",
    "    pred = imread(unet_pathToSavedResults + imgId)\n",
    "\n",
    "    labelMask = label.astype(bool)\n",
    "    predMask = pred.astype(bool)\n",
    "\n",
    "\n",
    "    pos_preds = np.where(predMask == 1)\n",
    "    neg_preds = np.where(predMask == 0)\n",
    "\n",
    "    pos_overlap = predMask * labelMask\n",
    "    neg_overlap = np.logical_not(predMask) * np.logical_not(labelMask)\n",
    "\n",
    "\n",
    "    if verbose==True:\n",
    "        imshow(label)\n",
    "        plt.title('label')\n",
    "        plt.show()\n",
    "\n",
    "        imshow(labelMask)\n",
    "        plt.title('labelMask')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        imshow(pred)\n",
    "        plt.title('pred')\n",
    "        plt.show()\n",
    "\n",
    "        imshow(predMask)\n",
    "        plt.title('pred')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    tp = np.count_nonzero(pos_overlap)\n",
    "    tn = np.count_nonzero(neg_overlap)\n",
    "    fp = len(pos_preds[0]) - tp\n",
    "    fn = len(neg_preds[0]) - tn\n",
    "\n",
    "    total_fp += fp\n",
    "    total_fn += fn\n",
    "    total_tp += tp\n",
    "    total_tn += tn\n",
    "\n",
    "    rowCount += 1\n",
    "\n",
    "\n",
    "\n",
    "sensitivity = float(total_tp) / (total_tp + total_fn)\n",
    "specificity = float(total_tn) / (total_tn + total_fp)\n",
    "precision = float(total_tp) / (total_tp + total_fp)\n",
    "f_score = 2 * precision * sensitivity / (precision + sensitivity)\n",
    "\n",
    "print(\"-Sensitivity: \" + str(sensitivity) +\n",
    "      \" ,    -Specificity: \" + str(specificity) +\n",
    "      \" ,    -Precision: \" + str(precision) +\n",
    "      \" ,    -F_score: \" + str(f_score)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# calculating performance for multi-class predictions using single class labels    \n",
    "unet_pathToSavedResults = '/home/hooman/UNet/vesUnet_try1/predicted6chanImages_cropped/'\n",
    "unet_pathTo1ChanLabels = '/home/hooman/dataPreparation/hsTestSet/cropped/croppedMasks_resized128-160/'\n",
    "verbose = False\n",
    "\n",
    "\n",
    "total_tn = 0\n",
    "total_tp = 0\n",
    "total_fn = 0\n",
    "total_fp = 0\n",
    "\n",
    "rowCount = 0\n",
    "\n",
    "\n",
    "for imgId in os.listdir(unet_pathTo1ChanLabels):\n",
    "    \n",
    "    label = imread(unet_pathTo1ChanLabels + imgId)\n",
    "    labelMask = label.astype(bool)\n",
    "    \n",
    "    \n",
    "    pred = imread(unet_pathToSavedResults + imgId)\n",
    "    predMask = np.zeros((pred.shape[0], pred.shape[1]), bool)\n",
    "    predPixels = np.where(pred == 2)\n",
    "    predMask[predPixels] = 1\n",
    "\n",
    "\n",
    "    pos_preds = np.where(predMask == 1)\n",
    "    neg_preds = np.where(predMask == 0)\n",
    "\n",
    "    pos_overlap = predMask * labelMask\n",
    "    neg_overlap = np.logical_not(predMask) * np.logical_not(labelMask)\n",
    "\n",
    "\n",
    "    if verbose==True:\n",
    "        imshow(label)\n",
    "        plt.title('label')\n",
    "        plt.show()\n",
    "\n",
    "        imshow(labelMask)\n",
    "        plt.title('labelMask')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        imshow(pred)\n",
    "        plt.title('pred')\n",
    "        plt.show()\n",
    "\n",
    "        imshow(predMask)\n",
    "        plt.title('pred')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    tp = np.count_nonzero(pos_overlap)\n",
    "    tn = np.count_nonzero(neg_overlap)\n",
    "    fp = len(pos_preds[0]) - tp\n",
    "    fn = len(neg_preds[0]) - tn\n",
    "\n",
    "    total_fp += fp\n",
    "    total_fn += fn\n",
    "    total_tp += tp\n",
    "    total_tn += tn\n",
    "\n",
    "    rowCount += 1\n",
    "\n",
    "\n",
    "\n",
    "sensitivity = float(total_tp) / (total_tp + total_fn)\n",
    "specificity = float(total_tn) / (total_tn + total_fp)\n",
    "precision = float(total_tp) / (total_tp + total_fp)\n",
    "f_score = 2 * precision * sensitivity / (precision + sensitivity)\n",
    "\n",
    "print(\"-Sensitivity: \" + str(sensitivity) +\n",
    "      \" ,    -Specificity: \" + str(specificity) +\n",
    "      \" ,    -Precision: \" + str(precision) +\n",
    "      \" ,    -F_score: \" + str(f_score)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'> Sandbox Area (DO NOT DELETE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Hs example of mask augmentation on several images\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "ia.seed(1)\n",
    "\n",
    "\n",
    "\n",
    "images_aug = []\n",
    "segmaps_aug = []\n",
    "\n",
    "\n",
    "cropAug = iaa.Sequential([\n",
    "    iaa.CropAndPad(\n",
    "    percent=(-0.3, 0.3),\n",
    "    pad_mode=[\"edge\"]),\n",
    "], random_order=False)\n",
    "\n",
    "\n",
    "scaleAug = iaa.Sequential([\n",
    "    iaa.Scale((0.5, 1.0)),\n",
    "], random_order=False)\n",
    "\n",
    "\n",
    "rotateAug = iaa.Sometimes(0.5, iaa.Affine(rotate=(-10, 10)))\n",
    "\n",
    "dropOutAug = iaa.Sometimes(0.5, iaa.Dropout([0.05, 0.1]))\n",
    "\n",
    "pixelValAddAug = iaa.Sometimes(0.5, iaa.Add((-40,40)))\n",
    "\n",
    "sharpenAug = iaa.Sometimes(0.2, iaa.Sharpen(alpha=(0.05, 0.2)))\n",
    "\n",
    "contrastNormAug = iaa.Sometimes(0.2, iaa.ContrastNormalization((0.5, 1.5)))\n",
    "\n",
    "\n",
    "\n",
    "for n, fileName in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    image = X_train[n]\n",
    "    segmap = Y_train[n]\n",
    "    segmap = ia.SegmentationMapOnImage(segmap, shape=image.shape, nb_classes=1+1)\n",
    "    \n",
    "    \n",
    "    #add original images too\n",
    "    \n",
    "\n",
    "    \n",
    "    # X translation\n",
    "    images_aug.append(iaa.Affine(translate_px={\"x\":-5}).augment_image(image))\n",
    "    segmaps_aug.append(iaa.Affine(translate_px={\"x\":-5}).augment_segmentation_maps([segmap])[0])\n",
    "\n",
    "    images_aug.append(iaa.Affine(translate_px={\"x\":-10}).augment_image(image))\n",
    "    segmaps_aug.append(iaa.Affine(translate_px={\"x\":-10}).augment_segmentation_maps([segmap])[0])\n",
    "\n",
    "\n",
    "    images_aug.append(iaa.Affine(translate_px={\"x\":-15}).augment_image(image))\n",
    "    segmaps_aug.append(iaa.Affine(translate_px={\"x\":-15}).augment_segmentation_maps([segmap])[0])\n",
    "\n",
    "    images_aug.append(iaa.Affine(translate_px={\"x\":5}).augment_image(image))\n",
    "    segmaps_aug.append(iaa.Affine(translate_px={\"x\":5}).augment_segmentation_maps([segmap])[0])\n",
    "\n",
    "    images_aug.append(iaa.Affine(translate_px={\"x\":10}).augment_image(image))\n",
    "    segmaps_aug.append(iaa.Affine(translate_px={\"x\":10}).augment_segmentation_maps([segmap])[0])\n",
    "\n",
    "    images_aug.append(iaa.Affine(translate_px={\"x\":15}).augment_image(image))\n",
    "    segmaps_aug.append(iaa.Affine(translate_px={\"x\":15}).augment_segmentation_maps([segmap])[0])\n",
    "\n",
    "\n",
    "\n",
    "    # Y translation\n",
    "    images_aug.append(iaa.Affine(translate_px={\"y\":5}).augment_image(image))\n",
    "    segmaps_aug.append(iaa.Affine(translate_px={\"y\":5}).augment_segmentation_maps([segmap])[0])\n",
    "\n",
    "    images_aug.append(iaa.Affine(translate_px={\"y\":10}).augment_image(image))\n",
    "    segmaps_aug.append(iaa.Affine(translate_px={\"y\":10}).augment_segmentation_maps([segmap])[0])\n",
    "\n",
    "    images_aug.append(iaa.Affine(translate_px={\"y\":15}).augment_image(image))\n",
    "    segmaps_aug.append(iaa.Affine(translate_px={\"y\":15}).augment_segmentation_maps([segmap])[0])\n",
    "\n",
    "\n",
    "    #horizantal flip\n",
    "    images_aug.append(iaa.Fliplr(1).augment_image(image))\n",
    "    segmaps_aug.append(iaa.Fliplr(1).augment_segmentation_maps([segmap])[0])\n",
    "\n",
    "\n",
    "    #Random crop\n",
    "    cropAug_det = cropAug.to_deterministic()\n",
    "    images_aug.append(cropAug_det.augment_image(image))\n",
    "    segmaps_aug.append(cropAug_det.augment_segmentation_maps([segmap])[0])\n",
    "\n",
    "\n",
    "\n",
    "    #Random rotate or elastically transform\n",
    "    rotateAug_det = rotateAug.to_deterministic()\n",
    "    images_aug.append(rotateAug_det.augment_image(image))\n",
    "    segmaps_aug.append(rotateAug_det.augment_segmentation_maps([segmap])[0])\n",
    "\n",
    "\n",
    "    #drop some pixels at random 50% of the time\n",
    "    dropOutAug_det = dropOutAug.to_deterministic()\n",
    "    images_aug.append(dropOutAug_det.augment_image(image))\n",
    "    segmaps_aug.append(dropOutAug_det.augment_segmentation_maps([segmap])[0])\n",
    "\n",
    "\n",
    "    # add rand nb between -40,40 to some pixels 50% of the time \n",
    "    pixelValAddAug_det = pixelValAddAug.to_deterministic()\n",
    "    images_aug.append(pixelValAddAug_det.augment_image(image))\n",
    "    segmaps_aug.append(pixelValAddAug_det.augment_segmentation_maps([segmap])[0])\n",
    "\n",
    "\n",
    "    #sharpen images 20% of the time\n",
    "    sharpenAug_det = sharpenAug.to_deterministic()\n",
    "    images_aug.append(sharpenAug_det.augment_image(image))\n",
    "    segmaps_aug.append(sharpenAug_det.augment_segmentation_maps([segmap])[0])\n",
    "\n",
    "\n",
    "    #contrastNorm images 20% of the time\n",
    "    contrastNormAug_det = contrastNormAug.to_deterministic()\n",
    "    images_aug.append(contrastNormAug_det.augment_image(image))\n",
    "    segmaps_aug.append(contrastNormAug_det.augment_segmentation_maps([segmap])[0])\n",
    "\n",
    "\n",
    "cells = []\n",
    "for image_aug, segmap_aug in zip(images_aug, segmaps_aug):\n",
    "    cells.append(segmap_aug.draw_on_image(image_aug))        # column 4\n",
    "    \n",
    "# Convert cells to grid image and save.\n",
    "grid_image = ia.draw_grid(cells, cols=1)\n",
    "imageio.imwrite(\"/home/hooman/sdc1Storage/FM_PROJECT/FMDL_3.1/UNet_Hydraulics/hsUnet_try0_sameNetworkAs_try21_1chan_roiDelineatorVersion-1/dataFor__hsUnet_try0_sameAs_try21_1chan_roiDelineatorVersion-1/example_segmaps4.jpg\", grid_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#printing all shapes and types\n",
    "\n",
    "print('orig image')\n",
    "print(type(X_train[0]))\n",
    "print(X_train[0].shape)\n",
    "\n",
    "print()\n",
    "print('augmented image')\n",
    "print(type(images_aug[0]))\n",
    "print(images_aug[0].shape)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('orig labels')\n",
    "print(type(Y_train[0]))\n",
    "print(Y_train[0].shape)\n",
    "\n",
    "print()\n",
    "print('converted orig labels')\n",
    "k = ia.SegmentationMapOnImage(Y_train[0], shape=X_train[0].shape, nb_classes=1+1)\n",
    "print(type(k))\n",
    "print(k.shape)\n",
    "\n",
    "print()\n",
    "print('augmented labels')\n",
    "print(type(segmaps_aug[0]))\n",
    "print(segmaps_aug[0].shape    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"converted back\")\n",
    "kk = k.get_arr_int()\n",
    "print(type(kk))\n",
    "print(kk.shape)\n",
    "\n",
    "\n",
    "m = kk[...,np.newaxis].astype(np.bool)\n",
    "print(m.shape)\n",
    "print(type(m))\n",
    "print(m.dtype)\n",
    "#y.astype(int) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#(single image of above for tests) Debugging boundaris for boxDetector 2nd round (do not delete)\n",
    "rows = []\n",
    "\n",
    "fileNames = ['KAJF0576_20110311121812_avi_0.png','KAJF0576_20110311074750_avi_23250.png','1_20170118-023300_0001n0_17261.png','1_20161116-044000_0001n0_8135.png','1_20161116-044000_0001n0_16835.png', '1_20161117-000500_0001n0_6000.png', '1_20161117-002000_0001n0_4200.png']\n",
    "\n",
    "for fileName in fileNames:\n",
    "    \n",
    "    filePath = labelsPath + fileName\n",
    "\n",
    "    imgLabel = imread(filePath)\n",
    "    img = imread(imagesPath + fileName)\n",
    "\n",
    "    #I added this for try3  ssd-multiclass-tries 1 and 2 didnt have this.\n",
    "    imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "    print(\"processing file: \" + filePath)\n",
    "\n",
    "\n",
    "\n",
    "    #bucketBoundariesDict = getBucketBoundariesTooth2ToothV2(imgLabel, img)\n",
    "    matInsideBoundariesDict = getMatInsideBoundaries(imgLabel, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# copying files from one dir to another\n",
    "\n",
    "import shutil\n",
    "\n",
    "# deleting files that are not in one dir from another\n",
    "filesInCsv = {}\n",
    "\n",
    "for fileName in os.listdir('/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/temp/'):\n",
    "    filesInCsv[fileName] = 1\n",
    "\n",
    "\n",
    "\n",
    "for fileName in os.listdir('/media/hooman/New Volume/FM_PROJECT_STORAGE/QC-Tests/backhoe/all/'):\n",
    "    if fileName in filesInCsv:\n",
    "        print(fileName)\n",
    "        shutil.copy('/media/hooman/New Volume/FM_PROJECT_STORAGE/QC-Tests/backhoe/all/' + fileName,'/media/hooman/1tb-ssd-hs3-linu/FM_PROJECT/dataPreparation/FMDL_3.1/backhoe/hsTestSetOfHardImages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#(WRONG) Find all boundaries and wirte the ones you find to rows. Used this for ssdMulti-try1,2\n",
    "rows = []\n",
    "for fileName in os.listdir(labelsPath):\n",
    "    \n",
    "    filePath = labelsPath + fileName\n",
    "    \n",
    "    imgLabel = imread(filePath) \n",
    "    #MISTAKE1: not converting to rgb\n",
    "    \n",
    "    print(\"processing file:\\n\", filePath)\n",
    "    \n",
    "    \n",
    "    \n",
    "    boundariesDict = getAllBoundaries(imgLabel)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if('bucket' in boundariesDict):\n",
    "        # write up the rows\n",
    "        (xmin, xmax, ymin, ymax) = boundariesDict['bucket']\n",
    "        row = fileName + \",\" + filePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"bucket\" + \"\\n\"\n",
    "    \n",
    "        rows.append(row)\n",
    "    \n",
    "    else:\n",
    "        print(\"ERROR: Found no bucket boundary. This should NOT happen\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    if('fineInside' in boundariesDict):\n",
    "        if len(boundariesDict['fineInside']) == 4:\n",
    "            (xmin, xmax, ymin, ymax) = boundariesDict['fineInside']\n",
    "            row = fileName + \",\" + filePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"fineInside\" + \"\\n\"\n",
    "        else:\n",
    "            print(\"ERROR: Found more than one fineInside Boundaries. This should NOT happen\\n\")\n",
    "        \n",
    "        rows.append(row)        \n",
    "    \n",
    "    \n",
    "    \n",
    "    if('rockInside' in boundariesDict):\n",
    "        for rockBbx in boundariesDict['rockInside']:\n",
    "            \n",
    "            (xmin, xmax, ymin, ymax) = rockBbx\n",
    "            \n",
    "            row = fileName + \",\" + filePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"fineInside\" + \"\\n\"\n",
    "            #MISTAKE2: above should be rockInside\n",
    "            rows.append(row)\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    #Ignoring Teeth for now. Cuz I believe they should be individual boundaries for teeth cuz one tooth line boundary will confuse the algo, since there might be material inside the boundarie that are not teeth. \n",
    "    '''\n",
    "    if(boundariesDict['teeth']):\n",
    "        if len(boundariesDict['teeth']) == 4:\n",
    "            (xmin, xmax, ymin, ymax) = boundariesDict['teeth']\n",
    "            row = fileName + \",\" + filePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"teeth\" + \"\\n\"\n",
    "        else:\n",
    "            print(\"ERROR: Found more than one teeth Boundaries. This should NOT happen\\n\")\n",
    "        \n",
    "        rows.append(row)\n",
    "    ''' \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "print(\"processes \"+ str(len(rows)) + \" rows\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# finding only bucket boundaries (rest is same as first cell #Finding matInside and bucket boundaries. For ssdMulti-try3 )\n",
    "\n",
    "rows = []\n",
    "for fileName in os.listdir(labelsPath):\n",
    "    \n",
    "    filePath = labelsPath + fileName\n",
    "    \n",
    "    imgLabel = imread(filePath)\n",
    "    \n",
    "    #I added this for try3  ssd-multiclass-tries 1 and 2 didnt have this.\n",
    "    imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "    \n",
    "    print(\"processing file: \" + filePath)\n",
    "    \n",
    "    \n",
    "    \n",
    "    bucketBoundariesDict = getAllBoundaries(imgLabel)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if('bucket' in bucketBoundariesDict):\n",
    "        # write up the rows\n",
    "        (xmin, xmax, ymin, ymax) = bucketBoundariesDict['bucket']\n",
    "        row = fileName + \",\" + filePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"bucket\" + \"\\n\"\n",
    "    \n",
    "        rows.append(row)\n",
    "    \n",
    "    else:\n",
    "        print(\"ERROR: Found no bucket boundary. This should NOT happen\\n\")\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "print(\"processes \"+ str(len(rows)) + \" rows\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# creating masks for u-net CORRECT (using BGR for labels) with overlay\n",
    "\n",
    "'''\n",
    "croppedImagesPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/images/'\n",
    "croppedLabelsPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/labels/'\n",
    "croppedMasksPath  = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/masks/'\n",
    "croppedOverlayedPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/overlayed/'\n",
    "'''\n",
    "\n",
    "croppedImagesPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/images/'\n",
    "croppedLabelsPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/labels/'\n",
    "\n",
    "croppedMasksPath  = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/try2_withInappInside/fullInsideMaterilMasks/'\n",
    "croppedOverlayedPath = '/media/hooman/hsSsdPartUbuntu/FM_PROJECT/dataPreparation/FMDL_3.1/try2_withInappInside/fullOverlays/'\n",
    "\n",
    "\n",
    "n = 0\n",
    "fileName = '1_20180122-131700_0001n0_41430.png'\n",
    "img = imread(croppedImagesPath + fileName)\n",
    "imgLabel = imread(croppedLabelsPath + fileName)\n",
    "#imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGB2BGR)  This is wrong too\n",
    "imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "inapInside  = (128, 0, 255)\n",
    "    \n",
    "labelsDic = {\n",
    "    'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "    'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "    #for Hydraulics U-Net I had the inapInside labels but not for BucyrucAndPnH \n",
    "    'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "\n",
    "#    'emptyInside' :np.where(np.all(imgLabel == emptyInside, axis=-1)), bad idea\n",
    "}\n",
    "\n",
    "\n",
    "#print(labelsDic)\n",
    "#print(img.shape)\n",
    "\n",
    "mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "mask[labelsDic['fineInside']] = 1\n",
    "mask[labelsDic['rockInside']] = 1\n",
    "mask[labelsDic['inapInside']] = 1\n",
    "#mask[labelsDic['emptyInside']] = 1\n",
    "\n",
    "\n",
    "\n",
    "mask.dtype='uint8'\n",
    "maskOverlay = cv2.cvtColor(mask*255, cv2.COLOR_GRAY2BGR)\n",
    "maskOverlay[:,:,0] = 0\n",
    "maskOverlay[:,:,2] = 0\n",
    "\n",
    "\n",
    "opacity = 0.2\n",
    "cv2.addWeighted(maskOverlay, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "\n",
    "\n",
    "mask.dtype='uint8'\n",
    "#cv2.imwrite(croppedMasksPath + fileName, mask)\n",
    "#cv2.imwrite(croppedOverlayedPath + fileName, img)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "n += 1\n",
    "\n",
    "print(\"created  \" + str(n) + \"  binary masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#cropping images with GT boundaries and creating appropriate masks and creating mask overlays\n",
    "\n",
    "imagesPath = '/home/hooman/backhoeOpticalScene/images/'\n",
    "labelsPath = '/home/hooman/backhoeOpticalScene/labels/'\n",
    "\n",
    "masksSavePath = '/home/hooman/backhoeOpticalScene/roiDelineators/try4-csvFrom-ssdTry3-withInapp-reducedNumberOfempyBuckets-BatchSize4/croppedMasks/'\n",
    "\n",
    "overlaySavePath = '/home/hooman/backhoeOpticalScene/roiDelineators/try4-csvFrom-ssdTry3-withInapp-reducedNumberOfempyBuckets-BatchSize4/croppedOverlayOfMasks/'\n",
    "\n",
    "\n",
    "for row in gt_rows[1:len(gt_rows)-1]:\n",
    "#for row in gt_rows[14:15]:\n",
    "    vals = row.split(',')\n",
    "    fileName = vals[0]\n",
    "    print(\"prcessing imgId: \" + fileName + \"\\n\")\n",
    "\n",
    "    #read the image from csv row\n",
    "    img = imread(imagesPath + fileName)\n",
    "    \n",
    "    label = imread(labelsPath + fileName)\n",
    "    label = cv2.cvtColor(label, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "    \n",
    "    #get boundaries to cropp the image from csv\n",
    "    xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "    if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "        (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "\n",
    "        img = img[ymin:ymax, xmin:xmax,]\n",
    "        imgLabel = label[ymin:ymax, xmin:xmax]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Create a mas from cropped image\n",
    "        labelsDic = {\n",
    "            'rockInside' : np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "            'fineInside' : np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "            'fmInapp'    : np.where(np.all(imgLabel == fmInapp, axis=-1)),\n",
    "        }\n",
    "\n",
    "        \n",
    "        mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "        mask2 = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "        mask.dtype='uint8'\n",
    "        mask2.dtype='uint8'\n",
    "        \n",
    "        mask[labelsDic['fineInside']] = 1\n",
    "        mask[labelsDic['rockInside']] = 1\n",
    "        mask[labelsDic['fmInapp']] = 1\n",
    "        \n",
    "\n",
    "        \n",
    "        #Remove the points that are not in the largest contour from mask\n",
    "        _,contours,_ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE, offset=(0, 0))\n",
    "        \n",
    "        if contours:\n",
    "            max_cnt = max(contours, key=cv2.contourArea)\n",
    "\n",
    "            # cv2.drawContours(mask2, max_cnt, -1, 1, cv2.FILLED, 8) thos does NOT fill up the inside of contour\n",
    "            cv2.drawContours(mask2, [max_cnt], -1, 1, cv2.FILLED, 8)\n",
    "\n",
    "        \n",
    "        #if no contours found, mask2 will remain as all 0s\n",
    "        cv2.imwrite(masksSavePath + fileName, mask2)\n",
    "            \n",
    "            \n",
    "        #get the overlay\n",
    "        maskOverlay = cv2.cvtColor(mask2*255, cv2.COLOR_GRAY2BGR)\n",
    "        maskOverlay[:,:,0] = 0\n",
    "        maskOverlay[:,:,2] = 0\n",
    "\n",
    "        opacity = 0.2\n",
    "        cv2.addWeighted(maskOverlay, opacity, img, 1 - opacity, 0, img)\n",
    "        \n",
    "        cv2.imwrite(overlaySavePath + fileName, img)\n",
    "        \n",
    "        \n",
    "        '''        \n",
    "        plt.imshow(mask)\n",
    "        plt.title('mask1')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(mask2)\n",
    "        plt.title('mask2 final')\n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(img)\n",
    "        plt.title('overlayed img')\n",
    "        plt.show()\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# random crop the masks create above\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "offsetsToApply = [50,75, 100, 125, 150, 175]\n",
    "dirToSaveImages = '/home/hooman/backhoeOpticalScene/roiDelineators/try1-csvFrom-ssdTry2/randomCroppedImages/'\n",
    "dirToSaveMasks = '/home/hooman/backhoeOpticalScene/roiDelineators/try1-csvFrom-ssdTry2/randomCroppedMasks/'\n",
    "\n",
    "\n",
    "dirToReadImages = '/home/hooman/backhoeOpticalScene/images/'\n",
    "dirToReadMasks = '/home/hooman/backhoeOpticalScene/roiDelineators/try1-csvFrom-ssdTry2/croppedMasks/'\n",
    "\n",
    "\n",
    "for row in gt_rows[15:16]:\n",
    "    \n",
    "    vals = row.split(',')\n",
    "\n",
    "    if os.path.exists(dirToReadImages + vals[0]) and os.path.exists(dirToReadMasks + vals[0]):\n",
    "        \n",
    "        imgPil = Image.open(dirToReadImages + vals[0])\n",
    "        img = np.array(imgPil) \n",
    "        imgPil.close()\n",
    "\n",
    "        labelPil = Image.open(dirToReadMasks + vals[0])\n",
    "        label = np.array(labelPil)\n",
    "        labelPil.close()\n",
    "        \n",
    "        \n",
    "\n",
    "        xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "        if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "            (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "\n",
    "            imgWidth = img.shape[1]\n",
    "            imgHeight = img.shape[0]\n",
    "\n",
    "\n",
    "            imgAct = img[ymin:ymax, xmin:xmax,]\n",
    "            labelAct = label[ymin:ymax, xmin:xmax]\n",
    "\n",
    "            if imgAct.shape[0] > 0 and imgAct.shape[1] > 0 and labelAct.shape[0] > 0 and labelAct.shape[1] > 0: \n",
    "                cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '_RCAct.png'), imgAct)\n",
    "                cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '_RCAct.png'), labelAct)\n",
    "\n",
    "\n",
    "\n",
    "            for offset in offsetsToApply:\n",
    "\n",
    "                img1 =     img[ymin + offset:ymax + offset, xmin:xmax]\n",
    "                label1 = label[ymin + offset:ymax + offset, xmin:xmax]\n",
    "                \n",
    "                if img1.shape[0] > 0 and img1.shape[1] > 0 and label1.shape[0] > 0 and label1.shape[1] > 0: \n",
    "                    cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_1.png', img1)\n",
    "                    cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_1.png', label1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                img2 =     img[ymin:ymax, xmin + offset:xmax + offset]\n",
    "                label2 = label[ymin:ymax, xmin + offset:xmax + offset]\n",
    "         \n",
    "                if img2.shape[0] > 0 and img2.shape[1] > 0 and label2.shape[0] > 0 and label2.shape[1] > 0: \n",
    "                    cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_2.png', img2)\n",
    "                    cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_2.png', label2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                if (ymin - offset) > 0:\n",
    "                    img3 =     img[ymin - offset:ymax - offset, xmin:xmax]\n",
    "                    label3 = label[ymin - offset:ymax - offset, xmin:xmax]\n",
    "                    \n",
    "                    if img3.shape[0] > 0 and img3.shape[1] > 0 and label3.shape[0] > 0 and label3.shape[1] > 0: \n",
    "                        cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_3.png', img3)\n",
    "                        cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_3.png', label3)\n",
    "\n",
    "\n",
    "\n",
    "                if (xmin - offset) > 0:\n",
    "                    img4 =     img[ymin:ymax, xmin - offset:xmax - offset]\n",
    "                    label4 = label[ymin:ymax, xmin - offset:xmax - offset]\n",
    "                    \n",
    "                    if img4.shape[0] > 0 and img4.shape[1] > 0 and label4.shape[0] > 0 and label4.shape[1] > 0: \n",
    "\n",
    "                        cv2.imwrite(dirToSaveImages + vals[0].replace('.png', '') + '_RC' + str(offset) + '_4.png', img4)\n",
    "                        cv2.imwrite(dirToSaveMasks + vals[0].replace('.png', '') + '_RC' + str(offset) + '_4.png', label4)\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"one of the provided directories doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getAllBoundaries_backhoe(imgLabel, img=[]):\n",
    "    \n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        'emptyInside' :np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'case' :np.where(np.all(imgLabel == case, axis=-1)),\n",
    "        'teeth' :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'bucketOutside':np.where(np.all(imgLabel == bucketOutside, axis=-1)),\n",
    "        'sheave': np.where(np.all(imgLabel == sheave, axis=-1)),\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "  \n",
    "    \n",
    "    ##############################################\n",
    "    ############## Bucket Boundary ###############\n",
    "    ##############################################\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    for labV in sortedLabelColsDic.values():\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    for labV in sortedLabelRowsDic.values():\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "\n",
    "    \n",
    "\n",
    "    #get the bucket boundary\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "    \n",
    "    if len(xmins) > 0 and len(xmaxs) > 0 and len(ymins) > 0 and len(ymaxs) > 0 : \n",
    "\n",
    "        (bucket_xmin, bucket_xmax, bucket_ymin, bucket_ymax) = (xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1])\n",
    "        \n",
    "        \n",
    "        croppedIm = imgLabel[0:bucket_xmax, bucket_ymin:bucket_ymax]\n",
    "        \n",
    "        plt.imshow(croppedIm)\n",
    "        plt.show()\n",
    "        \n",
    "        labelsDic2 = {\n",
    "            'rockInside' :np.where(np.all(croppedIm == rockInside, axis=-1)),\n",
    "            \n",
    "            'fineInside' :np.where(np.all(croppedIm == fineInside, axis=-1)),\n",
    "            \n",
    "            'fmInapp' :np.where(np.all(croppedIm == fmInapp, axis=-1)),\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "        #get the boundary for each label\n",
    "        sortedLabelColsDic = {}\n",
    "        sortedLabelRowsDic = {}\n",
    "        for k in labelsDic2.keys():\n",
    "            if len(labelsDic2[k][0]) > 0:\n",
    "                sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic2[k][0]),\n",
    "                sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic2[k][1]),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ##############################################\n",
    "        ############## matInside Boundary ###############\n",
    "        ##############################################\n",
    "        #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "        lowColVals = []\n",
    "        highColVals = []\n",
    "        for labV in sortedLabelColsDic.values():\n",
    "            for v in labV:\n",
    "                lowColVals.append(v[0])\n",
    "                highColVals.append(v[len(v)-1])\n",
    "\n",
    "        lowRowVals = []\n",
    "        highRowVals = []\n",
    "        for labV in sortedLabelRowsDic.values():\n",
    "            for v in labV:\n",
    "                lowRowVals.append(v[0])\n",
    "                highRowVals.append(v[len(v)-1])\n",
    "\n",
    "\n",
    "\n",
    "        #get the bucket boundary\n",
    "        xmins2 = np.sort(np.array(lowColVals))\n",
    "        xmaxs2 = np.sort(np.array(highColVals))\n",
    "        ymins2 = np.sort(np.array(lowRowVals))\n",
    "        ymaxs2 = np.sort(np.array(highRowVals))\n",
    "\n",
    "        if len(xmins2) > 0 and len(xmaxs2) > 0 and len(ymins2) > 0 and len(ymaxs2) > 0 : \n",
    "            boundariesDict['matInside'] = [xmins2[0], xmaxs2[len(xmaxs2)-1], ymins2[0] + bucket_ymin, ymaxs2[len(ymaxs2)-1] + bucket_ymin]\n",
    "        \n",
    "            #if bucket_xmin > xmins[0]:\n",
    "                #bucket_xmin = xmins[0]\n",
    "        \n",
    "        boundariesDict['bucket'] = [bucket_xmin, bucket_xmax, bucket_ymin, bucket_ymax]\n",
    "\n",
    "\n",
    "        return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Finding matInside and bucket boundaries. For Backhoe\n",
    "rows = []\n",
    "\n",
    "fileName = '1_20180703-232500_1001n0_324.png'\n",
    "    \n",
    "imgFilePath = imagesPath + fileName\n",
    "\n",
    "imgLabel = imread(labelsPath + fileName)\n",
    "\n",
    "#I added this for try3  ssd-multiclass-tries 1 and 2 didnt have this.\n",
    "imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "print(\"processing file: \" + fileName)\n",
    "\n",
    "\n",
    "allBoundaries = getAllBoundaries_backhoe(imgLabel)\n",
    "\n",
    "if allBoundaries:\n",
    "    if('bucket' in allBoundaries):\n",
    "        # write up the rows\n",
    "        (xmin, xmax, ymin, ymax) = allBoundaries['bucket']\n",
    "        row = fileName + \",\" + imgFilePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"bucket\" + \"\\n\"\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    else:\n",
    "        print(\"ERROR: Found no bucket boundary.\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    if('matInside' in allBoundaries):\n",
    "        if len(allBoundaries['matInside']) == 4:\n",
    "            (xmin, xmax, ymin, ymax) = allBoundaries['matInside']\n",
    "            row = fileName + \",\" + imgFilePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"matInside\" + \"\\n\"\n",
    "        else:\n",
    "            print(\"ERROR: Found more than one matInside Boundaries. This should NOT happen\\n\")\n",
    "\n",
    "        rows.append(row)        \n",
    "\n",
    "\n",
    "\n",
    "for row in rows:\n",
    "    visualizeRow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def visualizeRow(row):\n",
    "    vals = row.split(',')\n",
    "    \n",
    "    img = imread(imagesPath + vals[0])\n",
    "    label = imread(labelsPath + vals[0])\n",
    "    \n",
    "    xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "    if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "        (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "        \n",
    "        cv2.rectangle(img,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(255,0,0),3)\n",
    "        cv2.rectangle(label,(int(xmin), int(ymin)),(int(xmax), int(ymax)),(255,0,0),3)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(label)\n",
    "    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Finding matInside and bucket boundaries. For Backhoe\n",
    "rows = []\n",
    "\n",
    "fileName = '1_20180703-232500_1001n0_324.png'\n",
    "    \n",
    "imgFilePath = imagesPath + fileName\n",
    "\n",
    "imgLabel = imread(labelsPath + fileName)\n",
    "\n",
    "#I added this for try3  ssd-multiclass-tries 1 and 2 didnt have this.\n",
    "imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "print(imgLabel.shape)\n",
    "plt.imshow(imgLabel)\n",
    "plt.title('imgLabel')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imgLabel[0:xmax, ymin:ymax])\n",
    "plt.title('imgLabel[0:xmax, ymin:ymax]')\n",
    "plt.show()\n",
    "\n",
    "kk = imgLabel[(imgLabel[:, :, 0] == 0) & (imgLabel[:, :, 1] == 255) & (imgLabel[:, :, 2] == 0)]\n",
    "\n",
    "\n",
    "print(kk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#ds\n",
    "filesToDelete = [\n",
    "    '1_20180122-161700_0001n0_1050_RC150_1.png',\n",
    "    '1004_ESP_S05_003_14168_RC175_1.png',\n",
    "    '1_20180122-224600_0001n0_23239_RC175_1.png',\n",
    "    '1_20170118-212900_0001n0_19405_RC175_1.png',\n",
    "    '1004_ESP_S04_008_19783_RC100_1.png',\n",
    "    '1_20180122-101700_0001n0_2345_RC175_1.png',\n",
    "    '1004_ESP_S04_012_71885_RC175_1.png',\n",
    "    '1_20180122-151700_0001n0_78742_RC175_1.png',\n",
    "    '1_20170118-081100_0001n0_12101_RC175_1.png',\n",
    "    '1004_ESP_S05_001_53103_RC175_1.png',\n",
    "    '1004_ESP_S05_002_2958_RC150_1.png',\n",
    "    '1_20180122-061000_0001n0_3143_RC125_1.png',\n",
    "    '1004_ESP_S05_001_35973_RC150_1.png',\n",
    "    '1004_ESP_S05_002_2958_RC150_2.png',\n",
    "    '1_20180122-192427_0001n0_11366_RC150_1.png',\n",
    "    '1004_ESP_S05_001_35973_RC175_2.png',\n",
    "    '1_20180122-181700_0001n0_39621_RC150_1.png',\n",
    "    '1_20180122-121700_0001n0_31663_RC175_1.png',\n",
    "    '1004_ESP_S05_002_2958_RC75_3.png',\n",
    "    '1004_ESP_S04_004_70739_RC175_1.png',\n",
    "    '1_20180122-071740_0001n0_97652_RC150_1.png',\n",
    "    '1004_ESP_S05_002_20706_RC150_1.png',\n",
    "    '1004_ESP_S04_011_84985_RC175_1.png',\n",
    "    '1_20161117-002000_0001n0_6600_RC175_1.png',\n",
    "    '1_20180122-194635_0001n0_31231_RC175_1.png',\n",
    "    '1016_CHM_023_949_RC175_1.png',\n",
    "    '1_20180122-081700_0001n0_8809_RC175_1.png',\n",
    "    '1004_ESP_S04_008_19783_RC125_1.png',\n",
    "    '1004_ESP_S04_004_50030_RC175_1.png',\n",
    "    '1_20180122-141700_0001n0_2351_RC150_1.png',\n",
    "    '1004_ESP_S05_002_2958_RC175_1.png',\n",
    "    '1_20180122-041007_0001n0_54683_RC175_1.png',\n",
    "    '1_20180122-081700_0001n0_9641_RC175_1.png',\n",
    "    '1004_ESP_S05_002_2958_RC75_1.png',\n",
    "    '1_20170118-023300_0001n0_1961_RC175_1.png',\n",
    "    '1004_ESP_S04_008_19783_RC75_1.png',\n",
    "    '1_20170118-212900_0001n0_19405_RC150_1.png',\n",
    "    '1_20170118-072600_0001n0_14902_RC175_1.png',\n",
    "    '1004_ESP_S05_001_53103_RC150_1.png',\n",
    "    '1_20180122-041007_0001n0_3339_RC175_1.png',\n",
    "    '1_20161116-085500_0001n0_6000_RC175_1.png',\n",
    "    '1_20180123-034600_0001n0_6055_RC175_1.png',\n",
    "    '1_20180122-121700_0001n0_48269_RC175_1.png',\n",
    "    '1_20161115-073100_0001n0_10017_RC175_1.png',\n",
    "    '1_20180122-181700_0001n0_34021_RC175_1.png',\n",
    "    '1_20180122-171700_0001n0_1050_RC175_1.png',\n",
    "    '1_20180122-081700_0001n0_57_RC150_1.png',\n",
    "    '1004_ESP_S05_002_2958_RC100_3.png',\n",
    "    '1_20180122-041007_0001n0_24636_RC175_1.png',\n",
    "    '1_20180122-041007_0001n0_42955_RC175_1.png',\n",
    "    '1_20180123-014600_0001n0_1327_RC175_1.png',\n",
    "    '1004_ESP_S04_008_19783_RC150_4.png',\n",
    "    '1_20180122-111700_0001n0_36831_RC175_1.png',\n",
    "    '1_20170118-064100_0001n0_25496_RC175_1.png',\n",
    "    '1016_CHM_026_12161_RC175_1.png',\n",
    "    '1_20161115-222501_0001n0_8697_RC150_1.png',\n",
    "    '1_20180122-161700_0001n0_84651_RC175_1.png',\n",
    "    '1_20180122-192427_0001n0_0_RC175_1.png',\n",
    "    '1_20180122-151700_0001n0_78742_RC150_1.png',\n",
    "    '1004_ESP_S05_003_84_RC175_1.png',\n",
    "    '1004_ESP_S04_009_35297_RC175_1.png',\n",
    "    '1_20170118-072600_0001n0_13422_RC175_1.png',\n",
    "    '1004_ESP_S04_008_19783_RC75_3.png',\n",
    "    '1_20180122-101700_0001n0_74895_RC175_1.png',\n",
    "    '1_20180122-041007_0001n0_25990_RC175_1.png',\n",
    "    '1_20180122-192427_0001n0_19815_RC150_1.png',\n",
    "    '1004_ESP_S04_008_19783_RC150_3.png',\n",
    "    '1_20180122-234600_0001n0_86659_RC175_1.png',\n",
    "    '1_20180123-004600_0001n0_49677_RC150_1.png',\n",
    "    '1_20180122-041007_0001n0_24636_RC150_1.png',\n",
    "    '1004_ESP_S04_006_3614_RC175_1.png',\n",
    "    '1_20180122-224600_0001n0_8180_RC175_1.png',\n",
    "    '1_20170118-212900_0001n0_8812_RC175_1.png',\n",
    "    '1_20161116-155500_0001n0_4837_RC175_1.png',\n",
    "    '1004_ESP_S05_002_2958_RC75_2.png',\n",
    "    '1_20180122-141700_0001n0_2351_RC175_1.png',\n",
    "    '1_20180122-151700_0001n0_23847_RC175_1.png',\n",
    "    '1004_ESP_S04_008_16321_RC175_1.png',\n",
    "    '1004_ESP_S05_001_53103_RC125_1.png',\n",
    "    '1_20180122-041007_0001n0_3339_RC150_1.png',\n",
    "    '1004_ESP_S05_002_2958_RC100_1.png',\n",
    "    '1_20180122-051000_0001n0_27363_RC150_1.png',\n",
    "    '1_20180122-161700_0001n0_15438_RC175_1.png',\n",
    "    '1_20170118-172900_0001n0_19999_RC175_1.png',\n",
    "    '1_20180122-141700_0001n0_59038_RC175_1.png',\n",
    "    '1004_ESP_S04_008_19783_RC175_2.png',\n",
    "    '1_20180122-181700_0001n0_1141_RC175_1.png',\n",
    "    '1004_ESP_S05_003_22719_RC175_1.png',\n",
    "    '1004_ESP_S04_008_19783_RC75_2.png',\n",
    "    '1_20161117-022000_0001n0_1200_RC150_1.png',\n",
    "    '1_20180122-214600_0001n0_44290_RC175_1.png',\n",
    "    '1_20180122-121700_0001n0_31663_RC150_1.png',\n",
    "    '1_20161116-155500_0001n0_937_RC175_1.png',\n",
    "    '1_20180123-034600_0001n0_4802_RC175_1.png',\n",
    "    '1004_ESP_S04_008_19783_RC75_4.png',\n",
    "    '1004_ESP_S04_008_19783_RC50_1.png',\n",
    "    '1_20161117-032000_0001n0_20700_RC150_1.png',\n",
    "    '1_20180122-051000_0001n0_31723_RC175_1.png',\n",
    "    '1_20180122-181700_0001n0_39621_RC175_1.png',\n",
    "    '1_20170118-155900_0001n0_15858_RC175_1.png',\n",
    "    '1004_ESP_S05_002_2958_RC100_4.png',\n",
    "    '1_20180122-192427_0001n0_11366_RC175_1.png',\n",
    "    '1_20170118-142900_0001n0_7435_RC175_1.png',\n",
    "    '1004_ESP_S05_001_31976_RC175_1.png',\n",
    "    '1004_ESP_S05_001_35973_RC125_2.png',\n",
    "    '1004_ESP_S04_008_19783_RC125_2.png',\n",
    "    '1_20180122-131700_0001n0_31846_RC175_1.png',\n",
    "    '1004_ESP_S05_002_2958_RC125_1.png',\n",
    "    '1004_ESP_S04_008_16321_RC150_1.png',\n",
    "    '1_20180122-171700_0001n0_1200_RC175_1.png',\n",
    "    '1_20180122-181700_0001n0_9696_RC175_1.png',\n",
    "    '1_20161117-032000_0001n0_6600_RC175_1.png',\n",
    "    '1004_ESP_S04_011_25718_RC150_1.png',\n",
    "    '1_20180123-024600_0001n0_45644_RC175_1.png',\n",
    "    '1_20180122-234600_0001n0_86659_RC125_1.png',\n",
    "    '1004_ESP_S04_008_19783_RC50_2.png',\n",
    "    '1004_ESP_S05_002_2958_RC125_3.png',\n",
    "    '1_20180122-234600_0001n0_86811_RC175_1.png',\n",
    "    '1_20180122-111700_0001n0_50519_RC175_1.png',\n",
    "    '1004_ESP_S04_004_39156_RC175_1.png',\n",
    "    '1_20170118-023300_0001n0_19511_RC150_1.png',\n",
    "    '1_20180123-014600_0001n0_1327_RC150_1.png',\n",
    "    '1_20180122-234600_0001n0_33906_RC175_1.png',\n",
    "    '1016_CHM_017_101_RC175_1.png',\n",
    "    '1004_ESP_S04_008_19783_RC100_3.png',\n",
    "    '1_20170118-064100_0001n0_26459_RC175_1.png',\n",
    "    '1004_ESP_S05_002_2958_RC150_4.png',\n",
    "    '1004_ESP_S05_002_2958_RC50_2.png',\n",
    "    '1_20180123-004600_0001n0_49677_RC175_1.png',\n",
    "    '1_20180122-181700_0001n0_12066_RC175_1.png',\n",
    "    '1_20180123-014600_0001n0_56510_RC175_1.png',\n",
    "    '1_20180122-194635_0001n0_40113_RC175_1.png',\n",
    "    '1_20180123-014600_0001n0_56030_RC175_1.png',\n",
    "    '1_20161115-222501_0001n0_13297_RC175_1.png',\n",
    "    '1_20161115-073100_0001n0_10017_RC150_1.png',\n",
    "    '1_20180122-121700_0001n0_55085_RC150_1.png',\n",
    "    '1_20161117-000500_0001n0_4200_RC175_1.png',\n",
    "    '1004_ESP_S04_012_52063_RC175_1.png',\n",
    "    '1_20180122-141700_0001n0_30710_RC175_1.png',\n",
    "    '1_20170118-164400_0001n0_8796_RC175_1.png',\n",
    "    '1_20180123-024600_0001n0_24146_RC150_1.png',\n",
    "    '1004_ESP_S05_002_2958_RC75_4.png',\n",
    "    '1_20180122-061000_0001n0_3143_RC175_1.png',\n",
    "    '1004_ESP_S05_001_35973_RC150_2.png',\n",
    "    '1_20161117-002000_0001n0_6600_RC150_1.png',\n",
    "    '1_20180122-101700_0001n0_881_RC175_1.png',\n",
    "    '1_20170118-111000_0001n0_4429_RC175_1.png',\n",
    "    '1004_ESP_S04_008_19783_RCAct.png',\n",
    "    '1_20180122-192427_0001n0_6869_RC175_1.png',\n",
    "    '1_20180122-041007_0001n0_84646_RC175_1.png',\n",
    "    '1_20180122-114041_0001n0_230_RC175_1.png',\n",
    "    '1004_ESP_S04_008_19783_RC175_1.png',\n",
    "    '1_20180122-071740_0001n0_97652_RC175_1.png',\n",
    "    '1016_CHM_025_8475_RC175_1.png',\n",
    "    '1_20180123-014600_0001n0_81334_RC175_1.png',\n",
    "    '1_20180122-192427_0001n0_6869_RC150_1.png',\n",
    "    '1_20161117-000500_0001n0_4200_RC150_1.png',\n",
    "    '1004_ESP_S05_002_2958_RC175_3.png',\n",
    "    '1_20180122-111700_0001n0_26423_RC175_1.png',\n",
    "    '1_20180122-051000_0001n0_480_RC175_1.png',\n",
    "    '1_20170118-172900_0001n0_20962_RC175_1.png',\n",
    "    '1004_ESP_S04_015_12535_RC175_1.png',\n",
    "    '1_20161117-022000_0001n0_1200_RC175_1.png',\n",
    "    '1_20180122-181700_0001n0_9696_RC150_1.png',\n",
    "    '1004_ESP_S04_008_19783_RC50_3.png',\n",
    "    '1_20180122-161700_0001n0_84651_RC150_1.png',\n",
    "    '1_20161116-155500_0001n0_937_RC150_1.png',\n",
    "    '1004_ESP_S04_008_19783_RC150_2.png',\n",
    "    '1004_ESP_S04_015_3175_RC175_1.png',\n",
    "    '1_20180122-114041_0001n0_230_RC150_1.png',\n",
    "    '1_20180122-101700_0001n0_27563_RC175_1.png',\n",
    "    '1_20170118-231001_0001n0_16508_RC175_1.png',\n",
    "    '1_20180123-014600_0001n0_10926_RC150_1.png',\n",
    "    '1004_ESP_S04_008_19783_RC125_4.png',\n",
    "    '1004_ESP_S04_009_16877_RC175_1.png',\n",
    "    '1_20180122-034228_0001n0_662_RC150_1.png',\n",
    "    '1_20180123-024600_0001n0_24146_RC175_1.png',\n",
    "    '1_20180123-024600_0001n0_52607_RC175_1.png',\n",
    "    '1004_ESP_S05_001_35973_RC100_2.png',\n",
    "    '1_20170118-023300_0001n0_19511_RC175_1.png',\n",
    "    '1_20161115-222501_0001n0_8697_RC175_1.png',\n",
    "    '1016_CHM_013_8412_RC175_1.png',\n",
    "    '1_20180122-051000_0001n0_27363_RC175_1.png',\n",
    "    '1_20161117-032000_0001n0_20700_RC175_1.png',\n",
    "    '1004_ESP_S04_004_70739_RC125_1.png',\n",
    "    '1_20180122-051000_0001n0_68711_RC175_1.png',\n",
    "    '1_20180122-161700_0001n0_65776_RC175_1.png',\n",
    "    '1_20161115-073100_0001n0_217_RC175_1.png',\n",
    "    '1004_ESP_S05_002_25143_RC150_1.png',\n",
    "    '1_20161117-022000_0001n0_17400_RC175_1.png',\n",
    "    '1004_ESP_S04_015_14770_RC175_1.png',\n",
    "    '1_20180122-171700_0001n0_1050_RC150_1.png',\n",
    "    '1004_ESP_S05_002_2958_RC100_2.png',\n",
    "    '1_20180122-051000_0001n0_31723_RC150_1.png',\n",
    "    '1_20180122-121700_0001n0_55085_RC175_1.png',\n",
    "    '1_20161116-155500_0001n0_1237_RC175_1.png',\n",
    "    '1004_ESP_S04_012_32241_RC175_1.png',\n",
    "    '1004_ESP_S05_002_2958_RC125_2.png',\n",
    "    '1_20170118-155900_0001n0_14253_RC175_1.png',\n",
    "    '1004_ESP_S05_002_20706_RC175_1.png',\n",
    "    '1_20180123-034600_0001n0_4380_RC175_1.png',\n",
    "    '1_20180122-051000_0001n0_25947_RC150_1.png',\n",
    "    '1004_ESP_S05_002_25143_RC175_1.png',\n",
    "    '1_20170118-092550_0001n0_23212_RC175_1.png',\n",
    "    '1004_ESP_S04_008_19783_RC100_2.png',\n",
    "    '1_20180122-081700_0001n0_57_RC175_1.png',\n",
    "    '1_20180122-194635_0001n0_40113_RC150_1.png',\n",
    "    '1_20180122-061000_0001n0_4827_RC175_1.png',\n",
    "    '1004_ESP_S04_011_23274_RC175_1.png',\n",
    "    '1004_ESP_S04_008_19783_RC50_4.png',\n",
    "    '1004_ESP_S04_008_19783_RC175_3.png',\n",
    "    '1004_ESP_S04_011_25718_RC175_1.png',\n",
    "    '1_20180122-034228_0001n0_19428_RC175_1.png',\n",
    "    '1004_ESP_S04_004_70739_RC150_1.png',\n",
    "    '1_20180122-194635_0001n0_25320_RC175_1.png',\n",
    "    '1004_ESP_S05_002_2958_RC175_4.png',\n",
    "    '1_20180122-034228_0001n0_662_RC175_1.png',\n",
    "    '1004_ESP_S05_002_2958_RC50_1.png',\n",
    "    '1004_ESP_S05_002_2958_RC175_2.png',\n",
    "    '1004_ESP_S04_008_19783_RC100_4.png',\n",
    "    '1_20180123-034600_0001n0_4802_RC150_1.png',\n",
    "    '1_20180122-041007_0001n0_24636_RC125_1.png',\n",
    "    '1004_ESP_S05_002_2958_RC150_3.png',\n",
    "    '1004_ESP_S05_002_2958_RC50_4.png',\n",
    "    '1004_ESP_S04_009_18942_RC175_1.png',\n",
    "    '1_20161116-044000_0001n0_25835_RC175_1.png',\n",
    "    '1_20180122-061000_0001n0_1315_RC175_1.png',\n",
    "    '1_20161117-032000_0001n0_14400_RC175_1.png',\n",
    "    '1_20180122-051000_0001n0_2797_RC175_1.png',\n",
    "    '1_20180122-051000_0001n0_25947_RC175_1.png',\n",
    "    '1_20180122-161700_0001n0_1050_RC175_1.png',\n",
    "    '1_20180122-192427_0001n0_19815_RC175_1.png',\n",
    "    '1_20180123-014600_0001n0_10926_RC175_1.png',\n",
    "    '1_20180122-061000_0001n0_3143_RC150_1.png',\n",
    "    '1004_ESP_S05_002_2958_RCAct.png',\n",
    "    '1_20161115-124600_0001n0_26200_RC175_1.png',\n",
    "    '1004_ESP_S04_015_14770_RC150_1.png',\n",
    "    '1_20180123-014600_0001n0_56030_RC150_1.png',\n",
    "    '1004_ESP_S04_013_84422_RC175_1.png',\n",
    "    '1_20180122-234600_0001n0_86659_RC150_1.png',\n",
    "    '1_20161116-155500_0001n0_1237_RC150_1.png',\n",
    "    '1004_ESP_S05_001_35973_RC175_1.png',\n",
    "    '1_20170118-231001_0001n0_16187_RC175_1.png',\n",
    "    '1_20180122-192427_0001n0_0_RC150_1.png',\n",
    "    '1_20180122-101700_0001n0_2001_RC175_1.png',\n",
    "    '1004_ESP_S05_002_2958_RC50_3.png',\n",
    "    '1004_ESP_S04_008_19783_RC125_3.png',\n",
    "    '1004_ESP_S05_002_2958_RC125_4.png',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "for fileName in filesToDelete:\n",
    "    if os.path.exists('/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCropped_images/' + fileName):\n",
    "        os.remove('/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/cropped/randomCropped_images/' + fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# random cropping Images for U-Net Hydraulics\n",
    "\n",
    "row = gt_rows[3]\n",
    "offsetsToApply = [50,75, 100, 125, 150, 175]\n",
    "\n",
    "vals = row.split(',')\n",
    "\n",
    "img = imread(imagesPath + vals[0])\n",
    "label = imread(labelsPath + vals[0])\n",
    "\n",
    "xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "    (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "    \n",
    "    imgWidth = img.shape[1]\n",
    "    imgHeight = img.shape[0]\n",
    "    \n",
    "    print(imgWidth, imgHeight)\n",
    "    print(xmin, xmax, ymin, ymax)\n",
    "    \n",
    "    imgAct = img[ymin:ymax, xmin:xmax,]\n",
    "    labelAct = label[ymin:ymax, xmin:xmax]\n",
    "    \n",
    "    plt.imshow(imgAct)\n",
    "    plt.title('imgAct')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # good offsets 0, 25, 50,75, 100, 125, 150 \n",
    "    for offset in offsetsToApply:\n",
    "        \n",
    "        #if (ymax + offset) <= imgHeight:\n",
    "        img1 = img[ymin + offset:ymax + offset, xmin:xmax]\n",
    "\n",
    "        plt.imshow(img1)\n",
    "        plt.title('img1')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        #if (xmax + offset) <= imgWidth:\n",
    "        img2 = img[ymin:ymax, xmin + offset:xmax + offset]\n",
    "\n",
    "        plt.imshow(img2)\n",
    "        plt.title('img2')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        if (ymin - offset) >= 0:\n",
    "            img3 = img[ymin - offset:ymax - offset, xmin:xmax]\n",
    "\n",
    "            plt.imshow(img3)\n",
    "            plt.title('img3')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        if (xmin - offset) >= 0:\n",
    "            img4 = img[ymin:ymax, xmin - offset:xmax - offset]\n",
    "\n",
    "            plt.imshow(img4)\n",
    "            plt.title('img4')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# random cropping Images for U-Net BucyrusAndPnH\n",
    "from PIL import Image\n",
    "\n",
    "offsetsToApply = [50,75, 100, 125, 150, 175]\n",
    "dirToSaveImages = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/randomCroppedImages/'\n",
    "dirToSaveMasks = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/randomCroppedMasks/'\n",
    "\n",
    "\n",
    "dirToReadImages = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/allImages/'\n",
    "dirToReadMasks = '/home/hooman/dataPreparation/hsTrainingSetBucyrusAndPnH/unet/fullMaks/'\n",
    "\n",
    "\n",
    "row = gt_rows[3]\n",
    "\n",
    "#print(row)\n",
    "\n",
    "vals = row.split(',')\n",
    "\n",
    "if os.path.exists(dirToReadImages + vals[0]) and os.path.exists(dirToReadMasks + vals[0]):\n",
    "\n",
    "    #img = imread(dirToReadImages + vals[0])\n",
    "    imgPil = Image.open(dirToReadImages + vals[0])\n",
    "    img = np.array(imgPil) \n",
    "    imgPil.close()\n",
    "    \n",
    "    labelPil = Image.open(dirToReadMasks + vals[0])\n",
    "    label = np.array(labelPil)\n",
    "    labelPil.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    xmin, xmax, ymin, ymax = vals[2:6]\n",
    "\n",
    "    if xmin != \"\" and xmax != \"\" and ymin != \"\" and ymax != \"\":\n",
    "        (xmin, xmax, ymin, ymax) = (int(round(float(xmin))), int(round(float(xmax))), int(round(float(ymin))), int(round(float(ymax))))\n",
    "\n",
    "        imgWidth = img.shape[1]\n",
    "        imgHeight = img.shape[0]\n",
    "\n",
    "\n",
    "        imgAct = img[ymin:ymax, xmin:xmax,]\n",
    "\n",
    "        plt.imshow(imgAct)\n",
    "        plt.title('imgAct')\n",
    "        plt.show()\n",
    "\n",
    "        for offset in offsetsToApply:\n",
    "\n",
    "            img1 =     img[ymin + offset:ymax + offset, xmin:xmax]\n",
    "\n",
    "            plt.imshow(img1)\n",
    "            plt.title('img1')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "            img2 =     img[ymin:ymax, xmin + offset:xmax + offset]\n",
    "            plt.imshow(img2)\n",
    "            plt.title('img2')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "            if (ymin - offset) >= 0:\n",
    "                img3 =     img[ymin - offset:ymax - offset, xmin:xmax]\n",
    "                \n",
    "                plt.imshow(img3)\n",
    "                plt.title('img3')\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "\n",
    "            if (xmin - offset) >= 0:\n",
    "                img4 =     img[ymin:ymax, xmin - offset:xmax - offset]\n",
    "                \n",
    "                plt.imshow(img4)\n",
    "                plt.title('img4')\n",
    "                plt.show()\n",
    "        \n",
    "else:\n",
    "    print(\"one of the provided directories doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# creating masks for u-net CORRECT (using BGR for labels) with overlay\n",
    "\n",
    "croppedImagesPath = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/images/'\n",
    "croppedLabelsPath = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/labels/'\n",
    "croppedMasksPath  = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/masks/'\n",
    "croppedOverlayedPath = '/home/hooman/dataPreparation/hsTrainingSetWithRelabeled/overlays/'\n",
    "\n",
    "\n",
    "n = 0\n",
    "fileName = '1_20170118-064100_0001n0_3347.png'\n",
    "img = imread(croppedImagesPath + fileName)\n",
    "imgLabel = imread(croppedLabelsPath + fileName)\n",
    "#imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGB2BGR)\n",
    "imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "labelsDic = {\n",
    "    'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "    'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "    'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "#    'emptyInside' :np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "}\n",
    "\n",
    "\n",
    "#print(labelsDic)\n",
    "\n",
    "mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "mask[labelsDic['fineInside']] = 1\n",
    "mask[labelsDic['rockInside']] = 1\n",
    "mask[labelsDic['inapInside']] = 1\n",
    "#mask[labelsDic['emptyInside']] = 1\n",
    "\n",
    "\n",
    "\n",
    "mask.dtype='uint8'\n",
    "maskOverlay = cv2.cvtColor(mask*255, cv2.COLOR_GRAY2BGR)\n",
    "maskOverlay[:,:,0] = 0\n",
    "maskOverlay[:,:,2] = 0\n",
    "\n",
    "\n",
    "opacity = 0.2\n",
    "cv2.addWeighted(maskOverlay, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "\n",
    "\n",
    "mask.dtype='uint8'\n",
    "cv2.imwrite(croppedMasksPath + fileName, mask)\n",
    "cv2.imwrite(croppedOverlayedPath + fileName, img)\n",
    "\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imgLabel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Overlaying predicted segmentation resutls\n",
    "\n",
    "unet_pathToSavedResults = '/home/hooman/dataPreparation/testingMahdisNetworkOnMyLatestTestSetForComparison/correctedIds_preds/'\n",
    "testImagesPath = '/home/hooman/dataPreparation/testingMahdisNetworkOnMyLatestTestSetForComparison/correctedIds_images/'\n",
    "\n",
    "# set this to '' to not save results but desplay the images instead\n",
    "pathToSaveOverlayResults = '/home/hooman/UNet/hsUnet_try11/croppedImagesPredictionsOverlayed/'\n",
    "\n",
    "\n",
    "\n",
    "#for imgId in os.listdir(testImagesPath):\n",
    "    \n",
    "imgId = '1_20161115-124600_0001n0_0.png'\n",
    "\n",
    "\n",
    "img = imread(testImagesPath + imgId)\n",
    "\n",
    "pred = imread(unet_pathToSavedResults + imgId)\n",
    "\n",
    "\n",
    "'''\n",
    "predRes = cv2.resize(pred, (img.shape[1], img.shape[0])) \n",
    "\n",
    "predCol = cv2.cvtColor(predRes*255, cv2.COLOR_GRAY2BGR)\n",
    "predCol[:,:,0] = 0\n",
    "predCol[:,:,2] = 0\n",
    "\n",
    "\n",
    "opacity = 0.1\n",
    "overIm = cv2.addWeighted(predCol, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "imgRes = cv2.resize(img, (128, 128)) \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "imshow(img)\n",
    "plt.title('img')\n",
    "plt.show()\n",
    "\n",
    "imshow(pred)\n",
    "plt.title('pred')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "imshow(imgRes)\n",
    "plt.title('imgRes')\n",
    "plt.show()\n",
    "\n",
    "imshow(predRes)\n",
    "plt.title('predRes')\n",
    "plt.show()\n",
    "\n",
    "imshow(predCol)\n",
    "plt.title('predCol')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "if pathToSaveOverlayResults != '':\n",
    "    cv2.imwrite(pathToSaveOverlayResults + imgId, overIm)\n",
    "else:\n",
    "    imshow(overIm)\n",
    "    plt.title('overLayedImage')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# creating masks for u-net CORRECT (using BGR)\n",
    "\n",
    "croppedImagesPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/images/'\n",
    "croppedLabelsPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/labels/'\n",
    "croppedMasksPath  = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/masks/'\n",
    "croppedOverlayedPath = '/home/hooman/dataPreparation/hsTrainingSet/trainingSetForHsUNetCroppedImages-CleanedUp/overlayed/'\n",
    "\n",
    "\n",
    "fileName = '1_20161116-025500_0001n0_15617.png'\n",
    "\n",
    "img = imread(croppedImagesPath + fileName)\n",
    "imgLabel = imread(croppedLabelsPath + fileName)\n",
    "imgLabel = cv2.cvtColor(imgLabel, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "\n",
    "labelsDic = {\n",
    "    'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "    'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "    'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "#    'emptyInside' :np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "}\n",
    "\n",
    "\n",
    "print(labelsDic)\n",
    "\n",
    "mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "mask[labelsDic['fineInside']] = 1\n",
    "mask[labelsDic['rockInside']] = 1\n",
    "mask[labelsDic['inapInside']] = 1\n",
    "#mask[labelsDic['emptyInside']] = 1\n",
    "\n",
    "\n",
    "\n",
    "mask.dtype='uint8'\n",
    "maskOverlay = cv2.cvtColor(mask*255, cv2.COLOR_GRAY2BGR)\n",
    "maskOverlay[:,:,0] = 0\n",
    "maskOverlay[:,:,2] = 0\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "    \n",
    "opacity = 0.2\n",
    "cv2.addWeighted(maskOverlay, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.title('overLayedImage')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imgLabel)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropping images to contain only ROI (V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_rows = readCsvRows(\"/home/hooman/backhoeOpticalScene/roiDelineators/try1-csvFrom-ssdTry2/fromSSdTry2_fineAndRockAndInapInMatInside_backhoe_shuffled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for row in gt_rows[1:len(gt_rows)-1]:\n",
    "    cropImgFromRow(row, False , True,'','/home/hooman/backhoeOpticalScene/roiDelineators/try1-csvFrom-ssdTry2/croppedLabels/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating U-Net images (padding with 0) and maskst (6 channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#displaying the image sizes for my version of VES U-Net \n",
    "\n",
    "img = imread(imagesPath + '1_20161116-155500_0001n0_10537.png')\n",
    "\n",
    "imgResized = cv2.resize(img, (640, 480)) \n",
    "\n",
    "# you can downsample with numpy too. I use opencv to be consistant.    imgDs = img[::4, ::4, :]\n",
    "imgDs = cv2.resize(imgResized, (0,0), fx=0.25, fy=0.25) \n",
    "\n",
    "imgPadded = cv2.copyMakeBorder(imgDs,4,4,0,0,cv2.BORDER_CONSTANT,value=(0,0,0))\n",
    "\n",
    "\n",
    "\n",
    "print(img.shape)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "print(imgResized.shape)\n",
    "plt.imshow(imgResized)\n",
    "plt.show()\n",
    "\n",
    "print(imgDs.shape)\n",
    "plt.imshow(imgDs)\n",
    "plt.show()\n",
    "\n",
    "print(imgPadded.shape)\n",
    "plt.imshow(imgPadded)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# WRONG Creating the (128, 160, 6) labels \n",
    "\n",
    "imgLabel = imread(labelsPath + '1_20161116-155500_0001n0_10537.png') \n",
    "#imgLabel = imread(labelsPath + '1016_CHM_026_116.png') \n",
    "#imgLabel = imread(labelsPath + '1_20161115-153100_0001n0_14400.png')\n",
    "\n",
    "mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1], 6), bool)\n",
    "\n",
    "backGroundMask = np.ones((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "\n",
    "labelsDic = {\n",
    "    'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "    'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "    'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "    'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "    'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "    'case'       :np.where(np.all(imgLabel == case, axis=-1)),\n",
    "    'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "    'dust'       :np.where(np.all(imgLabel == dust, axis=-1)),\n",
    "}\n",
    "\n",
    "#channel 1\n",
    "if 'wmInside' in labelsDic:\n",
    "    mask[labelsDic['wmInside'][0], labelsDic['wmInside'][1], 1] = 1\n",
    "    backGroundMask[labelsDic['wmInside']] = 0\n",
    "\n",
    "    \n",
    "#channel 2\n",
    "if 'rockInside' in labelsDic:\n",
    "    mask[labelsDic['rockInside'][0], labelsDic['rockInside'][1], 2] = 1\n",
    "    backGroundMask[labelsDic['rockInside']] = 0\n",
    "    \n",
    "if 'fineInside' in labelsDic:\n",
    "    mask[labelsDic['fineInside'][0], labelsDic['fineInside'][1], 2] = 1\n",
    "    backGroundMask[labelsDic['fineInside']] = 0\n",
    "    \n",
    "    \n",
    "#channel 3\n",
    "if 'teeth' in labelsDic:\n",
    "    mask[labelsDic['teeth'][0], labelsDic['teeth'][1], 3] = 1\n",
    "    backGroundMask[labelsDic['teeth']] = 0\n",
    "\n",
    "    \n",
    "#channel 4\n",
    "if 'emptyInside' in labelsDic:\n",
    "    mask[labelsDic['emptyInside'][0], labelsDic['emptyInside'][1], 4] = 1\n",
    "    backGroundMask[labelsDic['emptyInside']] = 0\n",
    "\n",
    "if 'shadow' in labelsDic:\n",
    "    mask[labelsDic['shadow'][0], labelsDic['shadow'][1], 4] = 1\n",
    "    backGroundMask[labelsDic['shadow']] = 0\n",
    "    \n",
    "if 'dust' in labelsDic:\n",
    "    mask[labelsDic['dust'][0], labelsDic['dust'][1], 4] = 1\n",
    "    backGroundMask[labelsDic['dust']] = 0\n",
    "    \n",
    "    \n",
    "#channel 5\n",
    "if 'case' in labelsDic:\n",
    "    mask[labelsDic['case'][0], labelsDic['case'][1], 5] = 1\n",
    "    backGroundMask[labelsDic['case']] = 0\n",
    "      \n",
    "\n",
    "#channel 0\n",
    "mask[:,:, 0] = backGroundMask\n",
    "    \n",
    "\n",
    "print(imgLabel.shape)\n",
    "plt.imshow(imgLabel)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(labelsDic)\n",
    "\n",
    "for i in range(6):\n",
    "    plt.imshow(mask[:,:,i])\n",
    "    plt.show()\n",
    "    \n",
    "np.save('/home/hooman/dataPreparation/hsTrainingSet/masks0PaddedForUNet/' + '1_20161116-155500_0001n0_10537', mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# WRONG Creating the (128, 160, 6) labels \n",
    "generatedMaskPath = '/home/hooman/dataPreparation/hsTrainingSet/masks0PaddedForUNet/'\n",
    "\n",
    "for fileName in os.listdir(labelsPath):\n",
    "    \n",
    "    label = imread(labelsPath + fileName) \n",
    "    \n",
    "    \n",
    "    \n",
    "    #resize the label map.\n",
    "    imgLabelResized = cv2.resize(label, (640, 480)) \n",
    "\n",
    "    # you can downsample with numpy too. I use opencv to be consistant.    imgDs = img[::4, ::4, :]\n",
    "    imgLabelDs = cv2.resize(imgLabelResized, (0,0), fx=0.25, fy=0.25) \n",
    "\n",
    "    imgLabel = cv2.copyMakeBorder(imgLabelDs,4,4,0,0,cv2.BORDER_CONSTANT,value=(0,0,0,0))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1], 6), bool)\n",
    "\n",
    "    backGroundMask = np.ones((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "\n",
    "    \n",
    "    \n",
    "    labelsDic = {\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "        'case'       :np.where(np.all(imgLabel == case, axis=-1)),\n",
    "        'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "        'dust'       :np.where(np.all(imgLabel == dust, axis=-1)),\n",
    "    }\n",
    "\n",
    "    \n",
    "    \n",
    "    #channel 1\n",
    "    if 'wmInside' in labelsDic:\n",
    "        mask[labelsDic['wmInside'][0], labelsDic['wmInside'][1], 1] = 1\n",
    "        backGroundMask[labelsDic['wmInside']] = 0\n",
    "\n",
    "\n",
    "    #channel 2\n",
    "    if 'rockInside' in labelsDic:\n",
    "        mask[labelsDic['rockInside'][0], labelsDic['rockInside'][1], 2] = 1\n",
    "        backGroundMask[labelsDic['rockInside']] = 0\n",
    "\n",
    "    if 'fineInside' in labelsDic:\n",
    "        mask[labelsDic['fineInside'][0], labelsDic['fineInside'][1], 2] = 1\n",
    "        backGroundMask[labelsDic['fineInside']] = 0\n",
    "\n",
    "\n",
    "    #channel 3\n",
    "    if 'teeth' in labelsDic:\n",
    "        mask[labelsDic['teeth'][0], labelsDic['teeth'][1], 3] = 1\n",
    "        backGroundMask[labelsDic['teeth']] = 0\n",
    "\n",
    "\n",
    "    #channel 4\n",
    "    if 'emptyInside' in labelsDic:\n",
    "        mask[labelsDic['emptyInside'][0], labelsDic['emptyInside'][1], 4] = 1\n",
    "        backGroundMask[labelsDic['emptyInside']] = 0\n",
    "\n",
    "    if 'shadow' in labelsDic:\n",
    "        mask[labelsDic['shadow'][0], labelsDic['shadow'][1], 4] = 1\n",
    "        backGroundMask[labelsDic['shadow']] = 0\n",
    "\n",
    "    if 'dust' in labelsDic:\n",
    "        mask[labelsDic['dust'][0], labelsDic['dust'][1], 4] = 1\n",
    "        backGroundMask[labelsDic['dust']] = 0\n",
    "\n",
    "\n",
    "    #channel 5\n",
    "    if 'case' in labelsDic:\n",
    "        mask[labelsDic['case'][0], labelsDic['case'][1], 5] = 1\n",
    "        backGroundMask[labelsDic['case']] = 0\n",
    "\n",
    "\n",
    "    #channel 0\n",
    "    mask[:,:, 0] = backGroundMask\n",
    "    \n",
    "    \n",
    "    np.save(generatedMaskPath + fileName.replace(\".png\",\"\"), mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Creating the (128, 160, 6) labels \n",
    "\n",
    "imgLabel = imread(labelsPath + '1_20161116-155500_0001n0_10537.png') \n",
    "#imgLabel = imread(labelsPath + '1016_CHM_026_116.png') \n",
    "#imgLabel = imread(labelsPath + '1_20161115-153100_0001n0_14400.png')\n",
    "\n",
    "mask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), int)\n",
    "\n",
    "\n",
    "labelsDic = {\n",
    "    'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "    'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "    'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "    'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "    'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "    'case'       :np.where(np.all(imgLabel == case, axis=-1)),\n",
    "    'shadow'     :np.where(np.all(imgLabel == shadow, axis=-1)),\n",
    "    'dust'       :np.where(np.all(imgLabel == dust, axis=-1)),\n",
    "}\n",
    "\n",
    "#channel 1\n",
    "if 'wmInside' in labelsDic:\n",
    "    mask[labelsDic['wmInside']] = 1\n",
    "\n",
    "    \n",
    "#channel 2\n",
    "if 'rockInside' in labelsDic:\n",
    "    mask[labelsDic['rockInside']] = 2\n",
    "     \n",
    "if 'fineInside' in labelsDic:\n",
    "    mask[labelsDic['fineInside']] = 2\n",
    "    \n",
    "    \n",
    "#channel 3\n",
    "if 'teeth' in labelsDic:\n",
    "    mask[labelsDic['teeth']] = 3\n",
    "\n",
    "    \n",
    "#channel 4\n",
    "if 'emptyInside' in labelsDic:\n",
    "    mask[labelsDic['emptyInside']] = 4\n",
    "\n",
    "if 'shadow' in labelsDic:\n",
    "    mask[labelsDic['shadow']] = 4\n",
    "    \n",
    "if 'dust' in labelsDic:\n",
    "    mask[labelsDic['dust']] = 4\n",
    "    \n",
    "    \n",
    "#channel 5\n",
    "if 'case' in labelsDic:\n",
    "    mask[labelsDic['case']] = 5\n",
    "      \n",
    "    \n",
    "\n",
    "print(imgLabel.shape)\n",
    "plt.imshow(imgLabel)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(labelsDic)\n",
    "\n",
    "plt.imshow(mask)\n",
    "plt.show()\n",
    "    \n",
    "#np.save('/home/hooman/dataPreparation/hsTrainingSet/masks0PaddedForUNet/' + '1_20161116-155500_0001n0_10537', mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# loading a .npy file from disk\n",
    "mask = np.load('/home/hooman/dataPreparation/hsTrainingSet/masks0PaddedForUNet/1_20161116-155500_0001n0_10537.npy')\n",
    "\n",
    "for i in range(6):\n",
    "    plt.imshow(mask[:,:,i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to get the delination from bounding boxes with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# K-Means clustering on RGB on fullImage\n",
    "\n",
    "croppedImagesPath = '/home/hooman/dataPreparation/hsTrainingSet/cropped/croppedImages/'\n",
    "img = imread(croppedImagesPath + '1_20161115-073100_0001n0_2217.png')\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "(rows, cols) = (img.shape[0], img.shape[1])  #(336, 711, 3)\n",
    "\n",
    "halfImage = img #img[0:rows/2, 0: cols/3]\n",
    "\n",
    "plt.imshow(halfImage)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kernel = np.ones((7,7), np.uint8)\n",
    "#halfImage = cv2.dilate(halfImage, kernel, iterations=1)\n",
    "#halfImage = cv2.erode(halfImage, kernel, iterations=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# K-Means color compression with opencv\n",
    "\n",
    "#halfImage = cv2.imread(croppedImagesPath + '1_20161115-153100_0001n0_22800.png')\n",
    "Z = halfImage.reshape((-1,3))\n",
    "\n",
    "# convert to np.float32\n",
    "Z = np.float32(Z)\n",
    "\n",
    "# define criteria, number of clusters(K) and apply kmeans()\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "K = 2\n",
    "ret,label,center=cv2.kmeans(Z,K,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "\n",
    "#Z[label.flatten()==1]= (0,0,0)\n",
    "md = stats.mode(label.flatten())\n",
    "Z[label.flatten() == md[0][0]]= (255,255,255)#(0,0,0)\n",
    "\n",
    "\n",
    "\n",
    "Z = Z.reshape((halfImage.shape))\n",
    "res = Z.astype(np.uint8)\n",
    "plt.imshow(res)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "normalizedImg = cv2.normalize(res,res, 0, 1.0, cv2.NORM_MINMAX)\n",
    "\n",
    "normalizedImg = normalizedImg[:,:,0]\n",
    "\n",
    "mask = np.zeros(normalizedImg.shape[1])\n",
    "for c in range(normalizedImg.shape[1]):\n",
    "    count = 0\n",
    "    for r in range(normalizedImg.shape[0]):\n",
    "        count += normalizedImg[r][c]\n",
    "        \n",
    "    mask[c] = count\n",
    "    \n",
    "plt.imshow(normalizedImg)\n",
    "plt.show()\n",
    "    \n",
    "plt.plot(mask)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# K-Means on HSV channels\n",
    "croppedImagesPath = '/home/hooman/dataPreparation/hsTrainingSet/cropped/croppedImages/'\n",
    "img = imread(croppedImagesPath + '1_20161115-073100_0001n0_2217.png')\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "hsv_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "plt.imshow(hsv_image)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hue, sat, val = hsv_image[:,:,0], hsv_image[:,:,1], hsv_image[:,:,2]\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.subplot(311)                             #plot in the first cell\n",
    "plt.subplots_adjust(hspace=.5)\n",
    "plt.title(\"Hue\")\n",
    "plt.hist(np.ndarray.flatten(hue), bins=180)\n",
    "\n",
    "\n",
    "plt.subplot(312)                             #plot in the second cell\n",
    "plt.title(\"Saturation\")\n",
    "plt.hist(np.ndarray.flatten(sat), bins=128)\n",
    "\n",
    "plt.subplot(313)                             #plot in the third cell\n",
    "plt.title(\"Luminosity Value\")\n",
    "plt.hist(np.ndarray.flatten(val), bins=128)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# K-Means clustering to get the delination from bounding boxes\n",
    "halfImage = hsv_image[:,:,2]\n",
    "\n",
    "\n",
    "Z = halfImage.reshape((-1,3))\n",
    "\n",
    "# convert to np.float32\n",
    "Z = np.float32(Z)\n",
    "\n",
    "# define criteria, number of clusters(K) and apply kmeans()\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "K = 2\n",
    "ret,label,center=cv2.kmeans(Z,K,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "\n",
    "#Z[label.flatten()==1]= (0,0,0)\n",
    "md = stats.mode(label.flatten())\n",
    "Z[label.flatten() == md[0][0]]= 0\n",
    "\n",
    "\n",
    "\n",
    "Z = Z.reshape((halfImage.shape))\n",
    "res = Z.astype(np.uint8)\n",
    "plt.imshow(res)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "resBool = Z.astype(np.bool8)\n",
    "plt.imshow(resBool)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "mask = np.zeros(resBool.shape[1])\n",
    "for c in range(resBool.shape[1]):\n",
    "    count = 0\n",
    "    for r in range(resBool.shape[0]):\n",
    "        count += resBool[r][c]\n",
    "        \n",
    "    mask[c] = count\n",
    "    \n",
    "    \n",
    "    \n",
    "plt.plot(mask)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     15
    ]
   },
   "outputs": [],
   "source": [
    "# Trying to detect corners\n",
    "\n",
    "img = imread('/home/hooman/dataPreparation/hsTrainingSet/cropped/croppedImages/1_20161115-073100_0001n0_2217.png')\n",
    "\n",
    "imgLabel = imread('/home/hooman/dataPreparation/hsTrainingSet/cropped/croppedLabels/1_20161115-073100_0001n0_2217.png') \n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "plt.imshow(imgLabel)\n",
    "plt.show()\n",
    "\n",
    "getEmptyBoundaries(imgLabel, img)\n",
    "\n",
    "\n",
    "\n",
    "def getEmptyBoundaries(imgLabel, img=[]):\n",
    "    '''\n",
    "    HS: \n",
    "    ---This method returs a list of boundaries: 1 bucket boundary, 1 fineInside boundary (if present) and several     rockInside boundaries (if present). \n",
    "    '''\n",
    "    boundariesDict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##############################################\n",
    "    ########## Reading Labeled Pixels ############\n",
    "    ##############################################\n",
    "    labelsDic = {\n",
    "        'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "        'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "        'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "        'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "        'teeth'      :np.where(np.all(imgLabel == teeth, axis=-1)),\n",
    "    }\n",
    "    \n",
    "    if len(img) >0 :\n",
    "        plt.imshow(imgLabel)\n",
    "        plt.show()\n",
    "        print(labelsDic)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "    #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "    if len(img) >0 :\n",
    "        print(sortedLabelColsDic)\n",
    "        print(\"\\n\")\n",
    "        print(sortedLabelRowsDic)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    ##############################################\n",
    "    ############# emptyInside Boundary ############\n",
    "    ##############################################\n",
    "    if 'emptyInsideCols' in sortedLabelColsDic and 'emptyInsideRows' in sortedLabelRowsDic:\n",
    "        # Getting the rock maks used to find rock boundaries        \n",
    "        rockMask = np.zeros((imgLabel.shape[0], imgLabel.shape[1]), bool)\n",
    "        rockMask[labelsDic['emptyInside']] = 1\n",
    "\n",
    "        # This converts any np.array to opencv image.\n",
    "        cv_rockMask = img_as_ubyte(rockMask)\n",
    "\n",
    "        contours, _ = cv2.findContours(cv_rockMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Getting bounding boxes from contours\n",
    "        rockBoundaries = []\n",
    "        for cnt in contours:\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            (xmin, xmax, ymin, ymax) = (y, (y+h), x, (x+w))\n",
    "\n",
    "            # only consider large boundaries.\n",
    "            #if h>3 and w >3:\n",
    "            rockBoundaries.append([xmin, xmax, ymin, ymax])\n",
    "\n",
    "        boundariesDict['emptyInside'] = rockBoundaries\n",
    "\n",
    "\n",
    "    \n",
    "                \n",
    "\n",
    "    ##############################################\n",
    "    ######### Draw Boundaries if Verbose #########\n",
    "    ##############################################\n",
    "    if len(img) > 0:\n",
    "        print(boundariesDict)\n",
    "        \n",
    "        \n",
    "        #draw rockInside boundaries\n",
    "        for rockBb in boundariesDict['emptyInside']:\n",
    "            cv2.rectangle(img,(rockBb[2], rockBb[0]),(rockBb[3], rockBb[1]),(255,0,0),3)\n",
    "        \n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    return boundariesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# opencv pointPolyGon test to see if a point is inside or on the contour\n",
    "\n",
    "k = cv2.pointPolygonTest(largestContour, halfImage[:,:,0], False)\n",
    "\n",
    "for i in range(168):\n",
    "    for j in range(237):\n",
    "        k = cv2.pointPolygonTest(largestContour, (i,j) , False)\n",
    "        if k==-1:\n",
    "            halfImage[i,j,:] = (0,0,0)\n",
    "            \n",
    "plt.imshow(halfImage)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Erosion and dialation with opencv\n",
    "\n",
    "img = cv2.imread('/home/hooman/dataPreparation/hsTrainingSet/cropped/croppedImages/1_20161115-153100_0001n0_22800.png', 0)\n",
    "\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "img_erosion = cv2.erode(img, kernel, iterations=1)\n",
    "img_dilation = cv2.dilate(img, kernel, iterations=1)\n",
    "\n",
    "cv2.imshow('Input', img)\n",
    "cv2.imshow('Erosion', img_erosion)\n",
    "cv2.imshow('Dilation', img_dilation)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(img_erosion)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(img_dilation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Segmentation with GrabCut openCV\n",
    "img = cv2.imread('/home/hooman/dataPreparation/hsTrainingSet/cropped/croppedImages/1_20161115-073100_0001n0_2217.png')\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "nbIterations = 1\n",
    "makeRoISmallerBy = int(1*img.shape[1]/100)\n",
    "\n",
    "\n",
    "mask = np.zeros(img.shape[:2],np.uint8)\n",
    "bgdModel = np.zeros((1,65),np.float64)\n",
    "fgdModel = np.zeros((1,65),np.float64)\n",
    "\n",
    "\n",
    "rect = (makeRoISmallerBy,\n",
    "        makeRoISmallerBy,\n",
    "        img.shape[1]-makeRoISmallerBy,\n",
    "        img.shape[0]-makeRoISmallerBy\n",
    "       )\n",
    "\n",
    "\n",
    "cv2.grabCut(img,mask,rect,bgdModel,fgdModel, nbIterations, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "\n",
    "mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
    "\n",
    "img = img*mask2[:,:,np.newaxis]\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# K-Means clustering to get the delination from bounding boxes\n",
    "\n",
    "croppedImagesPath = '/home/hooman/dataPreparation/hsTrainingSet/cropped/croppedImages/'\n",
    "img = imread(croppedImagesPath + '1_20161115-073100_0001n0_2217.png')\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "(rows, cols) = (img.shape[0], img.shape[1])  #(336, 711, 3)\n",
    "\n",
    "halfImage = img[0:rows/2, 0: cols/3]\n",
    "\n",
    "plt.imshow(halfImage)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# K-Means color compression with opencv\n",
    "\n",
    "#halfImage = cv2.imread(croppedImagesPath + '1_20161115-153100_0001n0_22800.png')\n",
    "Z = halfImage.reshape((-1,3))\n",
    "\n",
    "# convert to np.float32\n",
    "Z = np.float32(Z)\n",
    "\n",
    "# define criteria, number of clusters(K) and apply kmeans()\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "K = 2\n",
    "ret,label,center=cv2.kmeans(Z,K,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "\n",
    "#Z[label.flatten()==1]= (0,0,0)\n",
    "md = stats.mode(label.flatten())\n",
    "Z[label.flatten() == md[0][0]]= (255,255,255)\n",
    "\n",
    "\n",
    "\n",
    "Z = Z.reshape((halfImage.shape))\n",
    "res = Z.astype(np.uint8)\n",
    "plt.imshow(res)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "cv_image = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY);\n",
    "contours, _ = cv2.findContours(cv_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "\n",
    "largestContour = max(contours, key=len)\n",
    "\n",
    "cv2.drawContours(halfImage, largestContour, -1, (0,255,0), 3)\n",
    "\n",
    "plt.imshow(halfImage)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "normalizedImg = cv2.normalize(res,res, 0, 1.0, cv2.NORM_MINMAX)\n",
    "\n",
    "normalizedImg = normalizedImg[:,:,0]\n",
    "\n",
    "mask = np.zeros(normalizedImg.shape[1])\n",
    "\n",
    "for c in range(normalizedImg.shape[1]):\n",
    "    count = 0\n",
    "    for r in range(normalizedImg.shape[0]):\n",
    "        count += normalizedImg[r][c]\n",
    "        \n",
    "    mask[c] = count\n",
    "    \n",
    "plt.imshow(normalizedImg)\n",
    "plt.show()\n",
    "    \n",
    "plt.plot(mask)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# K-Means color compression with opencv\n",
    "\n",
    "#halfImage = cv2.imread(croppedImagesPath + '1_20161115-153100_0001n0_22800.png')\n",
    "Z = halfImage.reshape((-1,3))\n",
    "\n",
    "# convert to np.float32\n",
    "Z = np.float32(Z)\n",
    "\n",
    "# define criteria, number of clusters(K) and apply kmeans()\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "K = 8\n",
    "ret,label,center=cv2.kmeans(Z,K,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "# Now convert back into uint8, and make original image\n",
    "center = np.uint8(center)\n",
    "res = center[label.flatten()]\n",
    "res2 = res.reshape((halfImage.shape))\n",
    "\n",
    "plt.imshow(res2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Converting to float32 and back to opencv image uint8\n",
    "Z = np.float32(origImage)\n",
    "newImage = Z.astype(np.uint8)\n",
    "\n",
    "plt.imshow(newImage)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# rotate an image.\n",
    "\n",
    "img = imread('/home/hooman/dataPreparation/hsTestSet/images/1004_ESP_S04_015_4169.png')\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_rows, num_cols = img.shape[:2]\n",
    "\n",
    "rotation_matrix = cv2.getRotationMatrix2D((num_cols/2, num_rows/2), 30, 1)\n",
    "img_rotation = cv2.warpAffine(img, rotation_matrix, (num_cols, num_rows))\n",
    "\n",
    "\n",
    "plt.imshow(img_rotation)\n",
    "plt.show()\n",
    "\n",
    "cv2.imwrite('/home/hooman/dataPreparation/hsTestSet/hsRot.png', img_rotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old ways of doing things with just a single (bucketBoundary) class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Old way of visualizing with just the bucket boundary\n",
    "\n",
    "rows = readCsvRows(\"/home/hooman/dataPreparation/testSet_multiClass_bucket_fine_rock_NoTeeth_NoCase.csv\")\n",
    "\n",
    "for row in rows[1:]:\n",
    "    visualizeRow(row)\n",
    "\n",
    "for row in rows[1:]:\n",
    "    writeRowToDisk(row, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Find just bucket boundaries and wirte the results to rows\n",
    "rows = []\n",
    "for fileName in os.listdir(labelsPath):\n",
    "    filePath = labelsPath + fileName\n",
    "    \n",
    "    imgLabel = imread(filePath)\n",
    "    \n",
    "    print(\"processing file:\\n\", filePath)\n",
    "    foundBucketBoundary, xmin, xmax, ymin, ymax = getBucketBoundaries(imgLabel)\n",
    "    \n",
    "    if(foundBucketBoundary):\n",
    "        # write up the rows\n",
    "        row = fileName + \",\" + filePath + \",\" + str(ymin) +\",\"+ str(ymax) + \",\" + str(xmin) + \",\" + str(xmax) + \",\" + \"bucket\" + \"\\n\"\n",
    "    else:\n",
    "        row = fileName + \",\" + filePath + \",\" + \"\" +\",\"+ \"\" + \",\" + \"\" + \",\" + \"\" + \",\" + \"bucket\" + \"\\n\"\n",
    "        print(\"Found no bucket boundary\\n\")\n",
    "    \n",
    "    rows.append(row)\n",
    "        \n",
    "print(\"processes \"+ str(len(rows)) + \" rows\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting rock and fine inside boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Testing the getAllBoundaries method\n",
    "verbose = True\n",
    "fileNames = os.listdir(labelsPath)\n",
    "imgId = \"1_20170118-101000_0001n0_21339.png\" #fileNames[4]\n",
    "\n",
    "img = imread(imagesPath + imgId)\n",
    "imgLabel = imread(labelsPath + imgId)\n",
    "\n",
    "getAllBoundaries(imgLabel, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#preparing binary mask for contour extractions\n",
    "\n",
    "rockMask = np.zeros((img.shape[0], img.shape[1]), bool)\n",
    "\n",
    "rockMask[labelsDic['rockInside']] = 1\n",
    "\n",
    "plt.imshow(rockMask)\n",
    "plt.show()\n",
    "\n",
    "# This converts any np.array to opencv image.\n",
    "# Need this if you get: TypeError: image data type = 0 is not supported\n",
    "cv_image = img_as_ubyte(rockMask)\n",
    "\n",
    "plt.imshow(cv_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, hierarchy = cv2.findContours(cv_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, hierarchy = cv2.findContours(cv_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# drawing contours\n",
    "\n",
    "img = imread(imagesPath + imgId)\n",
    "\n",
    "cv2.drawContours(img, contours, -1, (0,255,0), 3)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "print(len(contours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# converting contours to bounding boxes\n",
    "\n",
    "idx =0 \n",
    "for cnt in contours:\n",
    "    idx += 1\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    roi=img[y:y+h,x:x+w]\n",
    "    if h>2 and w >2:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),2)\n",
    "\n",
    "    \n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring images in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# sometimes rocks as small as this one are labeled as rocks sometimes rocks larger than this labeled as fine\n",
    "\n",
    "fileNames = os.listdir(labelsPath)\n",
    "imgId = \"1_20161115-153100_0001n0_20400.png\" #fileNames[4]\n",
    "\n",
    "img = imread(imagesPath + imgId)\n",
    "imgLabel = imread(labelsPath + imgId)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imgLabel)\n",
    "plt.show()\n",
    "\n",
    "labelsDic = {\n",
    "    'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "    'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "    'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "    'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "    'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "}\n",
    "\n",
    "labelsDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#This is marked as fineInside, But it has rocks bigger than above.\n",
    "#This material (perfect for FM) and reall fine Mat (not good for FM) both labeled as fine inside. \n",
    "\n",
    "fileNames = os.listdir(labelsPath)\n",
    "imgId = \"1_20180122-111700_0001n0_52415.png\" #fileNames[4]\n",
    "\n",
    "img = imread(imagesPath + imgId)\n",
    "imgLabel = imread(labelsPath + imgId)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imgLabel)\n",
    "plt.show()\n",
    "\n",
    "labelsDic = {\n",
    "    'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "    'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "    'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "    'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "    'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "}\n",
    "\n",
    "labelsDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#THis image has been labeled wrong. It is labled as fine inside but it should be labeled as inappropriate.\n",
    "# Look at above for what real fine looks like \n",
    "\n",
    "\n",
    "fileNames = os.listdir(labelsPath)\n",
    "imgId = \"KAJF0576_20110311063631_avi_8667.png\" #fileNames[4]\n",
    "\n",
    "img = imread(imagesPath + imgId)\n",
    "imgLabel = imread(labelsPath + imgId)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imgLabel)\n",
    "plt.show()\n",
    "\n",
    "labelsDic = {\n",
    "    'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "    'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "    'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "    'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "    'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "}\n",
    "\n",
    "labelsDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Inapp for FM has the same label as Inapp for WM which makes the whole label useless\n",
    "\n",
    "fileNames = os.listdir(labelsPath)\n",
    "imgId = \"KAJF0576_20110311084449_avi_12408.png\" #fileNames[4]\n",
    "\n",
    "img = imread(imagesPath + imgId)\n",
    "imgLabel = imread(labelsPath + imgId)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imgLabel)\n",
    "plt.show()\n",
    "\n",
    "labelsDic = {\n",
    "    'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "    'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "    'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "    'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "    'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "}\n",
    "\n",
    "labelsDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# This one has been labeled wrong as well. \n",
    "\n",
    "fileNames = os.listdir(labelsPath)\n",
    "imgId = \"1016_CHM_025_2196.png\" #fileNames[4]\n",
    "\n",
    "img = imread(imagesPath + imgId)\n",
    "imgLabel = imread(labelsPath + imgId)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imgLabel)\n",
    "plt.show()\n",
    "\n",
    "labelsDic = {\n",
    "    'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "    'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "    'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "    'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "    'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "}\n",
    "\n",
    "labelsDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Dust inside and outside the bucket has one label\n",
    "fileNames = os.listdir(labelsPath)\n",
    "imgId = \"1016_CHM_026_116.png\" #fileNames[4]\n",
    "\n",
    "img = imread(imagesPath + imgId)\n",
    "imgLabel = imread(labelsPath + imgId)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imgLabel)\n",
    "plt.show()\n",
    "\n",
    "labelsDic = {\n",
    "    'rockInside' :np.where(np.all(imgLabel == rockInside, axis=-1)),\n",
    "    'fineInside' :np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "    'inapInside' :np.where(np.all(imgLabel == inapInside, axis=-1)),\n",
    "    'emptyInside':np.where(np.all(imgLabel == emptyInside, axis=-1)),\n",
    "    'wmInside'   :np.where(np.all(imgLabel == wmInside, axis=-1)),\n",
    "}\n",
    "\n",
    "labelsDic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the color maps right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Correct Color maps from document\n",
    "\"\"\" \n",
    "*** Dust and Shadow can be outside or inside. They are trying to convert all shadows and dusts to inside only\n",
    "    but this has not been done in my dataset yet.\n",
    "*** Inap is anything inside the bucket that is inappropriate for FM and for WM.\n",
    "\n",
    "*** Rock == Boulders\n",
    "*** FineInside == Good For Fragmentation\n",
    "    \n",
    "* Hydralics have no cable and no sheave (the pully puling the cables up).\n",
    "* Bucyris has two cables and two sheaves. \n",
    "* B&H has a single cable and a single sheaves\n",
    "\"\"\"\n",
    "\n",
    "rockInside  = (0, 0, 255, 100)     #blue     \"rock_inside\"      = \"0000FF\"\n",
    "fineInside  = (0, 255, 0, 100)     #green    \"fine_inside\"      = \"00FF00\"\n",
    "emptyInside = (255, 255, 0, 100)   #yellow   \"empty\"            = \"FFFF00\"\n",
    "wmInside    = (255, 100, 100, 100) #L-Pink   \"wm_landmarks\"     = \"FF6464\"\n",
    "inapInside  = (150, 100, 50,100)   #L-Brown  \"inapp_For_FM\"     = \"966432\"\n",
    "\n",
    "\n",
    "teeth       = (255,   0, 255, 100) #pink     \"teeth\"            = \"FF00FF\"\n",
    "case        = (255, 0, 0, 100)     #red      \"case\"             = \"FF0000\"\n",
    "truck       = (255, 255, 200, 100) #cream    \"truck\"            = \"FFFFC8\"\n",
    "sheave      = (255, 128, 0, 100)   #Orage    \"Sheave\"           = \"FF8000\"\n",
    "cable       = (0 , 0, 0, 100)      #black    \"Cable\"            = \"000000\"\n",
    "\n",
    "rockOutside = (128, 0, 255, 100)   #purple    \"rock_outside\"    = \"8000FF\"\n",
    "fineOutside = (0, 255, 255, 100)   #cyan      \"fine_outside\"     = \"00FFFF\"\n",
    "\n",
    "void        = (180, 50, 50, 100)   #Brown    \"void anything not in this labels\"  = \"B43232\"\n",
    "shadow      = (120, 120, 120, 100) #gray     \"shadow inside or outside\"          = \"787878\"\n",
    "dust        = (80, 80, 80, 100)    #D-Gray   \"dust inside or outside\"            = \"505050\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Old labels compiled by me, These are wrong\n",
    "\n",
    "rockInside = (0, 255, 0, 100)     #green     \"rock_inside\"      = \"00FF00\"\n",
    "emptyInside = (255, 255, 0, 100)  #yellow    \"empty\"            = \"FFFF00\"\n",
    "wmInside = (255, 100, 100, 100)   #tangering \"wm_landmarks\"     = \"FF6464\"\n",
    "shadInside = (120, 120, 120, 100) #gray      \"shadow inside\"    = \"787878\"\n",
    "dustInside = (80, 80, 80, 100)    #lightGray \"dust\"             = \"505050\"\n",
    "fineInside = (150, 100, 50,100)   #brown     \"fine_inside\"      = \"966432\"\n",
    "inapInside = (0, 0, 255, 100)     #blue      \"inappropriate_fm\" = \"0000FF\"\n",
    "\n",
    "\n",
    "fineOutside = (0, 255, 255, 100)  #cyan      \"fine_outside\"     = \"00FFFF\"\n",
    "teeth = (255,   0, 255, 100)      #pink      \"teeth\"            = \"FF00FF\"\n",
    "case = (255, 0, 0, 100)           #red       \"case\"             = \"FF0000\"\n",
    "truck = (255, 255, 200, 100)      #L-Yellow  \"truck\"            = \"FFFFC8\"\n",
    "noClass = (255, 255, 255, 100)    #white     \"notClassified\"    = \"FFFFFF\"\n",
    "rockOutside = (128, 0, 255, 100)  #purple    \"rock_outside\"     = \"8000FF\"\n",
    "void = (180, 50, 50, 100)         #L-Brown   \"void\"             = \"B43232\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "*** Hydralics have no cable and no sheave (the pully puling the cables up).\n",
    "*** Bucyris has two cables and two sheaves. \n",
    "*** B&H has a single cable and a single sheaves\n",
    "\"sheave\", \"cable\", , , , \n",
    "\"FF8000 orange\",\"000000 black\", , , , \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'> OLD Sandbox Area (DO NOT DELETE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# open the file\n",
    "csv_loc = \"/home/hooman/dataPreparation/exampleCsv.csv\" #where you want the file to be downloaded to \n",
    "csv_file = open(csv_loc, \"w\") \n",
    "# write up the rows\n",
    "row = \"bafileName\" + \",\" + \"bsFIlePath\" + \",\" + \"123\" +\",\"+ \"1215\" + \",\" + \"233\" + \",\" + \"432\" + \",\" + \"bsClass\" + \"\\n\"\n",
    "csv_file.write(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting existing network csvs to our csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#vis rows\n",
    "def visualizeRowsFromExistingNetwork(rows):\n",
    "    for row in rows:\n",
    "        vals = row.split(',')\n",
    "\n",
    "        img = imread(imagesPath + vals[0])\n",
    "        topx, topy, width, height = vals[1:5]\n",
    "\n",
    "        (topx, topy, width, height) = (int(round(float(topx))), int(round(float(topy))), int(round(float(width))), int(round(float(height)))) \n",
    "\n",
    "        xmin = topx\n",
    "        xmax = topx + width\n",
    "        ymin = topy\n",
    "        ymax = topy + height\n",
    "\n",
    "        cv2.rectangle(img,(xmin, ymin),(xmax, ymax),(255,0,0),3)\n",
    "\n",
    "        print(vals[0])\n",
    "\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "visualizeRowsFromExistingNetwork(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#getExist\n",
    "existNetRowsDict = {}\n",
    "for row in rows[0:60]:\n",
    "    vals = row.split(',')\n",
    "    existNetRowsDict[vals[0]] = vals[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#do rows\n",
    "for row in gt_rows[1:len(gt_rows)-1]:\n",
    "    vals = row.split(',')\n",
    "    \n",
    "    if vals[0] in existNetRowsDict:\n",
    "        topx, topy, width, height = existNetRowsDict[vals[0]]\n",
    "\n",
    "        (topx, topy, width, height) = (int(round(float(topx))), int(round(float(topy))), int(round(float(width))), int(round(float(height)))) \n",
    "\n",
    "        xmin = topx\n",
    "        xmax = topx + width\n",
    "        ymin = topy\n",
    "        ymax = topy + height\n",
    "        \n",
    "        \n",
    "        img = imread(imagesPath + vals[0])\n",
    "        cv2.rectangle(img,(xmin, ymin),(xmax, ymax),(255,0,0),3)\n",
    "\n",
    "        print(vals[0])\n",
    "\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'1_20161115-124600_0001n0_0.png' in rowsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'sdfsdf' in rowsDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating binary masks to be used for calculating accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# experiementing with binaryMasks\n",
    "\n",
    "gt = np.zeros((img.shape[0], img.shape[1]), bool)\n",
    "\n",
    "plt.imshow(gt)\n",
    "plt.show()\n",
    "\n",
    "gt[ymin:ymax, xmin:xmax] = 1\n",
    "\n",
    "print(xmin, xmax, ymin, ymax)\n",
    "\n",
    "plt.imshow(img[197:463,63:637])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# experiementing with grayScales\n",
    "img[197:463,63:637] = 0\n",
    "img[0:197,:] = 255\n",
    "img[463:img.shape[0]] = 255\n",
    "img[:, 0:63] = 255\n",
    "img[:, 637:img.shape[1]] = 255\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "img = img/255\n",
    "\n",
    "plt.imshow(img[:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drawing bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#theresholding in opencv red channel\n",
    "\n",
    "imgCh1 = imread(resultsLoc + \"Test.h5_0_ch1_net_out.png\")\n",
    "\n",
    "plt.imshow(imgCh1)\n",
    "plt.show()\n",
    "\n",
    "red    = (255, 0 , 0)   #ch1 = wm_landmarks\n",
    "\n",
    "\n",
    "_, imgCh1_thresh = cv2.threshold(imgCh1, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.imshow(imgCh1_thresh)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#theresholding in opencv Yellow channel\n",
    "\n",
    "\n",
    "yellow = (255, 255, 0) #ch3 = Teeth\n",
    "\n",
    "imgCh3 = imread(resultsLoc + \"Test.h5_0_ch3_net_out.png\")\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(imgCh3)\n",
    "plt.show()\n",
    "\n",
    "_, imgCh3_thresh = cv2.threshold(imgCh3, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.imshow(imgCh3_thresh)\n",
    "plt.show()\n",
    "\n",
    "labelsDic = {\n",
    "    'teeth':np.where(np.all(imgCh3_thresh == yellow, axis=-1)),\n",
    "}\n",
    "\n",
    "sortedLabelColsDic = {}\n",
    "sortedLabelRowsDic = {}\n",
    "for k in labelsDic.keys():\n",
    "    if len(labelsDic[k][0]) > 0:\n",
    "        sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0])\n",
    "        sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1])\n",
    "        \n",
    "        \n",
    "ch3Cols = sortedLabelColsDic['teethCols']\n",
    "ch3Rows = sortedLabelRowsDic['teethRows']\n",
    "\n",
    "print(ch3Cols)\n",
    "print(ch3Rows)\n",
    "\n",
    "\n",
    "cv2.rectangle(imgCh3_thresh,(ch3Rows[0], ch3Cols[0]),(ch3Rows[len(ch3Rows)-1], ch3Cols[len(ch3Cols)-1]),(255,0,0),2)\n",
    "\n",
    "plt.imshow(imgCh3_thresh)\n",
    "plt.show()\n",
    "\n",
    "imgray = cv2.cvtColor(imgCh3, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(imgray, 127, 255, 0)\n",
    "\n",
    "plt.imshow(imgray)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(thresh)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "(cnts, _) = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Converting to float32 and back to opencv image uint8 that can be displayed\n",
    "Z = np.float32(origImage)\n",
    "newImage = Z.astype(np.uint8)\n",
    "\n",
    "plt.imshow(newImage)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Converting from color to gray. To fix the findControus error:\n",
    "# FindContours support only 8uC1 and 32sC1 images in function cvStartFindContours\n",
    "cv_image = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This converts any np.array to opencv image that can be used for drawing contours.\n",
    "# Need this if you get: TypeError: image data type = 0 is not supported\n",
    "from skimage import img_as_ubyte\n",
    "cv_image = img_as_ubyte(rockMask)\n",
    "\n",
    "plt.imshow(cv_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#drawing contours in opencv\n",
    "\n",
    "cv2.drawContours(imgCh3, cnts, -1, (0,255,0), 1)\n",
    "\n",
    "plt.imshow(imgCh3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#show all channels\n",
    "rawFileName = \"/home/hooman/performanceAnalysis/mahdisNetworkResult/Test.h5_0_\" #rawFileNames.pop()\n",
    "restOfName = \"net_out.png\"\n",
    "\n",
    "img    = imread(rawFileName + restOfName)\n",
    "imgCh1 = imread(rawFileName + \"ch1_\" + restOfName)\n",
    "imgCh2 = imread(rawFileName + \"ch2_\"  + restOfName)\n",
    "imgCh3 = imread(rawFileName + \"ch3_\"  + restOfName)\n",
    "imgCh4 = imread(rawFileName + \"ch4_\"  + restOfName)\n",
    "\n",
    "foundBucketBoundary, xmin, xmax, ymin, ymax = getBucketBoundaryFromChannels(imgCh1, imgCh2, imgCh3, imgCh4)\n",
    "print(foundBucketBoundary, xmin, xmax, ymin, ymax)\n",
    "\n",
    "cv2.rectangle(img,(ymin, xmin),(ymax, xmax),(255,0,0),3)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imgCh1)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imgCh2)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imgCh3)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imgCh4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define pixel values for each label\n",
    "red    = (64, 0 , 0)   #ch1 = wm_landmarks\n",
    "green  = (0, 37, 0)    #ch2 =  Fine_Inside, Rock_inside\n",
    "yellow = (189, 189, 0) #ch3 = Teeth\n",
    "blue   = (0, 1, 1)     #ch4 = Empty, Shadow, Dust\n",
    "pink   = (1, 0, 1)     #ch5 = Case\n",
    "\n",
    "#load the pixels for each label\n",
    "labelsDic = {\n",
    "    'wm':np.where(np.all(imgCh1 == red, axis=-1)),\n",
    "    'matInside':np.where(np.all(imgCh2 == green, axis=-1)),\n",
    "    'teeth':np.where(np.all(imgCh3 == yellow, axis=-1)),\n",
    "    'emptyInside':np.where(np.all(imgCh4 == blue, axis=-1)),\n",
    "}\n",
    "\n",
    "sortedLabelColsDic = {}\n",
    "sortedLabelRowsDic = {}\n",
    "for k in labelsDic.keys():\n",
    "    if len(labelsDic[k][0]) > 0:\n",
    "        sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0])\n",
    "        sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "ch1Cols = sortedLabelColsDic['wmCols']\n",
    "ch1Rows = sortedLabelRowsDic['wmRows']\n",
    "\n",
    "ch2Cols = sortedLabelColsDic['matInsideCols']\n",
    "ch2Rows = sortedLabelRowsDic['matInsideRows']\n",
    "\n",
    "ch3Cols = sortedLabelColsDic['teethCols']\n",
    "ch3Rows = sortedLabelRowsDic['teethRows']\n",
    "\n",
    "ch4Cols = sortedLabelColsDic['emptyInsideCols']\n",
    "ch4Rows = sortedLabelRowsDic['emptyInsideRows']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "imgCh1 = imread(rawFileName + \"ch1_\" + restOfName)\n",
    "imgCh2 = imread(rawFileName + \"ch2_\"  + restOfName)\n",
    "imgCh3 = imread(rawFileName + \"ch3_\"  + restOfName)\n",
    "imgCh4 = imread(rawFileName + \"ch4_\"  + restOfName)\n",
    "\n",
    "#cv2.rectangle(imgCh1,(ch1Rows[0][0], ch1Cols[0][0]),(ch1Rows[0][len(ch1Rows[0])-1], ch1Cols[0][len(ch1Cols[0])-1]),(255,0,0),2)\n",
    "#cv2.rectangle(imgCh2,(ch2Rows[0][0], ch2Cols[0][0]),(ch2Rows[0][len(ch2Rows[0])-1], ch2Cols[0][len(ch2Cols[0])-1]),(255,0,0),2)\n",
    "#cv2.rectangle(imgCh3,(ch3Rows[0][0], ch3Cols[0][0]),(ch3Rows[0][len(ch3Rows[0])-1], ch3Cols[0][len(ch3Cols[0])-1]),(255,0,0),2)\n",
    "#cv2.rectangle(imgCh4,(ch4Rows[0][0], ch4Cols[0][0]),(ch4Rows[0][len(ch4Rows[0])-1], ch4Cols[0][len(ch4Cols[0])-1]),(255,0,0),2)\n",
    "\n",
    "cv2.rectangle(imgCh1,(ch1Rows[0], ch1Cols[0]),(ch1Rows[len(ch1Rows)-1], ch1Cols[len(ch1Cols)-1]),(255,0,0),2)\n",
    "cv2.rectangle(imgCh2,(ch2Rows[0], ch2Cols[0]),(ch2Rows[len(ch2Rows)-1], ch2Cols[len(ch2Cols)-1]),(255,0,0),2)\n",
    "cv2.rectangle(imgCh3,(ch3Rows[0], ch3Cols[0]),(ch3Rows[len(ch3Rows)-1], ch3Cols[len(ch3Cols)-1]),(255,0,0),2)\n",
    "cv2.rectangle(imgCh4,(ch4Rows[0], ch4Cols[0]),(ch4Rows[len(ch4Rows)-1], ch4Cols[len(ch4Cols)-1]),(255,0,0),2)\n",
    "\n",
    "\n",
    "plt.imshow(imgCh1)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imgCh2)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imgCh3)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imgCh4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getBucketBoundaryFromChannels(imgCh1, imgCh2, imgCh3, imgCh4):\n",
    "    #define pixel values for each label\n",
    "    red    = (64, 0 , 0)   #ch1 = wm_landmarks\n",
    "    green  = (0, 37, 0)    #ch2 =  Fine_Inside, Rock_inside\n",
    "    yellow = (189, 189, 0) #ch3 = Teeth\n",
    "    blue   = (0, 1, 1)     #ch4 = Empty, Shadow, Dust\n",
    "    pink   = (1, 0, 1)     #ch5 = Case\n",
    "\n",
    "    #load the pixels for each label\n",
    "    labelsDic = {\n",
    "        'wm':np.where(np.all(imgCh1 == red, axis=-1)),\n",
    "        'matInside':np.where(np.all(imgCh2 == green, axis=-1)),\n",
    "        'teeth':np.where(np.all(imgCh3 == yellow, axis=-1)),\n",
    "        'emptyInside':np.where(np.all(imgCh4 == blue, axis=-1)),\n",
    "    }\n",
    "\n",
    "\n",
    "    #This flags signals whether we could detect any boundaries or not\n",
    "    foundBucketBoundary = False\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            foundBucketBoundary = True\n",
    "\n",
    "    #This flag can be used to label the boundary as either full, or empty bucket \n",
    "    #isFullBucket = len(labelsDic['rock'][0]) > 0\n",
    "\n",
    "\n",
    "    #get the boundary for each label\n",
    "    sortedLabelColsDic = {}\n",
    "    sortedLabelRowsDic = {}\n",
    "    for k in labelsDic.keys():\n",
    "        if len(labelsDic[k][0]) > 0:\n",
    "            sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "            sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "\n",
    "\n",
    "    #Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "    lowColVals = []\n",
    "    highColVals = []\n",
    "    for labV in sortedLabelColsDic.values():\n",
    "        for v in labV:\n",
    "            lowColVals.append(v[0])\n",
    "            highColVals.append(v[len(v)-1])\n",
    "\n",
    "    lowRowVals = []\n",
    "    highRowVals = []\n",
    "    for labV in sortedLabelRowsDic.values():\n",
    "        for v in labV:\n",
    "            lowRowVals.append(v[0])\n",
    "            highRowVals.append(v[len(v)-1])\n",
    "\n",
    "\n",
    "\n",
    "    #get the bucket boundary edges\n",
    "    xmins = np.sort(np.array(lowColVals))\n",
    "    xmaxs = np.sort(np.array(highColVals))\n",
    "    ymins = np.sort(np.array(lowRowVals))\n",
    "    ymaxs = np.sort(np.array(highRowVals))\n",
    "\n",
    "\n",
    "    if(foundBucketBoundary):\n",
    "        #return final bucket boundary points\n",
    "        return foundBucketBoundary, xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1]  \n",
    "    else:\n",
    "        return foundBucketBoundary, \"\",\"\",\"\",\"\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#img = imread(resultsLoc + \"Test.h5_0_net_out.png\")\n",
    "img = imread(resultsLoc + \"Test.h5_0_ch1_net_out.png\")\n",
    "#img = imread(resultsLoc + \"Test.h5_2_ch_net_out.png\")\n",
    "    \n",
    "\n",
    "#foundBucketBoundary, xmin, xmax, ymin, ymax = getBucketBoundariesFromMahdiNet(img)\n",
    "#print(foundBucketBoundary, xmin, xmax, ymin, ymax)\n",
    "#cv2.rectangle(img,(xmin, ymin),(xmax, ymax),(255,0,0),3)\n",
    "\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define pixel values for each label\n",
    "red    = (64, 0 , 0)   #ch1 = wm_landmarks\n",
    "green  = (0, 37, 0)    #ch2 =  Fine_Inside, Rock_inside\n",
    "yellow = (189, 189, 0) #ch3 = Teeth\n",
    "blue   = (0, 1, 1)     #ch4 = Empty, Shadow, Dust\n",
    "pink   = (1, 0, 1)     #ch5 = Case\n",
    "\n",
    "\n",
    "#load the pixels for each label\n",
    "labelsDic = {\n",
    "    'wm':np.where(np.all(img == red, axis=-1)),\n",
    "    'matInside':np.where(np.all(img == green, axis=-1)),\n",
    "    'teeth':np.where(np.all(img == yellow, axis=-1)),\n",
    "    'emptyInside':np.where(np.all(imgLabel == fineInside, axis=-1)),\n",
    "}\n",
    "\n",
    "\n",
    "#This flags signals whether we could detect any boundaries or not\n",
    "foundBucketBoundary = False\n",
    "for k in labelsDic.keys():\n",
    "    if len(labelsDic[k][0]) > 0:\n",
    "        foundBucketBoundary = True\n",
    "\n",
    "#This flag can be used to label the boundary as either full, or empty bucket \n",
    "#isFullBucket = len(labelsDic['rock'][0]) > 0\n",
    "\n",
    "\n",
    "#get the boundary for each label\n",
    "sortedLabelColsDic = {}\n",
    "sortedLabelRowsDic = {}\n",
    "for k in labelsDic.keys():\n",
    "    if len(labelsDic[k][0]) > 0:\n",
    "        sortedLabelColsDic[k+'Cols'] = np.sort(labelsDic[k][0]),\n",
    "        sortedLabelRowsDic[k+'Rows'] = np.sort(labelsDic[k][1]),\n",
    "\n",
    "\n",
    "\n",
    "#Get the min and max for rows and columns to caluclate bucket boundaries\n",
    "lowColVals = []\n",
    "highColVals = []\n",
    "for labV in sortedLabelColsDic.values():\n",
    "    for v in labV:\n",
    "        lowColVals.append(v[0])\n",
    "        highColVals.append(v[len(v)-1])\n",
    "\n",
    "lowRowVals = []\n",
    "highRowVals = []\n",
    "for labV in sortedLabelRowsDic.values():\n",
    "    for v in labV:\n",
    "        lowRowVals.append(v[0])\n",
    "        highRowVals.append(v[len(v)-1])\n",
    "\n",
    "\n",
    "\n",
    "#get the bucket boundary edges\n",
    "xmins = np.sort(np.array(lowColVals))\n",
    "xmaxs = np.sort(np.array(highColVals))\n",
    "ymins = np.sort(np.array(lowRowVals))\n",
    "ymaxs = np.sort(np.array(highRowVals))\n",
    "\n",
    "\n",
    "if(foundBucketBoundary):\n",
    "    #return final bucket boundary points\n",
    "    return foundBucketBoundary, xmins[0], xmaxs[len(xmaxs)-1], ymins[0], ymaxs[len(ymaxs)-1]  \n",
    "else:\n",
    "    return foundBucketBoundary, \"\",\"\",\"\",\"\","
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These are the channels used in generating above outputs\n",
    "\n",
    "\n",
    "    Ch0: background\n",
    "    Ch1:WM_landmarks\n",
    "    Ch2:Fine_Inside, Rock_inside\n",
    "    Ch3:Teeth\n",
    "    Ch4:Empty, Shadow, Dust\n",
    "    Ch5:Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(130):\n",
    "    for j in range(160):\n",
    "        if img[i,j,0] != 0 or img[i,j,1] != 0 or img[i,j,2] != 0:\n",
    "            print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(img[3, 127, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define pixel values for each label\n",
    "red    = (64, 0 , 0)   #ch1 = wm_landmarks\n",
    "green  = (0, 37, 0)    #ch2 =  Fine_Inside, Rock_inside\n",
    "yellow = (189, 189, 0) #ch3 = Teeth\n",
    "blue   = (0, 1, 1)     #ch4 = Empty, Shadow, Dust\n",
    "pink   = (1, 0, 1)     #ch5 = Case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load CSV with pandas\n",
    "from pandas import DataFrame, read_csv\n",
    "\n",
    "# General syntax to import a library but no functions: \n",
    "##import (library) as (give the library a nickname/alias)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd #this is how I usually import pandas\n",
    "import sys #only needed to determine Python version number\n",
    "import matplotlib #only needed to determine Matplotlib version number\n",
    "\n",
    "csv_loc = \"/home/hooman/dataPreparation/hsBoundingBoxes.csv\" #where you want the file to be downloaded to "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
